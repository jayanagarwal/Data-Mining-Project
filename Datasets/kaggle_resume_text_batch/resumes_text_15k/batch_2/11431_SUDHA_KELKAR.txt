

























































































Sudha P. KELKAR

Sudha Kelkar
9901577668 - sudhakelkar@gmail.com
Professional Summary
I am seeking a position where I can make a meaningful contribution continuously and grow professionally, utilize my knowledge and technical skills as a Big Data developer in the best possible manner and continuously learn the best practices to attain a challenging position, viewing organizations objectives and goals.
Skills
	· ETL Tools – Sqoop
· Big data Technologies: Hadoop, HDFS architecture, MapReduce, Yarn, Pig, Hive
· Relational Databases: MySQL
	· Cloud Computing: Cloudera Distributed environment
· Programming Languages: JAVA, SQL
· IDE Tools: Eclipse


Work History
	Nov 2016 to Current
	IQVIA Private Limited 
Programmer Analyst 
Project : Prod Ops
The purpose of the project is to store huge amount of clinical data generated by Sites across the Globe in Hive data warehouse. The data processing is done using Hadoop tools like Hive. This information is then translated into reports used by the business.

Role and Responsibility:
· Work with the Sqoop to load data from the external database to HDFS.
· Very good understanding of Partitions, Bucketing concepts in Hive and designed both Managed and External tables in Hive to optimize performance
· Creation and data loading in the hive tables and analysis of the data over them.
·  Understand customer analytic needs and translate them into pluggable Hadoop Hive.
· Written Hive jobs to parse the logs and structure them in tabular format to facilitate effective querying on the log data using Regex SERDE.
· Proactively solved a critical performance issue of a set of Hive Queries by various HQL optimization techniques.




	Dec 2015 to Oct 2016
	IQVIA Private Limited 
Programmer Analyst 
Project : Clinical Data Management
The purpose of the project is to store huge amount of information generated by Sites across the Globe in Hive data warehouse. Since the existing ETL setup takes huge time to do processing for the data, the company decided to use Hadoop technologies over existing systems.

Role and Responsibility:
· Created and worked on Sqoop jobs with incremental load to extract the data in an incremental last modified mode to HDFS.
· Work with the Sqoop to load data from the external database to HDFS.
· Created a merge jobs to merge the old data that was already there in HDFS with new extracted data before loading into Hive.
· Creation of cron jobs for the automation of jobs as per the time frequency and data availability.



	Jan 2015 to Nov 2015
	IQVIA Private Limited 
Programmer 
Project : Clinical Data Management
The project involves creation, validation and support for the clinical trials.
Role and Responsibility:
· Creation of forms, dictionaries, matrices and edit checks as per requirement
· Develop Database design as per the requirements document
· Programming validations on the database



	Oct 2011 to Dec 2014
	Cognizant Technology Solutions Pvt. Ltd. 
Programmer 
Project : CDM SSU
The project involves setting up database for Clinical Trials indulging in pre-market phases of new drugs.
Role and Responsibility:
· Take part in Database Design.
· Creating Questions/Question Groups/ Data Collection Modules (DCM)/Data Collection Instruments (DCI)/ Third Party DE pages/ DCI Book.
· Reviewing study related documents Study Specification/Edit Check Specification and suggesting changes if required.




Education
	2017
	Master of Computer Applications from IGNOU 



	2011
	Bachelor of Computer Applications from VP Institute of Management Studies and Research Sangli 



Personal Information
· Personal Profile
· Name: Sudha Kelkar
· Date of Birth: 11th October 1990
· Languages: English, Hindi, Marathi, Kannada.

Declaration
I hereby declare that the above written particulars are true to the best of my knowledge and belief.
Thank you very much for your time and consideration.
Sudha Kelkar
