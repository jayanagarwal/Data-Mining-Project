Krishna Srinivas Chilkamarri
ad6vij@r.postjobfree.com www.linkedin.com/in/krishnasrinivaschilkamarri 469-***-**** Professional Summary
Seasoned Data Engineer with extensive expertise in orchestrating data migrations, implementing cloud solutions, and leveraging big data platforms. Skilled in Python, Java, Spark, and AWS to drive complex projects, enhancing data workflows. Proficient in deploying advanced tools, including DBT, Informatica, and Snowflake, to streamline data processing and optimize accessibility.
SKILLS, TOOLS & CERTIFICATIONS
Programming Languages: Python (Advanced), R (Intermediate), Java(Advanced). Big Data Processing: Hadoop, Apache Spark, Kafka.
Data Integration and Orchestration: Informatica, DBT(Data Build Tool), AWS Data Pipeline, Apache Airflow, and Apache NiFi. Database Management: MySQL, PostgreSQL, Squirrel DB, DB2, MongoDB. Data Storage & Warehousing: Snowflake, AWS S3, Amazon Redshift, Apache Hive. Data Visualization: Power BI, Grafana, Kibana, Tableau. CI/CD: AWS CodePipeline, CodeBuild, GitLab.
Certifications: AWS Certified Cloud Practitioner, Certified Scrum Master (CSM), Certified Scrum Product Owner (CSPO). WORK EXPERIENCE
Data Engineer
Open Cloud Institute – UTSA, San Antonio, TX.
Sep 2021 – Aug 2023
● Integrated financial market data, using AWS Kinesis for real-time financial transactions and S3 events for SaaS application logs, enhancing the analytical depth for economic trends and user engagement analysis.
● Pioneered a seamless integration using Amazon S3, AWS Glue, and AWS Lake Formation, achieving a 50% data retrieval efficiency boost crucial for accelerating analytics and decision-making.
● Streamlined data orchestration with AWS Data Pipeline and executed scalable processing via AWS Lambda, augmented by Airflow, reducing batch times by 30% and enhancing data quality by 20%.
● Deployed Amazon Redshift for high-speed data warehousing, executing complex SQL over large datasets to quicken insight generation by 30%, significantly aiding strategic decisions.
● Developed a critical data pipeline that consolidated 500TB of data from multiple disparate sources into a single destination using AWS services, enabling quick analysis and reliable business insights on an unprecedented scale.
● Employed QuickSight to craft interactive dashboards visualizing financial trends and user interactions, enhancing strategic decision-making with clear, actionable insights.
● Crafted an Agile CI/CD framework using AWS CodePipeline and CodeBuild, integrated with GitLab, cutting data product time-to-market by 60% and boosting market responsiveness.
Data Engineer (Full-time)
Coforge, Hyderabad, India.
Apr 2020 – June 2021
● Orchestrated the migration of enterprise data from DB2 and Cloudera platforms to Snowflake, reducing dependency on legacy systems by over 40% through strategic data extraction and cleanup with Informatica. Enhanced data accessibility significantly.
● Spearheaded the implementation of DBT for data transformation, increasing data processing speed and accuracy by 35% and facilitating smoother, more reliable data loads into Snowflake.
● Developed custom macros to automate repetitive data manipulation tasks, enhancing staging and transformation efficiency, resulting in a 30% reduction in manual processing time and increased staging accuracy.
● Directed the staging phase of data migration, implementing stringent quality checks that improved data integrity and readiness for processing by 20%.
● Conducted comprehensive change analysis with DBT to resolve data discrepancies, optimizing transformation logic to enhance data flexibility and responsiveness to evolving business needs.
● Managed integration and support using Apache Hive within the Hadoop ecosystem and automated secure data transfers with the Charon utility, improving data operation stability and security and enhancing data transfer efficiency by 50%.
● Deployed Hue to provide an intuitive web-based interface for managing Hadoop services, reducing the learning curve for new data engineers by 25%.
● Leveraged Agile practices and employed Git with GitLab for source code management, cutting project timelines by 15% and boosting project efficiency by 25%, fostering a culture of rapid iteration and continuous improvement. Big Data Engineer (Internship)
Coforge, Hyderabad, India.
Oct 2019 – Mar 2020
● Spearheaded the design and deployment of a robust data pipeline architecture using Apache Kafka and Apache Airflow, enhancing data flow efficiency by 20%. This initiative streamlined real-time data ingestion and processing, facilitating quicker insights.
● Harnessed Power BI for dynamic analytical reporting, optimizing business processes by 18%. Developed comprehensive dashboards that provided critical insights into performance metrics, driving data-driven decision-making.
● Integrated Apache Spark with Apache Hive on the Hadoop ecosystem, cutting data handling time by 30%.
● Utilized Spark for fast in-memory data processing and Hive for efficient data warehousing, collectively boosting query performance and data accessibility.
● Standardized and refined database models using SQL and NoSQL databases, ensuring consistent data architecture across various sources. This optimization enforced data integrity and uniformity, crucial for accurate reporting and analytics. EDUCATION
The University of Texas at San Antonio, San Antonio, TX Master of Science in Computer Science, Data Science Concentration Aug 2021 – Aug 2023
Cumulative GPA: 3.70/4.0
Jawaharlal Nehru Technological University, Hyderabad, India Bachelor of Engineering in Computer Science
Aug2016 – Aug2020
Cumulative GPA: 8.5/10.0
ACADEMIC PROJECTS
AI Convergence: Vision & Language Enhancement
June 2023 – Aug2023
● Developed deep learning models with TensorFlow, achieving a 40% boost in prediction accuracy and enhanced pattern recognition capabilities, securing a 20% improvement through AI innovations.
● Optimized image processing workflows using OpenCV, accelerating processing speed by 15%, and innovated in NLP applications, boosting language understanding efficiency by 30% while driving a 50% increase in platform productivity with PyTorch. Neural Machine Translation Model
Jan 2023 – Apr 2023
● Collaborated with stakeholders to define the scope and expectations for a neural machine translation system, processed and normalized extensive multilingual datasets, and employed advanced preprocessing techniques to ensure high-quality model training.
● Developed and optimized an RNN-LSTM-based encoder-decoder model, implemented a sequence-to-sequence training methodology, and significantly improved BLEU scores across all targeted languages. Twitter Sentiment Analysis model
Jan 2022 – May 2022
● Developed and deployed an automated sentiment analysis model using NLP techniques and SVM classifiers, achieving a sentiment analysis accuracy of 93.25% and reducing analysis time by 96.67% by deploying the model on Heroku for superior scalability and reliability.
● Utilized PostgreSQL for data storage and retrieval, Power BI for data visualization, and TensorFlow for deep learning, ensuring high accuracy and consistency through advanced preprocessing and cleaning techniques like tokenization, lemmatization, and sentiment-specific word embeddings.
ACHIEVEMENTS
Runner-up at Smart India Hackathon 2019: Won a cash prize of 1,00,000 INR and a merit certificate from the Ministry of Education, Government of India.
First Prize at UTKRANTI 2018: Won a machine learning contest conducted by IIT Kharagpur, competing with over 30 teams from all over the country.
Published Paper: “Loan Delinquency Prediction Using Machine Learning Techniques” in College Research Journal.
Contact this candidate