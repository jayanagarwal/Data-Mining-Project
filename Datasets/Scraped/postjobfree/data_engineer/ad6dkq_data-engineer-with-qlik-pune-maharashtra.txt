RAHUL SARAWALE
Data Engineer
Experience Summary
Professional Experience
With over 4.3 years of experience in Information Technology, specialize in Data Integration and Engineering, particularly in the realm of ETL/ELT/CDC. Currently working as a Data Engineer with KPI Partners, Pune.
Honed my skills in platforms like Qlik Replicate, IBM CDC Infosphere and Informatica Cloud (IICS)/PowerCenter.
Core strength is in setting up complex data replication, building efficient data ingestion pipelines ensuring data consistency/accuracy/reliability, setting up a replication server and environment, On-prem to cloud server migrations, and efficient administration.
Expertise in performance tuning, backed by proficiency in SQL, Snowflake Data Warehouses, Unix/Shell scripting and Python.
A proven track record in client-facing roles, team leadership, RCA preparation, Error handling and troubleshooting, and meticulous documentation.
Technology Snapshot
Data Ingestion: Qlik Replicate and IBM
Infosphere
Data Integration: Informatica Cloud IICS
Databases: Oracle and Snowflake
Programming Language: Python, SQL, UNIX,
MATLAB, Embedded C, LATEX
Cloud Platform: AWS Stack – S3, Informatica
Cloud – IICS
Methodology: Agile, JIRA, Confluence,
ServiceNow
Data Science (Beginner):
ML/Tensorflow/OpenCV based Activity
Recognition & Automation with IoT,
Raspberry Pi and NodeRed
GenAI/Prompt Engineering (Beginner):
ChatGPT, Copilot
Soft Skill
Keen attention to detailing
Problem-solving acumen
Decision making
Communication
Education Background
My Contact
ad6dkq@r.postjobfree.com
Splendour Park, A-406, Lohegaon
Road, Wagholi, Pune-412207
+91-814*******
Infosys Client- Waste Management 2021 -2024
Capgemini Client- Medica 2020 -2021
Key responsibilities:
Liaised with clients, determined project requirements, and organized team schedules for efficient project delivery
Led 400 Qlik Replicate tasks, 200+ tables replication and 6 Servers, from creation to maintenance, ensuring smooth data flow between various sources and targets
Managed Qlik administration tasks including server migration, SSL upgrades, and user access approvals
Handled ETL/CDC pipeline development and support, including troubleshooting and performance tuning
Monitored system health using Qlik scheduling and Enterprise Manager, swiftly addressing issues to maintain operational efficiency Prepared comprehensive documentation, conducted RCA analysis, and provided training to teams on ETL/CDC tools
Key responsibilities:
Implemented Mapping utilizing various transformations, Mapping task, Synchronization task, Replication task, and Taskflow in Informatica cloud Executed Mass Ingestion tasks for file transfer and folder zipping/unzipping in designated landing folders
Implemented Incremental Load mappings and created ISM mappings within Informatica cloud
Conducted requirement gathering and performed Unit testing and contributed to Design Documentation
Key responsibilities:
Developed Informatica mappings using transformations and optimized Informatica mappings to address performance bottlenecks, ensuring efficient job execution
Applied Informatica and Database best practices for performance tuning Conducted Unit testing and prepared testing documentation, collaborating closely with the QA team
Prepared Technical Design Documentation reflecting the modified and tuned mapping logic
Capgemini Client- Kemper 2020 -2021
ME (E&TC)
Certification/Course Work
Python for Data Science
Databricks Data Engineer Associate
Informatica IICS, DBT
Data Vault Modelling
Snowflake DWH
Achievement
Received commendation from clients for
successfully managing and delivering complex
project
Contact this candidate