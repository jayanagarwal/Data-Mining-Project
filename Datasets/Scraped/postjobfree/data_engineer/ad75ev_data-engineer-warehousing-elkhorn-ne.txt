Pavani Ankilla
ad75ev@r.postjobfree.com
Phone No: 402-***-****
Sponsorship not required
PROFESSIONAL SUMMARY:
Ambitious Data Engineer with over 7 years of experience in building scale data solutions with emphasis on Project Planning & Management, Business Requirements Analysis, Designing, Development, testing, implementation, and maintenance. Seeking to have a challenging career to work independently in Data Warehousing with potential growth and facilitate critical solutions in time bound projects. Excel in Python, ETL Development and operationalizing data analytics solutions with improving database performance.
SKILLS:
Operating Systems: Windows, Linux, Unix.
Cloud Technologies: Snowflake, IICS, AWS CDK.
Data Warehousing: Snowflake, Teradata.
Databases: Snowflake, Teradata, DB2, Oracle, Microsoft SQL Server.
Methodologies: Safe Agile, Waterfall.
Data Integration Tool: Informatica PowerCenter.
Languages: Python, PySpark, SQL, Snow SQL.
File Formats: JSON, Parquet, XML, CSV, HTML.
IDE Tool: VS Code, IntelliJ, Databricks, Rapid SQL, IBM Data Studio.
Tools: JIRA, Jenkins, Control M (Scheduling tool), Service Now, Digital Workplace, Remedy Service, Tableau, Docker, Erwin Data Model, Bit bucket.

EDUCATION:
Master’s in system design from JNTU, Hyderabad-India, with GPA 3.5/4.
Bachelor in Electronics and Communication Engineering, JNTU-India, with GPA 3.6/4.0

Employer: Mutual Of Omaha Insurance Company
Title: Data Engineer Apr 2020 – Till Date

Description:
Mutual of Omaha Insurance Company provides Medicare Supplement, Life, Long Term Care, Disability, Critical Illness, Cancer, Heart Attack & Stroke, Dental, Vision, Group Benefits, Special Risk, Solutions for Businesses, Group Investments.
Mutual of Omaha Sr Health New Business division deals with products like Medicare Supplement, Dental, Vision, PDP (Prescription Drug Plan), MA (Medicare Advantage). Sr Health New Business Information systems (IS) support applications that underwrite Med SUPP, Dental and Vision, PDP (Prescription Drug Plan), MA (Medicare Advantage) products.
Responsibilities:
Implemented ETL pipelines for two major enterprise level projects.
Worked closely with analytics team to enhance data visualization and reporting capabilities resulting improvement in business insights.
Performed bulk loading from the external stage (AWS S3), internal stage to snowflake cloud using the COPY command.
Performed data loads into snowflake tables from the internal and external stages.
Written complex Snowsql scripts in Snowflake cloud data warehouse for business analysis and reporting.
Used FLATTEN table function to produce a lateral view of VARIANT, OBJECT, and ARRAY column.
Used SNOW PIPE for continuous data ingestion from the S3 bucket.
Developed snowflake procedures for executing branching and looping
Created clone objects to maintain zero-copy cloning.
Data validations have been done through information schema.
Experienced in fact and dimensional modeling (Star schema and snowflake schema) and SCD (Slowly Changing dimension).
Detected and corrected data quality errors while loading data into analytical warehouse on Snowflake.
Optimized DAG’s (Directed Acyclic Graph) for automating ETL pipelines.
Experience with AWS cloud services: EC2, S3, Lambda, SNS, Athena, and Glue
Cloned Production data for code modifications and testing
Conducted performance tuning and optimization techniques.
Provided training sessions to junior team members, improving team efficiency.
Collaborated with cross functional teams and business stake holders

Environment: Snowflake, AWS CDK, AWS Services, Bitbucket, Jenkins, Python, Git, Informatica PowerCenter, VScode, Jupyter Notebook, Teradata, DB2, SQL Server, ERWIN, Windows, JIRA, Control-M, Service Now, JSON, Parquet, XML, CSV, WinSCP, Unix.

Employer: Maruthi Technologies March 2018 – March 2020
Tittle: Informatica developer

Description:

An Auto/ Property/ Life Insurance Company serves its customers by offering wide range of innovative products to individuals and group customers located at various locations through its company-owned offices.
The primary objective of this project is to capture different Customers, Policies, Claims Agents, Products and financial related data from multiple OLTP Systems and Flat files. Extracted, Transformed and Loaded data into data warehouse using Informatica Power Centre and generated various reports on a monthly, semester and yearly basis. These reports give details of the various products and are used for Business development, improve performance and analysis of risk factors.
Responsibilities:
Involved in all phases of SDLC from requirement gathering, design, development, testing, support for production environment.
Involved in understanding the business requirements documents and translated into design document (HLD, LLD).
Involved in designing Dimensional Modeling like Star Schema and Snow Flake Schema.
Created mapping designs using various tools in Informatica Designer like Source Analyzer, Mapplet Designer and Mapping Designer.
Created complex mappings that involved implementation of Business Logic to load data in to staging area.
Created and used Informatica reusability at various levels of development.
Developed mappings/sessions using Informatica Power Center for data loading.
Performed data manipulations using various Informatica Transformations like Filter, Expression, Lookup Aggregate, Update Strategy, Normalizer, Joiner, Router, Sorter and Union.
Developed Workflows using task developer, Worklet designer and workflow designer in Workflow manager and monitored the results using workflow monitor.
Extracted data from Oracle and SQL Server then used Oracle for data warehousing.
Optimizing performance tuning at source, target, mapping and session level.
Actively participated in daily stand-up meetings, go-no-go meetings, and tri-week sprint meetings as part of Agile methodology and project specifications.
Coordinated with Scrum Master, Business Analysts and System Analysts to over-come the challenges and for technical specifications.
Involved in internal and external meetings as well as formal walk through among various teams and documenting the proceedings.
Environment: Informatica, Teradata, SQL Server, Windows, Jira, Tableau, SSRS, Power BI.
Contact this candidate