Manikanth
Python Developer
Email: ad59ju@r.postjobfree.com
Ph #: 813-***-****

Professional Summary
●10+ years of experience as a Data Engineer and Python Developer with deep understanding of technology trends with expertise in core of complex technologies.
●Strong understanding about the principles of Data warehousing like Data marts, OLTP, OLAP, Dimensional
Modeling, fact tables, dimension tables and star/snowflake schema modeling.
●Experienced in Database programming/ETL for creating Data Warehouse with Snowflake, IBM InfosphereDataStage11.5/11.3/ 9.1/8.5/8.1/7.5. (Manager, Designer, Administrator, Director), Parallel Extender, Talend and Teradata 14.10/13.10/12/10, DB2 UDB, Functions that involved source systems connectivity, jobs scheduling and Business reports functionality.
●Experienced with SDLC including analysis, design, construction, testing, and implementation.
●Experience in working with Tableau Desktop, Tableau Server, and Tableau Reader in various versions of Tableau 10.x/9.x/8. x.
●Experienced in complete life cycle of SDLC and major aspects of technological projects including Requirement Analysis, Design, Development, Database Design, Deployment, Testing, Debugging, and Application Maintenance.
● Also worked extensively on Different integration components of Guidewire application like, REST API’s, webservices, messaging, Batch Processes, plugins, Gosu bundles and Bulk Invoices.
●Experience in implementing with server-side technologies with restful API and MVC design patterns with Node JS and Django framework.
●Proficient in front-end development when working with Angular Versions, HTML5, CSS, XML, BootStrap, jQuery and Node.js.
●Experienced in AWS services like EC2, VPC, Route53, Lambda, IAM, Elastic Beanstalk, RDS, S3, CloudFront and Auto Scaling.
●Experience in implementing with server-side technologies with restful API and MVC design patterns with Node JS and Django framework.
●Experience in developing web services (WSDL, SOAP and REST) and consuming web services with python programming language.
●Expertise in Object Oriented Analysis and Design (OOAD), OOPS using Unified Modeling Language (UML), Design Patterns, MVC Frameworks.
●Proficient in developing complex SQL Queries, Stored Procedures, Triggers, Cursors, Functions, and Packages
along with performing DDL and DML operations on the database.
●Extensive experience in deploying, managing and developing MongoDB clusters and worked on Jenkins continuous integration tool for deployment of project.
●Proficient with automation tools like Jenkins for continuous integration and continuous delivery (CI/CD) and to implement the End-to-End Automation.
●Proficient in working with various Python Integrated Development Environments like PyCharm, Atom, Eclipse, PyDev and Sublime Text.
●Experience in writing Subqueries, Stored Procedures, Triggers, Cursors, and Functions on MySQL and PostgreSQL database.
●Enthusiastically managed multiple deadlines with priorities through proactively planning and managing tasks and resources.
●Excellent Interpersonal and communication skills, efficient time management and organization skills, ability to handle multiple tasks and work well in a team environment.

Technical Skills
Primary Languages
Python, SQL
Frameworks
Django, Flask, Angular Versions
Web Technologies
HTML5, CSS3, JavaScript, jQuery, AJAX, XML, JSON
IDEs Tools
Sublime Text, Spyder, PyCharm, Eclipse
API
REST, SOAP
Cloud
AWS, Snowflake, AWS IAM Roles & Policies & AWS Simple Storage Services (S3) including Storage classes, Object Life Cycle management, Microsoft azure.
Database
MySQL, Mongo DB, Oracle
Version Control Tools
Git, GitHub
Bug Tracking Tools
Jira
SDLC Methods
SCRUM, Agile
Operating System
Windows, iOS, Android, Sun Solaris, Linux, IBM AIX (4.0/5.x), Windows XP/NT/2000/7

Professional Experience:
Client: Verizon Data services Nov 2022 – Till Date
Role: Python Developer Responsibilities:
●Created parsers to extract system logs from different network devices.
●Created a reconcile program to check sanity of the logs with standard system logs.
●Developed re-usable collectors mechanism to retrieve system logs for all different network devices without the need to configure credentials and api endpoints by the consumers.
●Defined core entities and processes in the Guidewire application.
●Developed tagging mechanism to post-process the retrieved system logs from the api.
●Developed a config driven mechanism to post process system logs from network devices.
●Active participator in all agile ceremonies
Environment: Python, Django, FastAPI, JSON,, Jenkins, MongoDB, GITLAB, Agile, Windows, Pelchat.

Client: Frost Bank, San Antonio, TX Mar 2022 – Nov 2022
Role: Python Developer Responsibilities:
●Worked on the implementation of change requests raised by the client. Involved in complete Agile/SDLC - Requirement Analysis, Development, System and Integration Testing.
●Developed UI using HTML, jQuery, CSS, Angular 10 and Bootstrap.
●Implemented REST calls that consume the REST API’s using Angular Http Module.
●Guidewire out of the box rating management tool.
●Currently working on Guidewire Policy Center V 10.1, Configuration and Integration, Product model, Jobs, UW Issues, Publishing and Consuming Rest API’s etc.
●Developed Wrapper in Python for instantiating multi-threaded application.
●Wrote Python code embedded with JSON and XML to produce HTTP GET request, parsing HTML data from websites.
●Used Bootstrap and Angular UI Bootstrap for creating rich, Responsive UI Screens for varying screen sizes and devices.
●Developed automation scripts to back up the old records by using Mongo DB export command and transferred the files into backup machine with the help of ftplib.
●Worked on multiple containers and managed the load balancing between all the containers using NGINX.
●Used PyQt to implement GUI for the user to create, modify and view reports based on client data.
●Continuous improvement in integration workflow, project testing, and implementation of continuous integration pipeline with Jenkins. Implemented code coverage and unit test plug-ins with Maven in Jenkins.
●Participated in Version controlling process using GitHub, Git. Used Jira Project management tool.
●Performed efficient delivery of code based on principles of Test-Driven Development (TDD) and continuous integration to keep in line with Agile Software Methodology principles.
Environment: Python, Django Angular 10, TypeScript, Node JS, Angular CLI, NPM, Boto 3, Angular HTTP, JSON, XML, Mongo DB, PyQT, Maven, Jenkins, Mongo DB, GITHUB, Agile, Windows

Company: mroads, Hyderabad, India Jan 2018 – Dec 2020
Role: Python Developer Responsibilities:
●Worked in Agile development following Scrum process, Sprint and daily stand-up meetings.
●Coded Angular 2 controllers and directives for application functionality & used Angular 2 framework to bind HTML5 (views) to JavaScript objects (models).
●Involved in designing and developing Amazon EC2, Amazon S3, Amazon RDS, Amazon Elastic Load Balancing, Amazon SWF, Amazon SQS, and other services of the AWS infrastructure.
●Handled file uploads using Django's File Handling system with Boto3 and stored images into Amazon S3 Buckets, and monitored requests using Amazon CloudWatch.
●Performed validations for input fields making use of mainly Active Records.
●Developed and maintained the Verification and Validation group's project schedules and roadmap ensuring project on schedule.
●Used jQuery and AJAX calls for transmitting JSON data objects between front end and controllers and Utilized continuous integration and automated deployments with Jenkins.
●Wrote Python scripts to parse XML documents and load the data in database.
●Worked with IDE’s and also testing the API calls using postman before integrating with the front end.
●Identified several hidden bugs caused by complicated multithreading issues such as race conditions caused by asynchronous events and resolved them.
●Worked in MySQL database on simple queries and writing Stored Procedures for normalization and DE normalization.

●Wrote unit testing codes using unit test, resolving bugs and other defects.
●Used Version Control tool GIT. Debugged the project monitored on JIRA (Agile).
Environment: Python, Django, Angular 2, JavaScript, AWS, EC2, S3, Boto 3, jQuery, Ajax, XML, Bootstrap, GIT, Jira, Agile, Windows.

Company: TechDimension IT Solutions, Hyderabad, India Jun 2015 – Dec 2017 Role: Python Developer
Responsibilities:
●Developed user interface using, CSS3, HTML5, JavaScript and Jquery and Django.
●To ensure code for quality, logging, monitoring, and debugging code optimization dealt with python OOD.
●Designed table-less layouts, gradient effects, page layouts, navigation and icons using CSS and appropriate HTML tags as per W3C standards.
●Responsibilities for creation of Database, Business Logic to display the records dynamically on template based on query, providing user permission to access particular features of the site.
●Developed SOAP based API's and exposed them as SOAP web services via SOAPKit Router, consumed SOAP web services and tested web services using SOAP UI.
●Carried out various mathematical operations for calculation purpose using python libraries.
●Read client data in forms of .txt, .json, and .csv. Used Python’s File Handling syntax to read the files for data retrieval and storing purposes.
●Used Django APIs for database access and worked on databases like MySQL, PostgreSQL
●Prepared the reports for the day-to-day as well as weekly/monthly purposes in various formats like MS Excel, PDF, HTML, and XML etc.
●Responsible for Parsing XML data using XML parser and Testing, fixing of the bugs and coding modifications.
●Used integrated debugger tool from PyCharm for debugging of source code for better analysis.
●To build the Application used Maven and for Continuous Integration/Continuous Development used Jenkins.
●Maintained source code on GIT and used project management tool HP ALM.
Environment: Python, Django, HTML5, CSS3, SOAP, JSON, CSV, PostgreSQL, XML, PyCharm, Maven, Jenkins, GIT, HP ALM, Windows.

Blue Cross Blue Shield, India Oct 2012 – Nov 2015 Role: Data Engineer/Systems Analyst

Roles and Responsibilities:

Involved in the Analysis of the functional side of the project by interacting with functional experts to design and write technical specifications.
Worked on the Architecture of ETL process and design document, and by using the Architectural design created the source to target mapping from source to target mapping documents that involves source file, ODS Member match, Teradata tables, Transforming the data into 837 institutional and professional files and XML’s.
Created Data stage jobs (ETL Process) for populating the data into the Data warehouse constantly from different source systems like ODS, flat files, scheduled the same using Data Stage Sequencer for System Integration testing.
Extracted data from sources like Flat Files, DB2, Oracle and Teradata.
Preparing development timing plans & reporting to senior management about the supplier progress system & ensuring their engineering support for onsite integration & production launch.
Developed technical infrastructure designs, data mappings, flows and report dissemination mechanisms by architecting Data Warehouses and Marts.
Designed and developed parallel jobs, server and sequence jobs using DataStage Designer.
Experience in using different types of stages like Transformer, Aggregator, Merge, Join, Lookup, and Sort, remove duplicate, Funnel, Filter, Pivot, Shared containers for developing jobs.
Developed various bulk load and update procedures and processes using SQL Loader and PL/SQL and Teradata SQL Assist.
Developed various data connections from data source to Tableau Desktop for report and dashboard development.
Created Schedules and Extracted the data into Tableau Data Engine.
Exported data from Hive to Teradata and using Sqoop export and created the reports using the Tableau.
Involved in working with various kinds of data sources such as Teradata. Successfully loaded files to HDFS from Teradata, and load loaded from HDFS to HIVE and exported to Teradata based on business requirement.
Experienced in managing and reviewing Hadoop log files.
Supported Map Reduce Programs those are running on the cluster. Involved in loading data from UNIX file system to HDFS.
Troubleshooting performance issues with SQL tuning.
Working in a team with other associate product & component developers.
Involved in Unit testing and Integration testing to test jobs and the flow.
Worked on changed requests as per clients and projects technical specification needs.
Awareness about the functional/business aspects for the components.
Automated process of job monitoring, which helped in minimizing the manual intervention & documenting them perfectly.
Provide support for monthly/weekly batches in production run.
Involved in the Documentation of the ETL phase of the project.
Developed the reusable components, best practices that were later used in other Data warehouses.
Worked with release management teams to provide the necessary documentation and supported the go live projects.
Documenting business process, lesson learned & best practices for the project.
Environment: Infosphere DataStage 11.5, 8.7 and 8.5 (Designer, Manager, Director, and Administrator), Teradata v2r6, v2r12, DB2, ASG Zena tool, Oracle 10g/9i, Aqua Data Studio, Talend 6.4,7.0, Shell Scripts, AIX 5.1, Talend Data Fabric 6.2, 6.1, Hive, Pig, Python, HDFS.
Contact this candidate