Dheeraj Poppoppu
Frisco, Texas ***** Contact No: +1-217-***-****
Gmail ID: ad7441@r.postjobfree.com
Professional Summary
Over 4+ years of professional IT experience as a Data Engineer in the Analysis, development, testing and implementation of ETL & Business Intelligence solutions using cloud services (Azure and AWS). Proficient in managing and transforming large datasets, ensuring data quality, and supporting advanced analytics initiatives using big data Ecosystem and reporting tools such as Power BI &Tableau. Capability to collaborate in cross-functional teams to communicate flexible information arrangements that enhance company experiences and productivity.
Skills
Programming languages: C, OOPS through java, Python, Scala, Pyspark.
Database & Frameworks: SQL, MongoDB, Cosmo DB, Cassandra, PostgreSQL.
Cloud Platforms: Azure (Azure Blob Storage, Azure Synapse, Azure Data Factory, Azure Data Bricks, Azure Data Lake V2, Logic Apps, Functions, HDInsight, Event Hubs). AWS (S3, EC2, EMR, Redshift, RDS, Glue, Lambda, Kinesis, SNS, SQS, IAM, Cloud formation).
Hadoop Ecosystem (Bigdata): Apache Spark, Spark Streaming, Kafka, Sqoop, Hive, HBase, MapReduce, HDFS, Click house.
Data Orchestration: Apache Airflow.
BI Tools: Power BI, Tableau, Quick sight.
Version Management/CICD/DevOps: GIT, GitHub, Jenkins, Docker, Kubernetes, Terraform, Ansible.
ETL Tools: Talend Open Studio & Talend Enterprise Platform, Alation and Informatica.
Machine Learning: Regression Methods: Linear, Polynomial, Decision trees.
Methodologies: Agile (Scrum), Waterfall, UML, Design Patterns, SDLC.
Data Modeling Tools: Erwin Data Modeler 9.8, ER Studio v17, and Power Designer 16.6.
Currently Exploring: Apache Flink, Drill, Tachyon.
Work Experience
02/2023 to Current
Data Engineer
The Coca Cola – Atlanta, GA
Orchestrated data pipelines with Azure Data Factory, boosting processing efficiency by 35% and developing a custom alerting platform for monitoring, reducing downtime by 20%.
Deployed Spark-SQL applications in Databricks for data extraction, transformation, and aggregation, improving customer usage pattern analysis by 40%.
Spearheaded the design and execution of a high-performance data ingestion pipeline using Apache Kafka, achieving 99% uptime while processing over 2 million customer behavior events daily across data sources.
Fine-tuned Azure Synapse SQL pools for optimal query performance, leading to a 50% reduction in query execution time and enabling faster insights retrieval.
Configured a highly scalable data model and data warehouse using Snowflake, resulting in a 40% improvement in data processing speed and a 25% reduction in storage costs.
Devised Azure Logic Apps workflows to automate data integration tasks, reducing manual effort for recurring data processes.

07/2020 to 07/2022
Associate Data Engineer
Wipro – Hyderabad, India
Designed and executed a data ingestion pipeline using AWS Glue, capturing daily updates from healthcare databases and ensuring compliance with data integrity standards for over 1,500 patient records processed daily.
Deployed Spark applications in Scala, facilitating advanced interactions with PostgreSQL databases and Hive tables, enhancing data retrieval efficiency by 45%.
Designed and implemented a robust data ingestion framework using AWS Glue and Lambda, streamlined integration of diverse datasets from 5+ EHR systems, resulting in a 40% reduction in data processing time for analytics teams.
Architected robust data pipelines with AWS Glue, merging data from IoT devices, third-party APIs, and on-premises databases into Amazon Redshift and reducing processing time by 40%.
Applied data governance best practices and utilized tools such as Alation for metadata management, data quality assurance, and compliance.
Maintained robust documentation of data flows, governance protocols, and data management practices to support organizational data integrity.
Enhanced data accessibility for over 8 team members, driving enhance operational performance and insights.

01/2020 to 06/2020
Junior Data Engineer
Interactive Brokers – Hyderabad, India
Launched an Azure Data Factory solution to streamline the ingestion of daily trading data from Interactive Brokers API.
Configured integration runtime (IR) in Azure Data Factory to connect On-Premises SQL Server.
Transformed and loaded data from different sources like Azure SQL, Azure Blob storage and Azure SQL Data warehouse.
Data Ingestion to one or more Azure Services (Azure Data Lake Gen 2, Azure SQL, Azure DW) and processing the data in Azure Databricks.
Developed Databricks Python notebooks to Join, filter, pre-aggregate, and process the files stored in Azure data lake storage.
Utilized Snowflake and Teradata for scalable data warehousing solutions, enhancing data processing performance and reliability.
Crafted user-friendly Tableau dashboards that aggregated sales data from different locations, providing clarity on performance trends, this initiative facilitated targeted marketing efforts, boosting engagement metrics by 30% across all campaigns.

Education
12/2023
Master of Science: Management Information Systems
University of Illinois Springfield - Springfield, IL.
Certifications

DP 203 Azure Data Engineer Associate.
Contact this candidate