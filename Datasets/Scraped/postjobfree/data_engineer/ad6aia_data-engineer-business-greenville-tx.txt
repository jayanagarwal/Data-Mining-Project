Sunil Kumar M
ad6aia@r.postjobfree.com
https://www.linkedin.com/in/kumar-m-915179199/
PROFESSIONAL SUMMARY
Big Data Based Technologies: Hadoop, Hive, Cassandra, Kafka, Spark. Enterprise Middleware: Apache Kafka, Web Methods, Docker and Kubernetes. Cloud Technologies: AWS(Amazon Web Services), Azure Business Intelligence & Analytics MongoDB, Amazon Redshift, Azure Data Factory, Data Lake, Data Warehousing, Data Marts: Delta Lake, Databricks, Cosmos DB, Snowflake and BI Tools like MicroStrategy. Tableau, Oracle, AWS Glue
Systems: Linux, Windows.
Tools: Microsoft Office365(Power point, Word, Excel), Active Directory. Programming Languages: Python, Java, MySQL, C, HTML, CSS, PL/SQL, Spark, SQL. RDBMS: Oracle 11g, MySQL, PostgreSQL, IBM DB2
Development Tools: Eclipse, NetBeans, PyCharm, Jupyter Notebooks. Version Control Tools: GitHub, SVN
ETL Tools: Informatica, SSIS, DataStage.
Program Management: Database migrations, system migrations/integrations, automated solutions.
IT Project Life Cycle: Requirements management, business analysis, project scheduling, testing, PMO, resource onboarding, Agile, Confluence, JIRA. Program Management: Agile Methodology, Scrum Boards, Gantt Charts, Version control, Risk Management, Documentation.
Value-Added Leadership: Team building and mentoring, client relations and presentations. SUMMARY
Data Engineer with 3+ years of experience in building data intensive applications, tackling challenging architectural and scalability problems, managing data repos for efficient visualization, for a wide range of products.
Highly analytical team player, with the aptitude for prioritization of needs/risks. Constantly striving to streamlining processes and experimenting with optimizing and benchmarking solutions. Creative problem- solver and loves challenges.
Experience in shaping and implementing Big Data architecture.
Reliable Data Engineer keen to help companies collect, collate and exploit digital assets. Skilled administrator of information for Azure services ranging from Azure Databricks, Azure relational database and non-relational database, and Azure data factory and cloud services.
Practiced at cleansing and organizing data into new, more functional formats to drive increased efficiency and enhanced returns on investment.
Dynamic Database Engineer devoted to maintaining reliable computer systems for uninterrupted workflows. Delivered up-to-date methods to increase database stability and lower likelihood of security breaches and data corruption.
Background includes data mining, warehousing and analytics. Proficient in machine and deep learning. Quality-driven and hardworking with excellent communication and project management skills. PROFESSIONAL EXPERIENCE
Staffbee Solutions Inc., Dallas, TX 02/2023 -Present Data Engineer
Designed and implemented end-to-end data pipelines on Azure Data Factory to extract the financial data from various sources, transform it using Azure Databricks, and load it into Azure SQL Data Warehouse for analytics purposes.
Utilized AWS Glue for ETL processes, streamlining data integration and transformation.
Managed and optimized data storage and retrieval using Amazon Redshift, improving query performance.
Deployed machine learning models with Azure Machine Learning Services and AWS SageMaker for real-time predictive analytics.
Ensured data security compliance by implementing encryption measures on AWS and Azure platforms.
Automated data ingestion and transformation using Azure Logic Apps, Azure Functions, and AWS Lambda.
Neptune Information Solutions, Bangalore, India 06/2021-12/2021 Data Engineer-Intern
Developed a relational database for Content Management System. Migrated the existing database from MySQL to DynamoDB for an application and handled multiple API calls.
Assisted various application teams in developing backend services using Python, Java, J2EE, and RESTful web services.
Wrote complex SQL queries involving table updates, joins, aggregate functions, and subqueries.
Implemented ETL processes using SQL and AWS Glue. Cognizant, Hyderabad, India 02/2021-05/2021
Data Analyst
Intern role within the data analytics team, delivering insights to optimize business operations.
Designed SQL queries to manage and retrieve data, enhancing data accessibility.
Collaborated with the Data Science team to build predictive models, improving forecast accuracy.
Developed a Tableau-based data visualization solution for the sales team, increasing revenue.
Utilized AWS Redshift for data warehousing, enhancing the efficiency of data analysis tasks. IT Intellect Micro solutions, Pune, India 01/2020 – 1/2021 Data Engineer
Created data transfer pipelines between Azure services and on-premises systems, improving network throughput.
Developed and maintained SQL server stored procedures, views, and functions to optimize ETL processes.
Developed data models to streamline data processing pipelines in the Azure and AWS environments, boosting productivity by 30%.
Enhanced data integration, profiling, and validation by 40%, improving customer outcomes.
Collaborated with Analytics and BI teams to create globally adopted metrics and reporting solutions, reducing manual data analysis.
Automated monthly data purge processes using Azure Data Lake, Azure Data Factory, and AWS S3, reducing storage costs.
ACADEMIC PROJECTS AND ACHIEVEMENTS
Founder and Mentor of “Coding for All” program in undergratuation. This prgram task is to help beginners at Vardhaman College of Engineering to get familiarized with basic programming concepts and conduct weekly discussions on outreach program to learn coding.
Python Machine Learning project to process the data from the previous historical medical records and predict the future scenarios of the patient using Statistics, DataMining, and Machine Learning. EDUCATION and CREDENTIALS
Master of Engineering in computer sciences – University of Cincinnati, Ohio 12/2022 Bachelor of Technology – Vardhaman College of Engineering, India 05/2021
Contact this candidate