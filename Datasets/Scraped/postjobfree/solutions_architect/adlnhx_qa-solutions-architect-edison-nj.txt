Samuel Selwyn
QA Architect
Seasoned QA Solutions Architect with over 13 years experience in testing, specializing in test automation & DevOps QA, test strategies & QA planning, designing open source automation solutions, Performance testing & product performance analysis. Decade long experience working on various development models, specializing in Agile and is a Certified Scrum Master. Worked across multiple domains, including healthcare, banking, education & training, and Media. Has outstanding client management skills working on onshore-offshore models for clients across UK, US & Australia. Deeply interested in learning new technologies & actively performs POCs across industry standard tools.
Skills
Excellent
HP QC, HP ALM, Jira, TFS, Testlink, HP UFT, HP LeanFT, HP Mobile Centre, Selenium, Robotframework, Jenkins, Apium, LoadUIWeb, LoadRunner, LoadImpact, Jmeter, SoapUI, RESTful tools, BDD with Cucumber Excellent
Unix Commands, Python
Excellent
Java, Node JS, TestNG, Maven, AllureReporting, JavaScript, JEST Excellent
AWS & DevOps testing
Excellent
API automation
Excellent
A/B testing
Excellent
QA Management
Excellent
ETL & BigData Testing
Pre-Sales
Middlesex, NJ, 08846
929-***-****
adlnhx@r.postjobfree.com
https://www.linkedin.com
/in/samqaguy/
Excellent
Excellent
RFPs
Excellent
Test Strategy
Excellent
QA Team Building
Excellent
Architecture Improvements
Excellent
Solutions Delivery
Work History
2018-08 - Current QA Solutions Architect
Genisys, New York, NY
Project: Products, Mathematica, Princeton
Duration: 09/19-09/20
Description:
Project involved creating QA practices and solutions for a configurable data driven Case Management & Participant tracking application Highlights:
Built QA practice for client from ground-up. Implemented Test automation solutions integrated to DevOps.
Roles & Responsibilities:
Creating test plan, strategy & test management
Introduced and implemented appropriate tools for QA like Jira, Zephyr, LambdaTest
Designed and created a JavaScript based Test Automation solution for API and Web testing
Worked closely with DevOps to create QA CodeBuilds Worked with DevOps to create QA processes around CI/CDs Project: Verizon Digital Optimization, NY
Duration: 09/18 – 08/19
Description:
Verizon Digital Optimization project is aimed at increasing online sales and conversion through effective A/B testing practices. Hypothesis were presented based on data analytics, experiments were rolled out to select % of users, KPIs measured and the experiment either moved live or rolled off as per Sales and conversion numbers.
Role: QA Manager (Team of 4)
Roles and responsibilities:
Designed and developed test automation framework in-line with A/B test methodologies
Framework of Selenium+Java+Jmeter integrated with Jenkins AWS nodes to simulate traffic to validate split logic of A/B test framework Mentored and coached a team of manual and automation testers Test planning, resourcing and execution
Test reporting and sign-offs
Close co-ordination with Verizon stakeholders, including product SMEs, Test
& Target teams, distributed QA, UAT & Release management teams Designed and developed UI utility to launch A/B test experiments and run sanity automation suites, to be consumed by business stakeholders Key Achievements:
Designed & Built a complete new framework customized for A/B testing & validations
Jenkins integration
Built Java based UI utility for running tests and launching environments by non-tech stakeholders and teams
Trained VZ UAT team on consuming our toolsets
Project: Chuck E Cheese (Booking site & Workday implementations - support & maintenance), Bangalore/Pune/Dallas
Duration: 05/18 – 09/18
Description:
Chuck E Cheese booking site is being utilized by both internal teams and end-users to create and manage party reservations. This project dealt with providing maintenance and support for the booking site. Role: QA Consultant Lead (Team of 7)
Roles and responsibilities:
Managed vendor hand-over for QA capabilities on a recently won RFP, as part of the role, understood current QA practices from the Vendor, collated test artifacts and transitioned QA capabilities to the new QA team that was being built to take over this project, during discovery phase QA resource hiring, mentoring and training for both booking site & Workday projects
Engaged with business and engineering stakeholders from Chuck E Cheese during transition till steady state phases
Reviewed current QA practices/frameworks and built proposed process changes and new QA automation framework as part of the RFP Selenium/Java based GUI and API automation framework was built and demonstrated to Chuck E Cheese executive team
Ran sprints successfully and hand over QA to the newly hired QA lead Periodic review of QA activities as part of Genisys's QA competency lead Key Achievements:
POC & implementation on a custom test automation framework for GUI & API testing
Built a team of QA engineers from hiring to transitioning Successfully moved QA from Discovery to Steady state Added Jenkins and Browser-stack capabilities within the QA framework Implemented boards and sprints in VSTS
2013-01 - 2018-08 Test Manager/QA Competency Lead
Genisys, Bangalore, India, India
Project: AgriaPet Performance Tuning
Duration: 03/18 – 05/18
Description:
AgriaPet is a pet insurance web-application. It allows users to create contacts, add pet information, create quotes with the available insurance options for the pet, make a sale and generate Insurance policies. It also allows users to search policies, make claims and generate documents. The application had poor performance and the QA team with the Performance engineering team were engaged to identify bottlenecks and make fix recommendations.
Role: Performance Lead (Team of 3)
Roles and responsibilities:
Analyzed the application and created a test strategy Identified high impact scenarios and workflows
JMeter scripts preparation for both UI, API and MixedLoad scenarios Setting up parameterizations, cache, cookie and header managers Set up Perfmon monitors on all applicable servers
Setup required listeners to capture response time and other metrics Created shell scripts to automate report generation Report analysis
Performance profiling with DB architects
Identifying bottlenecks, long running queries, indexing issues Final report submission
Key Achievments:
Recommended test infrastructure for performance testing Mentored and coached a team of junior QA engineers to effectively create and run performance tests
Worked closely with DB architect in troubleshooting and identifying performance breakdowns
Provided scientific data to prove current system performance and recommended improvements
Project: Critical Mention CTV, Syndicaster TV & ClipSyndicate Duration: 06/13 – 07/18
Description:
Critical Mention is the leading global media monitoring service. They give subscribers access to real-time search results from TV and radio stations on four continents. Subscribers can view video seconds after it airs, edit clips, share coverage, create automated alerts and easily create reports containing high quality video and powerful analytics.
Critical Mention captures and indexes 40 hours of broadcast content every 60 seconds from more than 2,000 unique broadcast sources producing a robust database of more than 16 million searchable segments, all available in broadcast quality definition and in real-time.
HW/SW/Technology:
RESTful webservices, Lucene Query testing, Python, Selenium with Robot Framework, Google Docs, Cygwin, PowerCMD, JSON Visualizers, Redmine, LoadImpact, JMeter
Role: Test Manager and Project Manager (Team of 10) Roles and responsibilities:
Involved in all testing phases of SDLC life cycle in sectors like eLearning, Healthcare, Banking & Media with specialized focus on requirements engineering & test management
Worked closely with client teams and business analysts in gathering requirements
Extensively worked in Test planning & Strategy
Extensively worked in developing project plans & timelines Extensively worked in design & development of automation practices & frameworks
Built Selenium/Robotframework Python based Automation framework that supports GUI/API testing & integrated with Jenkins CI Built Performance testing solutions using JMeter and integrated with the Automation test framework, and Jenkins CI to measure performance standards across releases
Extensively worked in gathering & evolving performance goals, design & development of performance test practices
Extensively worked on building Test Competency groups within organizations by envisioning/building roadmaps, industry standard tools POCs, Design team participant for HP Automation tools, training & mentoring test engineers
Handled multiple projects and worked with multiple departments such as Account Management, Support, Datacentres, Content Engine, TechOps, Solution Engineering & Development teams to review Requirements, Project Test Scoping, Scale/Capacity planning, Incident management, change management, Release planning, 3rd Party UATs and Test Management as a Project/Test Manager
Managed Delivery Support for clients in US
Managed 10 member QA team
Managed Product Support Team of 5 in India
Key Achievements:
Transitioned the account from being managed by client to being a quality partner and owner of quality for the client's suite of products Increased team size from 3 to 10 with consistent high quality deliverables Added a team of support engineers due to the level of knowledge base that was built during the initial engagement
Built test automation that has 60% regression tests automated Built open source Performance test solutions that automatically measured performance against defined benchmarks release on release, with JMeter and Jenkins jobs
Part of the journey that propelled Critical Media to be the top media monitoring organization in the US
Built one of the most long standing and successful client relationship in Genisys
Built efficient junior engineers over a span of 5 years who transitioned into successful senior QA roles
2010-03 - 2012-09 Test Lead/Senior Test Engineer
HCL Technologies
Project: Core Banking Modernization End to End Pricing Testing R 28.0 Description:
R 28.0 CBM Pricing involves testing Line of Credit and Term Loan accounts in terms of Pricing arrangement setup on the account. The applicable interest rates and fees are setup on a loan account either during origination or during maintenance. Testing involves setting up and verifying the interest and fee charged on an account from the front end application Commsee, the web user application Finest Online, middleware IFW and backend SAP. HW/SW:
HP Quality Center 11, SAP, IFW Test Harness, Excel 2010 Role:
Offshore Test Lead
Roles and responsibilities:
Requirement study and walkthroughs on the latest DOOR requirements and Functional spec documents with the Business and Technical analysts. Preparation of SIT and E2E Test Scenarios and Test Cases. Peer review on the prepared test items.
Reporting test preparation status to the Client onshore and ensuring deadlines are met.
Ensuring RBSD methodology is applied on test preparation phase according to the Risk and Priorities of the Requirements. Uploading Test Scenarios and Test cases into Quality Centre 11 using Excel Macros. Providing Test Coverage reports from QC and ensuring all requirements are mapped to a test case.
Filling-in QC Test lab with the appropriate test cases according to the products to be tested and creating test sets for ST, SIT, E2E and Regression testing.
Maintaining status reports on the various shakedown testing performed as and when a build is available.
Assigning test cases to the team offshore according to the delivered and available functionalities and ensuring targets are met based on RBSD Methodology.
Preparing status reports from Quality Center on the execution status and progress.
Interacting with the Client and Business team on the blocking issues and targets to be achieved.
h Preparing ‘Progress t report’ on i the ‘Not completed’ w and ‘No Run’ tests
. ‘Reasons’ and sharing with the Client and Business for further Action Logging defects on execution and Maintaining Open Defects Filter for reporting purpose.
Sharing Execution and Open defects report to the Client on a Day-Day basis using Quality Centre and Excels.
e Ensuring test execution is done to meet “Earned Confidence” target as th project nears release dates.
Sharing Deferred defects and De-scoped test item list to the Client to be tested on future dated patch releases.
Assisting the team on execution as well using SAP and future dated Environments.
Reporting project metrics to the Managers offshore. Estimating Change requests in terms of test items to be prepared and executed and share with the team for preparation and execution. 2007-12 - 2010-02 QA Associate
Sify Software, Chennai, India, India
Project: Novartis Saba, GE MyLearning, NetApp Saba LMS Applications Deployment Testing
Description:
This short term deployment testing is done to evaluate the product in the r production server. The ‘Training’ program is moved into the Production server o into the clients LMS. This in turn is routed to our end where we test if the Product works fine as expected, the Certificates are generated on Completing/Passing the Modules, and these reports are sent or retained in the LMS for evaluating the user. The login sessions of the user is recorded, the history of his training retained for further evaluations. The user has the flexibility of taking the program in his own pace so the bookmarking retentions of the program is vital. All these features are tested on various platforms or LMS instances.
HW/SW:
ORT – Online Review Tool
Role: QA Associate
Roles and responsibilities:
Functional and behavioral testing on the product in the production environment
Defect tracking and reporting
Defects closure and Sign off on the Production/LMS release Discuss and update behaviors of different LMS platforms Verify the Client reported bugs/issues using the Test LMS as a platform that replicates real time client end platform
Project: Novartis FLM Simulator
Description:
d Novartis – FLM Simulator – This is a Desktop based application primarily focuse on the Pharma Sales personnel of Novartis. This Application has various features and resources that a sales person can use to increase his sales ability and generate revenues on a Quarter – Quarter basis. The Application basically simulates real time scenarios and evaluates revenue generated by the Sales team based on their performance and skills.
HW/SW:
ORT – Online Review Tool
Role: QA Associate
Roles and responsibilities:
f Creating test cases for various scenarios related with the ‘Training Needs’ o the Sales person, based on the Functional Document Initial Smoke testing on the build, executing test cases for Functional testing on the Module
Defect tracking and reporting
Defects closure and Sign off on the particular module Attend status meetings and team discussions on a monthly basis Re-validated and verified client modifications made in the Application post releases
Ad-Hoc testing on the application
Education
Bachelors Degree: Electronics & Instrumentation Engineering Certifications
Agile Certified Scrum Master
Interests
Running, Traveling, App Designing & Hobby Drummer
Industries
Education & Training (GE, SABA)
Healthcare (Novartis, Pfizer)
Banking & Insurance (Commonwealth Bank of Australia) Media (Aegis, Critical Media)
AgriaPet (Insurance)
Chuck E Cheese (Entertainment)
Verizon (Telecom)
Contact this candidate