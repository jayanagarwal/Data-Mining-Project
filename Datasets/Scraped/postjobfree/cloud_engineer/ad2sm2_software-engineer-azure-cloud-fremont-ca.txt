DINAKAR VEERAMANENI Sr Staff, Software Engineer

Fremont, California ad2sm2@r.postjobfree.com

Qualification Summary

20+ years of experience in System Analysis, Design, Architect and Development for Data Warehousing, Data Integration, Data Migration and developing customized applications using Python, Java, Big Data and Azure Cloud

KEY SKILS

Azure Cloud
Big Data
Kafka
Hive
Python
React
ExtJS
Java Script
Data Warehousing
Data Pipelines
SQL
ETL (Data Stage)
Databricks
Redshift
Spark

Summary:
Developed products that allow for collecting, sharing, and analyzing data from customer interactions across all Gap Inc digital touch points, create tools to better understand and curate the customer journey with quality data.
3+ Year of experience in architect and develop real-time steaming using Kafka. Processing 1 TB data daily and processed 1 PB historical data
Hands on experience with Microsoft Azure Cloud services, Virtual Networks, SQL Azure, ADF, Storage, Azure Active Directory.
Developed ETL framework for single Access point, less grants to issue, no wrapper code deployment. Multiple concurrent sessions maintained through Espresso. Additional parameters may be passed by Espresso with out changing the code base.
Excellent problem-solving skills, self-motivated, hardworking, ability to work independently or cooperatively in a team, eager to learn, ability to grasp quickly, excellent team player.

EMPLOYMENT EXPERIENCE:

Gap Inc.
Sr. Staff software Engineer June 2014 – Current

Roles & Responsibilities:
Led the team and hand on building following products
oGDP: Company strategies to bring all the data into one single platform with one architectural design. We are responsible for landing Adobe clickstream data into the GDP base structures and validating completeness and accuracy using spring batch & Kafka.

oMission Control/Digital Forecast Reporting: Digital Forecast Report enable our digital teams to assess digital (web & mobile app) key performance indicators against forecast in real time.

oWeb SDR: Library for all Tealium data layer variables and events and corresponding Adobe Analytics tag variables used across Gap Inc digital properties. All brands, all markets, organized by page type/product team

oTest Automation Framework: This tool provides the capability to automate and simulate user actions on a web page (such as clicking elements, completing web forms, navigating throughout the page) with the purpose of automating manual tests and saving manual effort.

oDQ Framework/Reports: DQ framework will allow to compare the metrics, extracted from different sources based on the business needs. We use this framework to compare data between Adobe, Tealium and Venus and send the reports

Gap Inc.
Sr Software Dev Engineer September 2011 – June 2014

Roles & Responsibilities:
Led the team and hand on building Gap customer database (customer 360) for effective & targeted marking to reduce marketing expense using PLSQL and shell script
Developed Audit Controls and Data Validation reports using Shell Scripts, Stored Procedures to audit the data at several different stages that is Auditing the data at Source systems, Staging, Data Warehouse and Data mart.
Performed in depth analysis of the source system and worked with the users, business analyst for understating the business requirements.
Participate in design reviews and recommend improvements.
Implemented most effective technical solutions to meet business requirements.
Worked with other Engineers in planning, prioritizing and executing assigned tasks within deadlines.
Recommended new technologies to ensure quality and productivity.
Designed & documented ETL process according to business requirements and followed the Gap Functional and Technical Design document standards.
Conducted Functional Design and Technical review sessions with the project team.
Provide trainings and mentor other Engineers when required.

IBM
Senior Advisory IT Specialist March 2006 – September 2011

Roles & Responsibilities:
ETL Lead in managing multiple ETL projects simultaneously of varying complexities. Responsible for technical design as well as technical development of all ETL projects.
Developed shared containers and routines to capture the errors and error handling purpose.
Developed complex ETL jobs to migrate the 3 TB data from Teradata to Oracle including complex business rules.
Extensively involved in fine-tuning existing applications using PL/SQL and Datastage.
Used oracle stored procedures to improve our daily process of sending data to external systems. Implemented new stored procedures in daily process as well as projects when necessary to transfer data to downstream systems and/or to update/change existing data within our database.
Extensive experience in Oracle Database Administration
Strong scripting skills with an emphasis PL/SQL coding, backup & recovery process.

Gap, Inc.
Lead Data Warehouse Engineer March 2000 – March 2006

Roles & Responsibilities:
Technical Team Lead for all aspects of the Data Warehouse Projects and/or application enhancement. Responsible for the Analysis, Design, Construction, Testing, and Implementation of projects using Software development life cycle.
Experience in developing and implementing complex Data Conversion, Data Migration projects using Ascential DataStage with Teradata, DB2, Oracle, SQL Server.
Involved in tuning the complex Data Warehouse systems and queries to improve data load times and end-user data access response times by using various ETL utilities to improve processing times.
Provided 24x7 support for our web reporting systems. Provide support and coordination to monitor and troubleshoot off-hours batch processing activities.
Contact this candidate