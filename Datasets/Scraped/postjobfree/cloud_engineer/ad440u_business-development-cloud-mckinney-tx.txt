Srikanth Anjuri
AWS Cloud Engineer
+1-469-***-****
Linkedin: srikanth
ad440u@r.postjobfree.com

Profile Summary
1.Having 11 years of demonstrated IT Experience in Cloud computing, Security, and DevOps. Implementing cloud strategies based on Enterprise requirements
2.Understanding client's requirements and preparing RFI, RFP, RFQ responses for Cloud projects as part of Pre-sales activity
3.Presenting sales & technical pitches for organization offerings to the CIOs/CXOs of prospective clients
4.Having pretty good expertise in Alliances/Marketing/Business Development and handling all Pre-Sales and Post-Sales activities
5.Cost-optimized for a Legacy Health care Application, saving $23,236.96 by redesigning the AWS Infrastructure as per the AWS Well-Architected framework
6.Experienced in cloud infrastructure, Microservices, and IoT Architecture designs patterns
7.Completed Production environment setup in less time than expected for this applauded with High-Five Award
8.Good hands-on knowledge in Terraform, CloudFormation, Jenkins, Ansible, Docker, Kubernetes
9.Expertise in automating builds and deployment process using Bash, Python and Shell scripts with focus on CI/CD leveraging cloud DevOps services
10.Expertise in DevOps, Release Engineering, Configuration Management, Cloud Infrastructure, Automation and migration
11.Designed stacks using Amazon Cloud Formation Templates to launch AWS Infrastructure and resources
12.Comprehensive experience on detail and summary reports including line and pie charts, trend analysis reports and sub-reports according to business requirements from Quick Sight
13.Knowledge of SDLC, Agile, ITIL,CISSP and CCSP

Technical Skills

Continuous Integration/deployment
Jenkins, AWS DevOps services, GitHub actions, Gitlab Pipelines
Operating Systems
Ubuntu, Red Hat Linux, Windows, Centos
Databases
Amazon RDS, AWS DynamoDB, MySQL, SQL Server, Oracle, NoSQL, Mongo DB,Redshift, Elasticcache
Build Tools
Maven, AWS Codebuild, ANT, Gradle
Cloud Environments
AWS, Azure, GCP
Version Control/Repository
GIT and GITHUB, Codecommit, Azure repos, Gitlab
Containers and orchestration
Docker, Docker swarm, Kubernetes, Helm,
Application & Web Servers
Nginx, Apache Tomcat, HTTPD
Programming Languages/Scripting
Python, Bash/Shell scripting
Monitoring/Infra Management
Cloud Watch, Nagios, Grafana,,Zabbix,Prometheus, N2WS,Zabbix,ParkMyCloud,Sophos,Commvault,Nutanix
DS Language
JSON, YAML
Configuration Management Tools
Ansible, Ansible Tower, Chef
Infrastructure provisioning tools/ IaC
Terraform, CloudFormation, AWS CDK, AWS SAM, AZURE ARM
Ticketing Tools
Jira, Azure Boards
Testing/Code Quality
SonarQube, ECR Inspector

Educational Qualifications
•Bachelors in technology degree from Acharya Nagarjuna University in 2013, India

Certifications
•Certified Kubernetes Administrator-CKA
•AWS Certified Solutions Architect - Associate
•Azure Administrator Associate AZ-103
•Azure DevOps Expert certification AZ-400
•Azure Security Technologies AZ-500 and among others

Projects
Client: Publicis Media-Seattle, WA, USA Apr 2023 - Present
Role: Team Lead
Responsibilities:
•Designed and implemented Terraform configurations to provision and manage AWS infrastructure resources, including EC2 instances, S3 buckets, RDS databases, VPCs, subnets, and IAM roles
•Utilized Terraform's AWS provider to interact with AWS APIs and automate the deployment of infrastructure components across multiple AWS regions and availability zones
•Automation of SSL certificates for IIS servers in AWS and Azure using PowerShell
•Leveraged N2WS, ParkMyCloud and Commvault for servers automation and backup
•Leveraged Zabbix for timely monitoring of Multi-cloud servers
•Maintained Security hardening in the application development cycle Streamlined application deployments
•Implemented monitoring and alerting solutions to track the progress and health of data migration jobs, proactively addressing any issues that arose during the migration
•Creation of catalog database tables for Athena for fast querying S3 data (more than TB) and setting up for query performance at Athena without moving data into Redshift
•Creation of Role based permission and creation of bucket policies to appropriate access to user
•Define enterprise data information architecture principles, policies, standards,procedures and documentation
•Extensively used Launch configurations and Auto Scaling to provide high availability to EC2 machines and effectively used scaling policies based on web traffic inside VPC
•Worked on S3 buckets like version control, Life cycle management, Cross-region replication
•Monitored server and network systems health and respond to incidents
•Setting up monitoring and logging solutions to track the performance and health of systems and applications, enabling proactive identification and resolution of issues

Environment:KeyVault,Elasticache,EventBridge,SystemsManager,PatchManager,TrustedAdvisor,DMS,ECS,EKS,Event Bridge, Config, Azure Functions and among others
Client: Publicis Media- Seattle,WA,USA April 2021 to Apr 2023
Role: Module Lead
Responsibilities:
•Estimation, design, building, and managing the infrastructure environments needed for the projects in the AWS
•Leveraging AWS Cloud Formation designer templates or Terraform for automation of infra
•Regularly monitor, research, and analyze ways in which the services in AWS can be leveraged for Application enhanced performance
•Managed network intrusion protection and prevention using Sophos
•Configured SNS notification at Auto Scaling as well as Route-53 level to get notifications when server and VPC failures respectively
•Setup Databases on Amazon RDS. Monitoring servers through Amazon CloudWatch, SNS
•Experienced in deployment strategies - CI/CD, Elastic Beanstalk, code commit, build deploy and Code pipeline
•Used Microsoft Azure portal to manage Virtual Networks, Virtual Machines, Blob storage and databases
•Designed solution for various system components using AWS and Microsoft Azure
•Created, managed, monitored VM using Azure portal admin
•Configured RDS instances using Cloud formations and Terraform, also used Terraform to map more complex dependencies and identify network issue
•Extract, transform and loading data from multiple sources into Elastic Search, Dynamo DB and Redshift
•Involved in designing and evaluated several cloud formation templates to implement whole AWS infrastructure
•Design and architect data platform to deliver a scalable model for future growth needs
•Designed and implemented scalable data architectures, ensuring optimal performance and reliability
•Implemented data security measures, ensuring compliance with data privacy regulations
•Designed Successful Data Migration approach using AWS DMS for infrastructure migration to Cloud environment
•Responsible for creation and implementation of AWS security guidelines and storage mechanism
•Managing security groups on AWS, focusing on high - availability, fault tolerance, and auto-scaling using Terraform templates and also Hands on experience in Architecting Legacy Data Migration projects such as Teradata to AWS Redshift, AWS Cloud from on-premises
•Ability to identify and gather requirements to define a solution to be built and operated on AWS
•Configured Inbound/Outbound in AWS Security groups according to the requirements

Environment: AWS API, AWS DMS, AWS Cloud, Autoscaling, ApplicationLoadBalancer, AMI’s, AWSMarketplace, S3, CRR, GitLab, GitHub, SNS, SQS

Client: H2H Solutions-Youngsoft-Wixom,MI,USA Oct 2019 to April 2021
Role- IT Infra Engineer-AWS

Responsibilities:
•Extensive experience working with setting up and implementing elastic search, kibana, glue, log stash, emr, s3, RDS, ec2, Sage maker, sqs, iam
•Provided solution architecture support for project development and maintenance activities
•Perform advance analytics and create machine learning models using Google cloud vision APIs, AWS sage maker, biq query and AWS/google cloud other artificial intelligence services
•Configuring the Continuous integration and Deployment (CI/CD) of the code on to AWS cloud
•Configured and managed various AWS Services including EC2, RDS, VPC, S3, Glacier, Cloud Watch, Cloud Front, and Route 53 among others
•Configured various performance metrics using AWS Cloud watch & Cloud Trial
•Collaborated with data analysts and scientists to provide reliable and optimized data solutions
•Conducted performance tuning and optimization of data processes to enhance system efficiency
•Participated in the design and implementation of data governance and data quality frameworks
•Assisted in troubleshooting and resolving data-related issues, ensuring data integrity and availability
•Responsible for configuring and securing the infrastructure on AWS Cloud
•Collaborate in the automation of AWS infrastructure via terraform and Jenkins - software and services configuration via Ansible.

Environment:AWS,GoogleCloud,Python,UNIX,Windows,ShellScripting,AWSDevOps,Nginx,EC2,EBS,ELB,ACM,RDS,IAM,CloudTrail,VPC,WAF,ACS,CloudWatch,Route53,MySQL,MySQLWorkbench

Client- SIHO - Columbus, IN Mar 2017 to Oct 2019
Role- Software Engineer
Responsibilities:
•Upgrading/Patching Production Environment servers for Stability and Security
•Implementing CI/CD Pipeline using Jenkins, Bamboo, and GIT
•Created VPC from the scratch and connected to network by using Internet Gateways, Route tables, and NATs
•Created many public and private subnets for proper segregation of webservers and database servers to provide high level security
•Extensively used Launch configurations and Auto Scaling to provide high availability to EC2 machines and effectively used scaling policies based on web traffic
•Enabled CRR (Cross Region Replication) to replicate data to other buckets which are present in different regions
•Worked on S3 bucket like version control, Life cycle management, Cross region replication
•Administered users, groups and setting up of policies by using IAM
•Enabled VPC Flow logs for the auditing purpose to track incoming and outbound traffic to and from VPC
•Used roles mainly to establish password less connection between S3 and EC2 for the data migration to and from
•Created alias record sets to provide alias names for load balancers DNS name
•Configured routing policies to provide high availability at region level and protects the infra from regional failure
•Worked closely with development teams to integrate their projects into the production AWS environment and ensure their ongoing support to ensure efficiency and effective outcomes

Environment: DevOps, Redhat, ElasticSearch, EC2, Azure Functions,VPC,Virtual Machines, Cloud Formation, AWS, AKS, Containers, ARM, Ant, GIT, MySQL

Client- Kohler Apr 2013 to Feb 2017
Role: Associate Software engineer
Provided IT support to more than 300 End-users through the ticketing system in addition to Handling tickets for clients, Hassle-free work experience saving time is like a spin-up of net profit to the organization
•Installed various software in client machines remotely
•Maintained Kaspersky Endpoint Protection Antivirus Server and Sophos Endpoint Agent UTM
•Documented and maintained supply of all required inventory
•Administered Chrome OS IT, Maintaining Email ID’S of employees and Smart entry details
•Created Snapshots to take back up copy of our EBS volumes.
•Created AMIs and Volumes and played with them like attaching, detaching, creating own AMIs for replication of same environment in same/different Availability Zones as well as same/different regions.
•Encrypted volumes to provide security from unauthorized access and misuse of data and provide protection from accidental deletion of machines
•Created SNS notification at Auto Scaling as well as Route-53 level to get notifications when server and VPC failures respectively
•Configured cloud watch alarms to get alert whenever any untoward situation arises which helps in addressing issue immediately time saved
Environment: S3, Windows and Chrome OS, AMI, SNS, CloudWatch, EBS, WinSCP, Shell Scirpting, Unix
Contact this candidate