Ugochukwu Obunadike Cell = 716-***-****
BSc, MS
ad0rcs@r.postjobfree.com
Data Scientist
Professional Summary
• Results-oriented and visionary Data Scientist with over 8 years of experience spanning across different sectors. I have provided recommendable solutions to fortune 500 companies as a consultant.
• Skills include business analysis, marketing analytics, exploratory data analysis, Business Intelligence reporting, data manipulation, statistical analysis, predictive analytics, data mining, machine learning, A/B testing, and data visualization.
• Demonstrate end-to-end ownership of projects involving translating business requirements to data analysis, designing algorithms, developing models, visualizing data, and designing reporting solutions.
• Possesses a working knowledge of cloud platforms such as Amazon Web Services (AWS) and Microsoft Azure, utilizing these skills for various data extraction, cleansing, model deployment, and validation tasks.
• Demonstrate a keen aptitude for cloud technology, working extensively on Google Cloud projects to support key functions, including data extraction, cleaning, model deployment, and validation, among others.
• Proficiently leverages Azure Data Lake and Azure Storage capabilities for enhanced data analysis, verification, cleansing, and migration.
• Possesses expert-level skills in data analysis, validation, and cleansing, with a particular focus on verification and migration processes, designed to support robust analytics pipelines.
• Strong knowledge of machine learning algorithms including linear regression, logistic regression, Random Forest, XG Boost, Naïve Bayes, SVM, K-means, K-nearest neighbors, dimensionality reduction
• Built multiple models using Convolution Neural Networks (CNN), Recurrent Neural Networks (RNN), LSTM using TensorFlow and Kera
• Experience of working across the analytics spectrum – descriptive, predictive, and prescriptive analytics
• Worked extensively on SQL queries, experience in working on SQL servers, Oracle and NoSQL databases such as HBase, Cassandra and MongoDB
• Proficient in Python libraries such Pandas, NumPy, Scikit-learn, Matplotlib, Seaborn and TensorFlow
• Build robust CI/CD and MLOps pipelines for model deployments, automations, parameter tracking, and version control, utilizing the latest technologies to manage complex analytics workflows with ease.
• Work extensively with cross-functional teams to identify critical business requirements, develop solutions, and deploy models that enable proactive decision-making supported by robust data insights.
• Leverage deep data analytics skills and machine learning expertise to enable effective predictive modeling, implementing best-in-class solutions that support data-driven decision-making and drive overall efficiencies.
• Demonstrate superior communication skills, providing clear and concise reports to stakeholders across teams, aligning technical methodologies with broader goals and objectives. Primary Skills
Python, R, SQL, Machine Learning, Azure, Snowflake, AWS Tableau, Power BI, Qlikview, Deep learning, Artificial Intelligence Data Science
Time series, Forecasting, Linear regression, Logistic regression, Decision Trees, NaïveBayes, Random Forest, SVM, Neural Networks, Sentiment Analysis, K-means, K-nearest Neighbors
(KNN), Ensemble methods, XG Boost, Principal Component Analysis (PCA) Domain and Functional Retail, Health and Finance. Migration, Production and Pipelines Tools Data Science tool: CDSW, AWS Sagemaker, R, Azure Databricks, Jupyter Database tool: Snowflake, Hadoop, SAS
Data Engineering tool: Snowflake, Databricks
Vizualization tools: Tableau, Qlikview, Python, R, Plotly, Power Bi IDE Tool: Visual Studio
Repository: Microsoft Azure, GitHub
Version Control tool: GIT
Other Utilities: Jira, Spinnaker, Azure (ADO, Kubernetes, App insights) Educational Background
BA – Political Science. Masters of Science – Econometrics Experience
Cognizant Technologies- (Albertsons) (June 2021 – September 2023) Senior Data Scientist,
• Consultant for Nationwide Retail company – Focused on building models that tackled– chargebacks, promo abuse, customer evaluation and data governance.
• Built data science self-service environments, developing analytical and analytical models with a strong focus on AI and predictive forecasting.
• Defined labels in training datasets, understood and documented spread of labels for Exploratory analysis using Python and SQL in Machine Learning and Hadoop platform.
• Built robust CI/CD and MLOps pipelines for model deployments, automations, parameter tracking, and version control, utilizing the latest technologies to manage complex analytics workflows with ease.
• Understand distribution of features, categorize fields, perform A/B testing on features related to labels and then develop complex features by transforming basic features all on python language.
• Create ETL pipeline for training data, created ETL pipeline for lookup tables, and for gathering core source data for model. Utilizing CDSW, Hadoop and Bitbucket.
• Optimized existing ML and deep learning models to improve accuracy and eliminate overfitting.
• Analysed sales data by product, geography, customer segment, and other variables to understand which products are seeing a decline in sales and which markets are underperforming.
• Identified factors that may be contributing to the decline in sales, such as a decrease in marketing spend, changes in customer preferences, or increased competition through analytics.
• Created interactive dashboards and reports to share findings with stakeholders, such as the sales, marketing or executive teams.
• Azure databricks expertise – creating job clusters, multi-purpose cluster, versioning and optimizing SQL dashboards.
• Collected data from diverse sources such as Azure SQL Database, created Spark clustering in Azure Databricks, transformed data into the target format, and stored data into destination storage in Azure to enable proactive analytics insights.
Environments – CDSW, Apache Hadoop, Snowflake, Databricks, MLOps, BitBucket, Git, Unix, CI/CD, Azure M &T Bank, Buffalo, New York and Remote
(October 2019 to June 2021)
Data Scientist – Contract
• Architect modern Artificial intelligent solutions using visual agents, visual analytics and deep learning Build ML model with yearly data with Python utilizing packages like Pandas, Numpy, Scikit, Scipy, Keras and XGBoost.
• Built machine learning models utilizing Python and essential libraries such as Pandas, Numpy, Scikit, Scipy, Keras, and XGBoost to analyze yearly data and provide insights to the business.
• Conducted data cleaning and pre-processing processes to ensure data suitability for accurate analysis to identify trends and patterns that positively impacted business decisions.
• Conducted analysis about trends in social media sentiment by date, time, platform, and other variables to understand how the perception is changing over time.
• Conducted sentiment analysis on data collected from various sources to quantify positive, negative, and neutral mentions of the brand. Leveraged analytics techniques to use this data to inform brand perception and image-related decisions proactively.
• Utilized Tableau and Excel dashboards, ad-hoc reporting features, and analytics tools such as QlikView to provide critical insights and analysis of financial data.
• Architected and developed modern Artificial Intelligence solutions using visual agents, visual analytics, and deep learning, building highly accurate Machine Learning models that provided valuable insights to support strategic decision-making.
• Collecting data from multiple data sources such as Azure SQL Database, then creating Spark clustering in Azure Databricks to transform data into target format and storing data into destination storage in Azure.
• Deployed well trained models to Azure machine learning, and automated ETL and model predictive analysis as a complete workflow by using Airflow.
• Identified valuable data sources, conducted vendor landscaping and technology assessments before building AI platform pipelines, ensuring analytics excellence and data security. Intertek, Detroit, Michigan (October 2018 to October 2019) Data Scientist – Contract
• Worked extensively with a Fortune 20 company, contributing over half a year to developing and deploying statistical programming and analytics solutions using cutting-edge technologies such as Splunk, Spark, R, Core Python, Bayesian methods (naïve and belief networks), Artificial Intelligence methods, predictive analytics techniques, linear programming models (prescriptive), and clustering.
• Implemented sophisticated Machine Learning (ML) solutions using advanced text mining techniques, market basket analysis, and sequence analytics to uncover valuable insights.
• Used Python programming language to create visually appealing graphs and charts that provided key business insights, while also analyzing data properties for measures of central tendency or dispersion, drawing on tools such as Tableau, Power BI, and Matplotlib for effective data visualization.
• Collaborated with development teams, utilizing expert analytics and data science experience to support comprehensive API roadmap development and implementation.
• Collaborated with stakeholders to identify data requirements, clean and pre-process data, develop robust analytics models and solutions to support better decision-making and produce valuable insights.
• Spearheaded the development of a sophisticated Data Science self-service environment in the cloud, ensuring ease of use and accuracy of output.
• Enhanced forecast analytics tasks using Python, drawing on essential libraries such as Numpy, Matplotlib, and Pandas to deliver robust, actionable data-driven insights.
• Possess expert knowledge of various tools, including R, Python, SAS, Tableau, Power BI, Elastic Search and others, leveraged to develop, visualize, and deploy effective machine learning and statistical algorithms for businesses to achieve maximal results.
Environment: Python, R Studio, R-Shiny, SQL, AWS, Azure, Tableau, ELK, Splunk, Data Science Studio, Elastic Search, Logstash and Kibanna (ELK)
Smart Save Supermarket Ltd, San Jose, California (September 2017 to October 2018) Data Scientist
• Demonstrated excellence in utilizing deep learning algorithms, visual agents, visual analytics, and other analytics techniques to design modern AI solutions that effectively address complex business challenges.
• Assessed the scope and scale of project based on current and future scope of project.
• Forecasted Average weekly demand using historical demand data and calculated safety stock, cycle stock and max stock across all nodes (Hubs, stores, etc) based on predictions done with python packages.
• Built MinMax, LSTM, ARIMA, Naive machine learning models and sent results back to local databases.
• Demonstrated proficiency in a wide range of analytics tools, including R, Python, Microsoft Excel, Tableau, MySQL, SQL Server 2005/2008, and Oracle, to perform in-depth data analysis and provide valuable insights to the business.
• Leveraged deep data analytics skills and machine learning expertise to enable effective predictive modeling, implementing best-in-class solutions that support data-driven decision-making and drive overall efficiencies.
• Extract data to identify device flows across various nodes and defined flow direction based by creating business rules.
• Computed parameters based on customer flows of each device.
• Build machine learning models using SVM, Logistic regression, Random forest algorithms to predict devices likely to be lemons (faulty device) prediction.
Environment: AWS Aurora, S3, Glacier, EMR, Python, Spark, Azure, Rest API, Linux, Hive, PrestoDB, MariaDB, SQL Server, Tableau.
Best Buy, Buffalo, New York
(July 2015 to September 2017) Data Scientist
• Developed machine learning solutions with a strong focus on analytics, leveraging technologies such as XGBOOST classifier models to identify potential promo abusers.
• Designed Excel and Tableau dashboards for higher management reports, and other data visualization reports as per the needs of the user to measure KPI. Frequently prepared ad-hoc reports using Microsoft Access and Excel.
• Performed Data Analysis using QlikView, Tableau software to analyze financial data. Environment: R, Python, Microsoft Excel and Access, Query Analyzer, SharePoint, Office 365, Tableau, MySQL, SQL Server 2005/2008, PL/SQL, Oracle, UNIX, Windows
Amherst Democratic Committee Internship, Buffalo, New York (June 2013 to August 2014) Data Analyst
• Part of the campaign team, where analyzed voting data, patterns and recommended awareness strategy.
• Created Tableau scorecards, dashboards using Stack bars, bar graphs, scattered plots, geographical maps, Gantt charts using show me functionality.
• Worked as Data Architects and IT Architects to understand the movement of data and its storage and ERStudio9.7
• Processed huge datasets (over billion data points, over 1 TB of datasets) for data association pairing and provided insights into meaningful data association and trends.
• Participated in all phases of data mining, data collection, data cleaning, developing models, validation visualization and performed Gap Analysis.
Contact this candidate