SUMMARY OF QUALIFICATIONS
Over ** year experience as Systems Analyst / Solution Architect / Data Architect / Application Developer / Database Developer / Data Modeler / Data Analyst / Data Governance / ETL / DW and BI Consultant in client-server and mainframe applications with an excellent delivery record of projects & system support
Application Development experience with full understanding of SDLC including Data Architect - logical / physical data modeling, development of strategy, gather functional and non-functional business requirements, analysis, coding and developing, maintenance and enhancements
Experience in Oracle application and database design, development, configuration, implementation and testing, creating and optimizing all database objects included materialized views, stored packages / procedure and functions, database triggers, synonyms, sequence, object type, user profile and roles
Over 7+ years of work experience in Business Analysis and Data Analysis in Financial industry. Specialized in Implementation of Financial Tools, Data Governance, Data Lineage, Data Quality, Project Financials, Budgets, Forecasts, Costs, Benefits, Requirements management, user acceptance testing, Change Management, Reporting and SQL
7+ years in Information Technology with Expertise in Data modeling for Data Warehouse/Data Mart development, Data Analysis for Online Transaction Processing (OLTP) and Data Warehousing (OLAP)/Business Intelligence (BI) applications.
Experience with Oracle BI, SQL including intermediate to advanced knowledge on DML / DDL
Experience in using Talend Data Integration Suite (7.3/8.0), Talend Open Studio and Talend Admin Console (TAC), created mapping in Talend, using Talend features, monitoring and scheduling jobs
Experience in Microsoft Power BI Desktop, Data visualization and modeling, Data query language: SQL, DAX, Data warehousing and analytics
Experience in creating Data Governance Policies, Business Glossary, Data Dictionary, Reference Data, Metadata, Data Lineage, and Data Quality Rules
Experience with data management technologies and tools such as MDM and Informatica Powercenter
Experience in Oracle ERP R12 Implementation (AP, AR, GL, CM) and Seibel Case Management & Oracle SCM
Experience in SAP HCM Implementation (OM,PY,PA,EN,TM)
Experience in Data Extraction, Transformation and Loading of data from multiple data sources into target databases using Azure Databricks, Azure SQL, SQL Server and Oracle
Extensive experience in Relational and Dimensional Data modeling for creating Logical and Physical Design of Database and ER Diagrams using multiple data modeling tools like ERWIN
Proficient experience in working on conceptual, physical and logical data models(3NF) using various Data Modeling tools like Erwin, MS Visio, IDEF1X methodology
Extensive knowledge and experience of Extraction, Transformation and Loading (ETL) environments database development methodologies, programming languages, developed highly complex SQL scripts, supported analysis and transformation of data, database extraction and data cleansing
Knowledge and understanding of web services (SOAP, XML, WSDL, SQL) and experience designing interfaces between application systems, Oracle API’s and Concurrent programs
Experience and Expertise includes Business Requirement Gathering, Requirement Mapping, GAP analysis, Functional architecture, Solution Design, Unit Testing, UAT and User Training
Technical expertise in Oracle RDBMS, DB2, COBOL, QMF, VSAM and debugging tools
Experience with ASG tech tool, data intelligence ASG Rochade, Becubic, Scanning, Data Lineage
Strong analytical, problem-solving, time management and communication skills, Organized, self-motivated, detail-oriented and a good team player and Continuously learning and updating my skills to keep up with changing IT technology
Demonstrated leadership abilities and team work skills as well as the ability to accomplish tasks under minimal direction and supervision

TECHNICAL SKILLS
Systems Windows NT/2000/XP/VISTA/7, VAX4200, VAX/VMS, UNIX, Linux, Apache, HSF
Languages T-SQL, PL/SQL, VB6, ASP.Net, VB.Net, C#, COBOL, WBF, WCF, XML, XSL, HTML
Networking Novell, NFS, Ethernet, Cisco CCNA, VPN, LAN, SOAP
Applications Oracle EBS R12, Oracle/PLSQL, Oracle/DBA, MS Windows, MS Office, Crystal Reports, MS Visio, MS Visual Studio, SSIS, SSRS, MS Project, SharePoint, UML, HP QC, Oracle BI Publisher, Seibel Case Management, Oracle XML Publisher, Seibel Tools, IBM Clearcase, Java Scripts, SSH, FTP, CASE Tools, SAP BI, SAP ECC 6.0, OBIEE g11/12C, ODI 12c, MsSQL, NoSQL, XML, ERwin, Toad, Jira, GitHub, Informatica Power Center/IDQ, DB2, OAF, QMF, ASG Rochade/Becubic Data Lineage Tools, AG Data Intelligence Tools (DI), Snowflake Cloud, Talend Cloud, Power BI

PROFESSIONAL EXPERIENCE
Solution Data Architect March 2023 – March 2024
TCS/Morgan Stanley, New York, USA
Provided advisory to define, improve or operationalize data management control frameworks, DQ standards, and governance process
Provided guidance on DQ and IT Control standards to align with Enterprise Risk Finance and Technology (RFT) Framework and industry standards
Developed expertise on the Banks Enterprise Data Management policies and standards and provide guidance to senior management
Performed current state assessment of Data Quality and IT Controls and provided recommendations to mitigate data risk more effectively
Recommended an optimized target state to ensure improve coverage and the right controls are deployed in strategic locations, dealt with stakeholders of varying degrees of seniority across Finance, Risk, and Technology
Recommended appropriate data capture, transport and use controls and collaborate with enterprise technology teams to implement recommended DQ Controls
Worked closely with DM team to refine existing DQ Rule to ensure appropriate coverage and granularity
Supported process to review Key Business elements (KBE), KBE metadata, prioritization, data lineage
Executed ERFTs Data Quality Framework to assess measure, monitor and report data quality for key business elements leveraged across key regulatory reports
Cooperated and engaged with the Monitoring, Governance and Issue Management work streams
Supported audit preparation and provided actionable recommendations to mitigate Data Quality and IT Controls risks highlighted in audit or regulatory findings
Provided guidance on required artifacts and collate DQ information in preparation for audit
Designed sustainable Data Quality controls as part of issue remediation process
Worked with business, technology, and issue remediation team to define sustainable Data Quality and IT controls
Provided actionable recommendations to implement controls that prevent, detect and correct DQ related risks

Senior Data Engineer/Data Architect Dec 2021 – Dec 2022
Knights of Columbus, New Haven, Connecticut, USA
Completed full life cycle of ETL/ELT development to address business needs or resolve issues including design, mappings, data transformations, scheduling and testing
Translated data movement requirements into technical ETL design
Developed ETL/ELT workflows and mappings to extract, transform, and load data into target environments, developed data extraction and transmissions to external vendors
Developed test plans and perform unit testing and create supporting documentation for new ETL processes
Determined impacts to data warehouse structures and information flows due to changes in business or technical requirements
Contributed to architectural decisions to support business processes, provided production support for data solutions
Complete root cause analysis and contribute to remediation planning and implementation
Performed data quality analysis, report data quality issues and propose solutions for data quality management, Learn and expand upon internal controls and participate in customer support
Performed design and code reviews in support of organizational standards and mentored less experienced team members
Created and managed tables, views, user defined functions, schemas, database in Snowflake Cloud Data Warehouse
Worked on EDW modules by retrieving the data from the different source systems databases like DB2, Oracle SAP, MS SQL Server, CSV files and then loading it into SAP ERP and Snowflake Cloud Data Warehouse using Talend Cloud ETL jobs
Ingested metadata, lineage and Data Quality (DQ) metrics from Talend ETL or database, in Collibra Catalog, for the various sources Talend connects with
Used Talend Cloud to connect with and sources data from multiple tools and applications, cataloguing data, creating lineage and documenting transformations before data is sent downstream for all these sources, into Collibra
Worked on Talend components, various file components, improving performance of Talend jobs, created triggers, Exporting and Importing of Talend jobs abd created Generic and Repository Schemas
Optimized the performance of the mappings by various tests and source, target and transformations
Worked on Design and implementation of transformation/mapping rules, executed the transformation and mapping rules for each field and format the data into the recipient structure according to the common source template specifications for S/4 HANA
Supported the transmission and processing of financial transactions, Financial transactions (policy level) from the core source systems to the sub ledger in S/4 HANA including Master
Developed data ingestion and integrations (REST, SOAP, SFTP, etc.) processes
Involved in migrating the client data warehouse architecture from on-premises into Azure cloud
Implemented Data Vault Modeling Concept as a solution for dealing with change and developing in-house by leveraging and enhancing the work done on the data warehouse model (Data Vault)
Performed data mapping between source MDM data model and the target EDW data model
Used GitHub, version control system with a distributed workflow, resolved issues related to merge & rebase, and issues related to a distributed workflow, test & review code by cloning the GitHub repository and reviewing the commits, issues, and pull requests
Worked on SnowSQL and Snowpipe, loading data into Snowflake tables from internal stage
Converted Joblets to support the snowflake functionality, used COPY, LIST, PUT and GET commands for validating the internal stage files
Consulted on Snowflake Data Platform Solution Architecture, Design, Development and deployment
Worked on Bulk loading from the external stage (AWS S3), internal stage to snowflake cloud using the COPY command
Designed and developed a highly efficient data pipelines using Databricks to ingest, store, and process data from multiple sources, resulting reduction in data processing time and improved data accuracy
Developed integration frameworks for Azure Databricks, troubleshooting and optimizing Delta Live Tables jobs to ensure seamless data processing and integration
Designed and executed a comprehensive data migration strategy from legacy systems to Databricks, reducing data redundancy and improving data retrieval time

Senior Data Management/Data Architect Dec 2020 – Dec 2021
BNY MELLON, Bank of New York, New York, USA
Responsible for determining systems requirements for new or modified database application programs, creates the system specifications and is responsible for the development, testing and implementation of efficient, cost effective application solutions
Worked in conjunction with the Data Architect/Modeler on the data warehouse reporting solution
Writing and tuning SQL queries, view, stored procedures, and function
Interpreting data models and developing database structures, using standard diagramming techniques to design and develop computer data models, and implementing and troubleshooting programming changes and modifications
Worked within a team and lead database efforts and to document customer requirements, translate into technical designs, and explain technical issues clearly and accurately to both technical and nontechnical audiences
Convey technical information on scanners (software) to data custodians
Prepares deliverables such as source to target mappings and transformation rules documentation
Defines and captures metadata and rules associated with ETL processes in Informatica and ThoughtSpot
Designed and developed the technical/functional specification for ETL development and implement using Informatica
Analyzed dependencies for workflow for various ETL processes, handle exception, and maintain logs
Managed artifacts - versions, including software code, documents, design models, and even the directory structure itself
Created and maintain Data Model in repository for Dev environment, create migration and data mapping databases
Worked on Intelligence Tool (DI), Rochade/Becubic Data Lineage Tools to provide data lineage functionality
Worked in building data pipelines for metadata extraction and storage, cataloging, populating Metadata content and associated business terms to the business glossary
Designed and developed mappings with required transformations and load the data into the warehouse server for analysis using Informatica Power Center, IDE (Informatica Data Explorer), IDQ (Informatica Data Quality)
Performed analysis of current source data and mapping to target MDM Financial Industry database to master customer information transforming from policy centric data to customer centric
Worked on development and delivery of data requirements for a Managed Meta Data (MDM) Environment in support of the Master Data Management program and related Data Governance
Ensured reported issues were resolved more quickly by documenting and tracking application issues, using Agile and DevOps Methodologies, as well as by participating in scrum meetings, which assisted with prioritization of issues

Senior Data Consultant/BI Developer Mar 2020 – July 2020
Express Scripts Canada (ESI), Mississauga, Canada
Participated in the design of analytics solutions supporting at an Enterprise level
Assisted in planning reporting projects to include but not limited to requirements analysis, project scoping, data analysis, and business logic transformation
Collaborated with BI System Analyst to create required reports using reporting tools like OBIEE, BI Publisher, profile data necessary to meet reporting requirements
Designed, develop, and support visualization tools including but not limited to dashboards, scorecards, operational and scheduled reports, ad-hoc queries, and decision support
Performed detailed data analysis, developing online analyst processing (OLAP) cubes for predictive analysis and forecasting
Designed and administration of Oracle Business Intelligence (OBI) repository
Ensured high levels BI Systems availability through systems administration/support and change management
Communicated task status, roadblocks, and critical matters to management promptly
Creating / Writing and maintaining the database objects - schemas, tables, indexes, views, user-defined functions, cursors, triggers, stored procedure, constraints, and roles
Using DDL and DML for writing triggers, stored procedures, and data manipulation
Worked closely with end users to designing reports and dashboards, suggesting better ways of reporting in OBIEE so that the required information is visualized by end users and drive the design and build of visualizations and analytics
Developed Reports / Dashboards with different Analytics Views (Drill-Down / Dynamic, Pivot Table, Chart, Column Selector, with global and local filters) using Oracle BI Presentation Services
Prepared and executed comprehensive test plans for system and quality testing of reports which included writing PL/SQL queries to check and compare the quality of data provided by report
Wrote several Packages /stored procedures/Functions/triggers in Oracle (PL/SQL) for the enterprise portal application and data merge
Worked with database administrators to optimize report performance through database tuning
Developed ELT and ETL Mapping in Oracle Data Integrator, Implemented SCD type1 and SCD type2, and Changed Data Capture (CDC)
Liaise with business subject matter experts in analyzing business requirements and translating them into detailed conceptual data models, process models, logical models, physical models and schema development in the database
Senior Data Modeler/BI/DW September 2019 – Jan 2020
CN Railway, Montreal, Canada
Interacted with users to gather business requirements for BI projects and enhancements
Designed data architecture for BI projects and enhancements
Created EDW business data models and business rules for all EDW environments
Created data definitions, models and access views and BO Universe Structures
Definition of data synchronization and acquisition rules, data quality and validation rules
Defined Extract/Transform/Load (ETL) processes
Ensured data access optimization
Analysis of functional and non-functional categorized data elements for data profiling and mapping from source to target data environment
Developed working documents to support findings and assign specific tasks and Data Profiling
Supplied high level and detail estimates for enhancements/projects
Provided data modeling services to BI Development & Support Team
Worked on Business Objects Universe Design & Report Construction, Data dimensional and relational modeling techniques and tools (Erwin)
Collaborated with enterprise data warehouse, data governance, and business teams on data quality issues, as well as architecture or structure of data repositories
Analyzed the Data Lineage from source systems including DB2, Oracle, SAP systems and legacy applications to Data Warehouse
Worked with the enterprise data governance team to incorporate business unit inventories as part of the enterprise data catalog and Business Information Model
Supported teams and processes with large data analysis using advance Excel features (Pivot tables, Macros etc.)

Senior Data Architect/SQL Developer March 2018 – July 2019
McKesson Canada, Toronto
Worked with customers and Stakeholders in gathering business requirements for data migration needs in Specialty Technology Solutions Project
Worked across multiple functional projects to understand data usage and implications for data migration
Developed PL/SQL triggers and master tables for automatic creation of primary keys, created stored procedures, functions and pancakes for moving the data from staging area to data mart
Involved in the designing, planning and managing the data migration process, continuous enhancement and fixing of production problems, generated server PL/SQL scripts for data manipulation and validations and materialized views for remote instances
Wrote and deployed stand-alone C# web application with SQL Server backend for attachments patient services applications using data from legacy data source extraction, translation and insertion from flat to the new patient solution
Worked with subject matter experts and project team to identify, define, collate, document and communicate the data migration requirements, understand the data structures and tables inherent in the new PSP system and be able to map legacy data to the new structure using mapping tools, Excel and intermediate databases
Ensuring that ETL processes run as scheduled and performance tuning ETL jobs as required
Developed and Optimized Stored Procedures and Functions to perform Work with technical & business staff to develop field level data mappings to aid in data migration and to build interfaces
Created & maintained data dictionaries for different areas of data, demonstrated a strong grasp of database architecture including SQL server and database access tools
Created and maintain Data Model in repository for Dev environment, create migration and data mapping databases
Synchronized model with data base and correct discrepancies if any in DDL and generate SQLs according to new model
Documented procedures to facilitate cross team support of ongoing operational interfaces and regular data patches
Worked closely with Data Architect for database schema changes, Evaluate, test and produce recommendations for the selection, user and deployment of DBMS software, data management tools and utilities, data warehouse and replication tools
Worked with business users to clarify data requirements and analyze and document scope of work for data conversion and cleansing projects
Developed and run validation processes to ensure conversion accuracy and quality
Created of database objects like tables, views, procedures and packages using oracle tools like Toad, PL/SQL Developer and SQL* Plus
Worked on support tickets of SPM using JIRA, resolve and follow up with functional and technical teams
Studied existing OLAP system(s) and created facts, dimensions and star schema representation for the data and warehouse systems
Scripted OLAP database backup and scheduled a daily backup using SQL Server agent job
Participated in the Sprint Planning sessions, daily stand-ups, sprint demos and sprint retrospective sessions
Designed SQL SSIS Packages to extract data from various data sources such as Access database, Excel spreadsheet, and flat files into SQL Server 2016 for further Data Analysis and Reporting by using multiple transformations provided by SSIS such as Data Conversion, Conditional Split, Bulk Insert, Merge and Union all, Scheduled and maintained nightly and weekly loads of data by creating the corresponding job tasks
Used Agile methodology to created and maintained project plans, project tracking, log of changes, issues, action items, and decisions
Developed custom Microsoft Power BI dashboards, visualizations, and interfaces with Microsoft SSRS to deliver meaningful and actionable insights
Facilitated daily scrum sessions and status updates to client management
Managed dependencies between business analysts, laboratory development, and operational development teams
Performed requirements analysis, design, and prototyping for Management Dashboards, Financial Reporting, and Sales Business Intelligence using Microsoft BI technologies, including Power BI, DAX, and SSAS
Extensively worked on Informatica IDE/IDQ, involved in massive data profiling using IDQ (Analyst Tool) prior to data staging

Senior Information Systems Officer / Data Architect Oct 2013 – Dec 2017
UNHQ - United Nations Secretariat, New York, USA
Umoja Project (SAP HCM, SAP BI, Inspira, IMIS, Necleus, OBIEE, ODI, ETL, Informatica EDC)
Provided support of Umoja SAP HR modules Maintain and stabilize HR modules in SAP system : Payroll, Time, OM, PA, Benefit, Training & Event, Appraisal, ESS/MSS Create/Maintain Payroll Schema
Supported and worked with the Umoja SAP HCM project team in Data Conversion, QA, Master Data Maintenance, Deployment, BI and ETL, Testing of HCM module
Testing & Creation of data the Enterprise Structure (Personnel areas, and Personnel sub areas), the Personnel Structure (Employee groups, Employee sub groups, Payroll Accounting Areas), and the Organizational Structure (Organization Units, Positions, Jobs)
Worked on HR data marts and transactional systems, this involved analyzing requirements (user stories), identifying transactional database / data marts, validating data mart design and ETL mappings logic, creating mappings from data mart for the report, creating repository (RPD), reports and dashboard, testing those reports, unit testing, regression testing and documentation
Designed customized interactive dashboards in OBIEE and SAP BI tools as BI power user applying analysis, drill down, guided navigation, prompts, filters, and variables
Designed, build and deploy data models optimized for business intelligence and analytics
Developed a Conceptual model using Erwin/Toad based on requirements analysis
Developed normalized Logical and Physical database models to design OLTP system for insurance applications
Created dimensional model for the reporting system by identifying required dimensions and facts using Erwin
Used forward engineering to create a Physical Data Model with DDL that best suits the requirements from the Logical Data Model
Coordinated data collection activities to support data migration / conversion of legacy data into Umoja. Acts as a liaison between the internal Umoja teams and the Deployment Cluster Sites
Developed Data Mapping, Data Governance, Transformation and Cleansing rules for the Master Data Management Architecture involving OLTP, ODS and OLAP
Developed global data strategy for Enterprise Data Management, including data architecture, Master Data Management (MDM), EDW, data modeling standards, meta data management and Data Governance
Modeled and designed the database using Agile development method. Created and documented logical, physical and dimensional data models (data warehouse, data model)
As part of Data Quality analysis: Traced Data Lineage of data elements to be used in the new system, worked with the data steward and data owners in creating metadata, Lineage, Data Quality rules and guidelines
Worked with business users to clarify data requirements and analyze and document scope of work for data conversion and data cleansing projects
Designed and developed custom made business intelligence solution according to the plan using BI applications
Built interactive dashboards with drill down effect through Oracle BI Answer using OBIEE 11g
Developed and design complex data structures, ad hoc queries, reports and analytics, stored procedures, functions, triggers
Interfaced with Umoja, Missions, OAH’s and HQ in order to facilitate data gathering and cleansing of data from legacy systems (IMIS, SUN, Progen etc) and provided guidance to missions and OAHs regarding data conversion
Designed ETL to load data from data warehouse, Oracle, MySQL, SQL Server to meet business needs
Involved in writing test scripts and functions in Test Script Language using QTP for automated testing
Developed and ran validation processes to ensure conversion accuracy and quality
Analyzed data coming from different sources for data conflicts resolution in order to maintain and enhance records within master data
Interacted with stakeholders in order to address issues and processes that will improve master data integrity
Designed a STAR schema for the detailed data marts and Plan data marts involving confirmed dimensions
Created and maintained the Data Model repository as per company standards, data integration and migration processes as required by Umoja technical teams
Analyzed business requirements, system requirements, data mapping requirement specifications, and responsible for documenting functional requirements and supplementary requirements in Quality Center
Worked on data profiling and data validation to ensure the accuracy of the data between the warehouse and source systems
Created master and work repositories for ODI by coordinating with Oracle DBAs
Used Erwin for reverse engineering to connect to existing database and ODS to create graphical representation in the form of Entity Relationships and elicit more information
Used standard ITIL Methodology to analyze and streamline existing business processes and assists in creation of new business processes, developed and documented IT Service Management policies, processes, and procedures based on ITIL best practices
Senior Systems Analyst / Data Management Consultant Oct 2010 – July 2013
Ministry of Community and Social Service, Ontario Public Services, Toronto, Canada
Family Responsibility Case Management Systems (FCMS) Project and OntTax Project
Worked as Oracle EBS ERP version R12 technical consultant in developing, implementing and maintaining of FRO ERP Financial System and Case Management System components
Conducted programming, coded, fixed and enhanced complex programming modules based on the functional specification documents (ISD’s) using the development tools and languages (SQL, PL/SQL, Oracle Forms, Oracle Reports, Oracle XML Publisher, Concurrent Programs, API’s, Alerts, Oracle Application Object Library, Workflow, Oracle Framework Architecture, Seibel Tools), version control tools (IBM Clearcase), and testing tools (HP QC)
Extracted data, designed, developed and execute SQL scripts on various databases, like IMS, SQL and Oracle to produce data sets for analysis
Analyzed, identified tested and implemented data management techniques on required data elements and assist in data migration
Implemented process for Extraction, Transformation and loading (ETL) using Oracle PL/SQL, SQL Loader, SQL Server, MS Access, MS Excel, Oracle XML Publisher, XML, XSD and Unix shell scripting
Worked with functional team to Implemented complete data migration mapping between Legacy data and Oracle AP / AR and GL application
Updated and tested oracle packages and procedures, and implementing successful interface between Siebel and EBS
Implemented data migration mapping between Legacy data, customize Oracle objects for data load using Oracle API’s, PL/SQL, SQL*Loader, Oracle Developer Suite 10g, SQL*Plus, Workflow Builder
Provided Data Governance solution to an integrated, comprehensive metadata repository, providing definitions, business rules, defaulting rules, data lineage, data governance workflow, etc
Analyzed, Designed, Built and Test Reports, Dashboards and other BI objects of financial and case management data using Oracle OBIEE 11g, Oracle XML publisher and Oracle EBS R12 concurrent manager
Designed, Developed, Tested and Implemented a variety of business application solutions used by the Ministry of Revenue/ Government Services client
Created various reports to meet client requirements (pivotal, chart, tabular, drill down, etc.) through global and local filters
Created, enhanced, upgraded,
Contact this candidate