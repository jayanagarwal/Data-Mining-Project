Anoop Chowdary
Contact number: 512-***-****
Gmail: ad5le1@r.postjobfree.com
Professional Summary:
Overview:
DevOps Engineer with 9 years of total IT experience encompassing a thorough understanding and hands-on experience of DevOps methodology and workflow, Continuous Integration (CI) / Continuous Deployment (CD) oriented Build and Release Management, Configuration Management, Containerization, Cloud Services, and System Administration.
Expertise:
Extensive experience in the design and implementation of Continuous Integration, Continuous Delivery, Continuous Deployment (CI/CD) and DevOps processes.
Proficient in setting up and configuring Sumo Logic Cloud SIEM for log and security event analysis.
Knowledgeable about Sumo Logic Apps and integrations for various technologies and platforms.
Proficiency in Sumo Logic query language for log data exploration and troubleshooting.
Proficient in installing and configuring Splunk Enterprise for log aggregation and analysis.
Implemented and managed GitOps workflows using Argo CD.
Leveraged Git repositories as the source of truth for application deployments.
Demonstrated ability to automate application deployments and updates using Argo CD.
Knowledgeable about Splunk's Common Information Model (CIM) for standardized log parsing.
Proficiency in Splunk Search Processing Language (SPL) for log data analysis.
Collaborated with security teams to remediate vulnerabilities and improve the overall security posture of applications.
Implemented and managed infrastructure as code (IaC) practices using Chef, enabling consistent and repeatable server provisioning.
Managed and maintained a fleet of nodes using Chef, ensuring that all systems were in compliance with the desired configurations.
Orchestrated configuration changes and application deployments across multiple environments with Chef, reducing manual errors and enhancing consistency.
Implemented version control strategies to maintain artifact versions and revisions effectively like GIT.
Automated CI/CD pipelines with tools like Jenkins, GitLab CI/CD, or Travis CI for seamless integration with Artifactory.
Knowledge on standard networking protocols and components such as HTTP, DNS, ECMP, TCP/IP, ICMP, the OSI Model, Subnetting and Load Balancing strategies
Maintained repository cleanliness through regular artifact cleanup and purging policies.
Translated business needs into effective Kibana visualizations, improving [specific outcomes].
Resolved technical issues, ensuring seamless Kibana and Elasticsearch workflows.
Conducted training sessions, elevating team proficiency in Kibana's features.
Developed advanced Kibana queries and aggregations, revealing hidden data insights.
Set up a Nexus Sona-type repository to manage your project's artifacts (e.g., JAR files, WAR files). This ensures that your artifacts are stored securely and can be easily retrieved for deployment or sharing.
Configure your build tool to publish the built artifacts to the Nexus repository.
Proficient in configuring, deploying, and managing PowerMax storage arrays.
Expertise in optimizing performance and ensuring high availability within PowerMax environments.
Designed and integrated PowerMax arrays into complex IT architectures.
Implemented performance monitoring and tuning strategies for PowerMax arrays.
Proficient in configuring and managing SAN block storage solutions using protocols like iSCSI, Fibre Channel, and FCoE.
Experienced in Terraform extensively to build and provision the infrastructure involving writing modules for a variety of services such as APIs, queues, functions, and others.
Experience with implementing monitoring solutions in Ansible, Terraform, Docker, and Jenkins.
Hands-on experience working with Configuration Management tools like Ansible, Puppet, and Chef.
Experienced in creating Branches, Merging, Rebasing, Reverting, Tagging, and maintaining the version across the environments using SCM tools like GIT on Linux and Windows environments.
Experienced in managing software artifacts required for development using repository managers like ECR, Nexus, and JFrog Artifactory.
Hands-on experience in container-based technologies Kubernetes, Docker, and ECS.
Experience with CI/CD in a containerized microservices environment.
Involved in the design and deployment of a multitude of cloud services on the AWS stack such as EC2, Route53, S3, RDS, DynamoDB, and IAM, while focusing on high availability, fault tolerance, and auto-scaling.
Worked on VAULT, a Secret Manager tool for storing Secrets, Key-Value pairs, and other security parameters.
Experience with automating Build, Test, and Deployment processes using CI/CD pipelines in Jenkins by developing scripts using Groovy, Bash, etc.
Automate using Ansible and Python the configuration, installation, and deployment setup of many systems within Cloud Services including the monitoring system.
Ability and experience to meld development and operations to ensure quick delivery of an effective and efficient end product.
Adapt to new, evolving technologies and implement them in current projects. Good interpersonal skills, quick learning, problem resolving, and meeting technical and business needs.
Skills:

Cloud Technologies:
GCP/ AZURE / AWS EC2, IAM, AMI, Elastic Load Balancer (EBL), DynamoDB, S3, SNS, Cloud formation, Route53, VPC, VPN, Security groups, Cloud watch, EBS, Athena, EWR
Operating System:
Linux, Unix, Ubuntu, Centos, Windows
Scripting:
Python, Bash.
CI-Automation/Build Tools:
GIT, Maven, Ant, Jenkins, Bamboo, Nexus, Artifactory, Docker, Ansible.
Application Servers:
Apache Tomcat, WebLogic, WebSphere
Web Server:
Apache, Nginx
Containerization Tools:
Docker, Kubernetes
Cloud Computing:
AWS, GCP, Azure
Configuration Management
Ansible, Puppet

Work Experience:
American Express Plano, Texas April 2022 to Present
Role: Cloud Engineer
Responsibilities:
Completing assignments in a high volume, dynamic environment with CI/CD and Monitoring.
Designing and developing E2E health check scripts for multiple critical components, such as Kafka, Elasticsearch, Cassandra, Consul, Redis, HAProxy, and Vault.
Create these health check scripts, such as Python, Shell scripting, or other relevant languages.
Proficiency in AWS or Azure, specifying the services and solutions you've worked with (e.g., AWS EC2, S3, Azure Virtual Machines, Azure App Service, etc.).
Leveraged advanced Kibana features such as Canvas for dynamic data visualization, enhancing the clarity and impact of presentations.
Proficiency in setting up and configuring AWS API Gateway to create and manage APIs.
Knowledge of authentication and authorization mechanisms, including API key, IAM roles, and OAuth, for securing APIs.
Ability to design and implement API Gateway policies for rate limiting, caching, and request/response transformation.
Experience in monitoring and logging API traffic using services like AWS CloudWatch and CloudTrail.
Understanding of API versioning and deployment strategies to ensure backward compatibility.
Expertise in a wide range of AWS services, including but not limited to EC2, S3, RDS, Lambda, IAM, VPC, and more.
Proficiency in setting up CI/CD pipelines to automate building, testing, and deploying applications.
Knowledge of containerization and orchestration technologies like Docker and Kubernetes.
Familiarity with integrating CI/CD pipelines with version control systems, issue tracking tools, and other DevOps-related services.
Ability to install, configure, and maintain Jenkins, including plugins and security settings.
Experience creating and managing Jenkins jobs and pipelines using Jenkins DSL or Pipeline as Code.
Troubleshooting and debugging Jenkins build and deployment issues.
Replicating Jenkins jobs in Harness, translating Jenkins job configurations into Harness pipelines. Proficient in utilizing Amazon EC2 for virtual server instances, including instance types, AMIs, and auto-scaling configurations.
Experienced in container orchestration with Amazon ECS (Elastic Container Service) or Amazon EKS (Elastic Kubernetes Service).
Skilled in serverless computing using AWS Lambda for event-driven microservices and backend tasks.
Using Jira's REST API for automation, data retrieval, and integration with other systems.
implementing and customizing AWS Landing Zones to set up a secure, multi-account AWS environment.
Configuring and managing AWS Control Tower for governance and compliance.
Utilizing AWS CloudTrail to monitor API activity and track changes in the AWS environment.
Implementing CloudWatch Alarms to set up proactive monitoring and automated responses to predefined thresholds.
Configuring and troubleshooting VPCs (Virtual Private Clouds) for secure and isolated networking.
Managing security groups, route tables, and understanding subnetting in the AWS network.
Defining and enforcing AWS resource tagging standards for consistent resource management.
Implementing automation through AWS Lambda functions or Step Functions for repetitive tasks.
Writing AWS CloudFormation templates or Terraform scripts to provision and manage infrastructure.
Implementing version control (e.g., Git) for Infrastructure as Code files.
Expertise in configuring Virtual Private Cloud (VPC) with subnets, route tables, and network ACLs for secure and isolated network environments.
Proficient in setting up VPN connections and Direct Connect for hybrid cloud connectivity.
Skilled in using AWS Route 53 for domain registration, DNS management, and global load balancing.
Experienced in implementing fine-grained access control using AWS IAM, including roles, policies, and permissions boundaries.
Proficient in writing AWS CloudFormation templates using YAML/JSON to define infrastructure resources and their configurations.
Experienced in implementing CloudFormation stack policies to enforce update protections and rollback behaviors. Skilled in using AWS CloudFormation Designer for visualizing and creating complex infrastructure templates.
Familiar with advanced CloudFormation features such as nested stacks, cross-stack references, and resource dependencies.
Proficient in Python programming language with expertise in data types, control structures, and object-oriented programming principles.
Experienced in developing Python scripts and applications to automate tasks and interact with AWS services using Boto3 SDK.
Skilled in handling AWS API responses, error handling, and pagination for large datasets. Familiarity with Python libraries and frameworks for data manipulation, such as Pandas, NumPy, and Spark.
Hands-on experience in provisioning and configuring AWS EMR clusters for big data processing workloads using Hadoop and Apache Spark.
Proficient in leveraging EMRFS for seamless integration with Amazon S3, enabling efficient data storage and processing.
Skilled in optimizing EMR cluster performance through instance types, auto-scaling configurations, and custom bootstrap actions/scripts.
Experienced in monitoring and troubleshooting EMR clusters to ensure high availability and reliability of big data applications.
Proficient in setting up AWS WAF (Web Application Firewall) and AWS Shield for protection against web application attacks and DDoS.
Skilled in managing encryption keys with AWS Key Management Service (KMS) for data encryption at rest and in transit.
Updated Python code for testing/working on multiple repositories. By adding more orgs to the list on file the script does the scanning for all the added orgs.
Worked for the Python upgrade, as CICD is scanning repos looking for Python code to determine potential changes.
Migrate Database from SQL Databases to NO SQL Databases MongoDB Database administration on multi-datacenter cluster
Experienced in monitoring, performance tuning, and managing MongoDB clusters.

Environment: Ansible, Python, Kubernetes, GIT, Jenkins, Terraform, Docker
Work Experience:
Fannie Mae San Jose, CA Dec 2020 to March 2022
Cloud Engineer
Responsibilities:
Work in setting up the CI/CD pipelines using Jenkins, GitHub, GitOps, Helm, and AWS.
Integrated GitOps practices with CI/CD pipelines (e.g., Jenkins, GitLab CI/CD, or CircleCI) to automate application deployments.
Proficient in configuring CI/CD pipelines to trigger GitOps workflows.
Implemented GitOps principles for versioning and managing infrastructure automation scripts.
Demonstrated ability to manage configuration files and secrets in Git repositories securely.
Leveraged Git branching strategies like GitFlow or GitHub Flow for efficient development and deployment.
Mastery of HashiCorp Terraform for defining and provisioning infrastructure as code (IaC).
Skill in writing Terraform configurations to manage AWS resources, including virtual private clouds (VPCs), EC2 instances, and security groups.
Ability to use Terraform modules for reusability and maintainability of infrastructure code.
Knowledge of Terraform state management and remote backends for collaboration.
Proficiency in creating and managing infrastructure in a declarative and version-controlled manner.
Expertise in AWS networking concepts, including subnets, route tables, and peering connections.
Knowledge of VPNs and Direct Connect for secure and scalable network connectivity.
Skill in implementing security groups and network access control lists (NACLs) for controlling traffic.
Experience in setting up VPC flow logs and network monitoring for security and compliance.
Familiarity with AWS Identity and Access Management (IAM) for fine-grained access control and security policy management. Strong understanding of AWS IAM policies and roles, including multi-factor authentication (MFA) and least privilege principles.
Proficient in implementing encryption at rest and in transit using AWS KMS, SSL/TLS, and AWS Certificate Manager.
Experienced in configuring AWS WAF and AWS Shield for DDoS protection and web application firewall (WAF) rules. Expertise in configuring Amazon S3 for object storage, including lifecycle policies, versioning, and cross-region replication.
Proficient in setting up Amazon EBS (Elastic Block Store) volumes for persistent block storage attached to EC2 instances.
Experienced in managing file storage with Amazon EFS (Elastic File System) for scalable and shared file systems.
Integrating version control and IaC tools into CI/CD pipelines for infrastructure automation.
Setting up comprehensive CloudWatch Dashboards for monitoring various AWS services.
Implementing custom metrics and logs for tracking performance and availability.
Automating the deployment of SaaS applications using AWS services like AWS Elastic Beanstalk or AWS Far gate.
Troubleshooting deployment issues using CloudWatch logs and metrics. Implementing CI/CD pipelines to automate testing, deployment, and validation processes.
Regularly reviewing and updating automation scripts for improved efficiency. Utilizing AWS Config and AWS Trusted Advisor for analyzing and optimizing the AWS infrastructure.
Providing support for incidents and outages using AWS support tools and services.
Building Docker images for applications and understanding Docker file best practices.
Orchestrating containers with Kubernetes, including deploying pods, services, and managing resources.
Implementing container security practices and monitoring Kubernetes clusters.
Using Jenkins pipelines to drive all microservices builds out to the Docker registry and then deployed to Kubernetes, Created Pods, and managed using Kubernetes.
Provisioned AWS services and resources using Terraform: EC2, EBS, S3, VPC, Auto Scaling, Cloud Formation, Elastic Load Balancing, RDS, Route 53, CloudWatch, Identity and Access Management (IAM).
Maintaining strong code hygiene (Groovy, Terraform, Python, Java) and doing peer code reviews daily.
Automated operation, installation, and monitoring of search ecosystem components in our open-source infrastructure stack, specifically: Solr, Zookeeper, Message Queues (RabbitMQ/Kafka/ActiveMQ), Redis
Running a cron job on Aiven Kafka exposes a metrics endpoint. Connected to the endpoint, get the metrics, and push to Cloudwatch at every minute.
Expertise in setting up centralized logging and monitoring using Amazon CloudWatch Logs and Metrics.
Proficient in creating custom dashboards and alarms in CloudWatch for proactive monitoring and alerting.
Experienced in using AWS Config for tracking resource inventory, configuration changes, and compliance auditing.
Skilled in implementing continuous integration and deployment (CI/CD) pipelines using AWS CodePipeline, AWS CodeBuild, and AWS Code Deploy.
Proficient in utilizing AWS Glue for serverless ETL (Extract, Transform, Load) workflows to prepare and transform large-scale datasets.
Experienced in defining Glue crawlers to automatically discover, catalog, and infer schema from various data sources.
Skilled in developing custom Glue jobs using PySpark or Python shell scripts to perform complex data transformations and aggregations.
Familiarity with Glue job triggers, scheduling options, and monitoring capabilities for orchestrating data processing pipelines.
Proficient in designing AWS Lambda functions in Python to implement serverless compute solutions for event-driven architectures.
Experienced in configuring Lambda function triggers, such as API Gateway, S3 events, SNS notifications, and CloudWatch events.
Skilled in optimizing Lambda function performance, memory allocation, and concurrency settings to meet application requirements.
Familiar with integrating Lambda functions with other AWS services, including DynamoDB, S3, SQS, and Kinesis, to build scalable and resilient serverless applications.
Proficient in writing AWS CloudFormation templates in YAML/JSON format to provision and manage infrastructure resources as code.
Experienced in defining CloudFormation parameters, mappings, conditions, and outputs to create reusable and parameterized templates.
Skilled in implementing advanced CloudFormation features such as nested stacks, cross-stack references, and resource tagging strategies.
Familiar with using AWS CloudFormation Change Sets for previewing and managing stack updates with rollback protection.
Involved in writing Java API for Amazon Lambda to manage some of the AWS services.
Proficiently administered and maintained the ServiceNow platform, ensuring its reliability, availability, and performance.
Managed user accounts, roles, and permissions to uphold security standards and data integrity.
Regularly performed platform upgrades and applied patches to keep the system up to date with the latest features and security enhancements.
Customized ServiceNow modules and workflows to align with business processes and requirements.
Created and managed service catalogs, request fulfillment workflows, and automation rules to streamline service delivery.
Developed automated workflows and notifications to ensure timely incident escalations and problem resolutions.
Implemented a server-less architecture using API Gateway, Lambda, and DynamoDB and deployed AWS Lambda code from Amazon S3 buckets. Created a Lambda Deployment function and configured it to receive events from the S3 bucket.
Environment: Jenkins, Terraform, AWS, EC2, Route53, S3, VPC, EBS, Auto scaling, Lambda, Kubernetes, Helm, Elastic Search, Kibana, FluxCD/ArgoCD, GIT, AWS, Unix/ Linux environment, bash scripting, GitHub Actions.

CISCO San Jose, CA
Cloud Engineer Feb 2019 to Nov 2020
Responsibilities:
Launching Amazon EC2 Cloud Instances using Amazon Images (Linux/ Ubuntu) and configuring launched instances with respect to specific applications.
Enforced configuration changes across the infrastructure with Puppet, ensuring consistency and compliance.
Configured and maintained Puppet master and agent nodes for optimal performance and reliability.
Integrated Puppet with Puppet DB to store and query node data, facilitating reporting, auditing, and troubleshooting.
In-depth knowledge of the features and differences between RHEL 7 and RHEL 8. Skilled in deploying and managing relational databases with Amazon RDS (Relational Database Service) for MySQL, PostgreSQL, or Aurora.
Proficient in NoSQL database management using Amazon DynamoDB for fast and flexible document and key-value storage.
Experienced in setting up data warehousing solutions with Amazon Redshift for analytics and reporting.
Creating S3 buckets and managing policies for S3 buckets and Utilizing S3 bucket and Glacier for Archival storage and backup on AWS.
Creating and maintaining documentation using tools like Confluence or Markdown. Documenting infrastructure changes, configurations, and troubleshooting procedures.
Participating in Agile or DevOps processes to align infrastructure changes with development sprints. Collaborating on infrastructure requirements with product owners and development teams.
Managing IAM (Identity and Access Management) for controlling access to AWS resources. Performing routine tasks like backups, patching, and instance management.
Writing Bash, Python, or PowerShell scripts for automation and system administration tasks. Using AWS CLI or SDKs for scripting AWS-specific tasks.
Building Docker images for application containerization. Orchestrating containerized applications using Kubernetes or AWS ECS.
Administering Windows Server and Linux instances on AWS. Configuring and maintaining OS-level security and updates. Expertise in writing Infrastructure as Code (IaC) using AWS CloudFormation templates or AWS CDK for automating resource provisioning.
Proficient in developing AWS Lambda functions for event-driven automation tasks, such as scheduled backups and data processing.
Skilled in designing and implementing CI/CD pipelines using AWS Code Pipeline and AWS Code Build for automated deployment.
Participating in sprint planning, daily stand-up meetings, sprint reviews, and retrospectives.
Understanding agile principles, managing a product backlog, and ensuring incremental development.
Collaborating with product managers, QA engineers, and other cross-functional teams.
Configuring Harness for continuous delivery, automating deployment strategies, and rolling deployments.
Implementing "click ops" to "CICD" transitions, eliminating manual steps in the software release process.
Setting up auto scaling and self-healing mechanisms in cloud environments using infrastructure automation tools.
Depending on the specific tools used, understanding Bitbucket for version control, ServiceNow for IT service management, SonarQube for code quality analysis, and Jenkins plugins for extended functionality.
Integrating and configuring these tools to work seamlessly within the DevOps ecosystem.
Strong Experience on the AWS platform and its dimensions of scalability including VPC, EC2, ELB, S3, and EBS, ROUTE53.
Designed AWS Cloud Formation templates to create custom sized VPC, subnets, and NAT to ensure successful deployment of Web applications and database templates.
Set up and built AWS infrastructure for various resources, VPC EC2, S3, IAM, EBS, Security Group, Auto Scaling, and RDS in CloudFormation JSON templates.
OpenShift virtualized PaaS provider - useful in automating the provisioning of commodity computing resources for cost and performance efficiency.
Automated AWS volume snapshot backups for enterprises using Lambda.
Experienced with event-driven and scheduled AWS Lambda functions to trigger various AWS resources.
Used lambda function for Infrastructure automation like EC2 automated snapshot creation, daily automated reporting of the list of EC2 instances etc.
Environment: AWS (EC2, VPC, ELB, S3, RDS, Cloud watch and Route53, Lambda), Kubernetes, GIT, Maven, Jenkins, Ansible, Terraform, Docker

Softizo Solutions Hyderabad, India
Cloud Engineer May 2013 to Dec 2017
Responsibilities:
Implemented a CD pipeline involving Jenkins, and GIT to set up automation from commit to deployment.
integrated Prometheus and Grafana with other observability tools such as Elasticsearch, Kibana, and Jaeger to provide comprehensive insights into system behavior.
Orchestrated data flows between monitoring tools to centralize observability data.
Implemented Puppet master high availability (HA) and failover solutions to ensure continuous configuration management service.
Utilized Prometheus and Grafana to troubleshoot incidents and outages, quickly identifying root causes and minimizing downtime.
Established incident response playbooks that included steps for leveraging monitoring data effectively.
Developed and maintained dashboards and reports to track SLO compliance and reliability metrics.
Collaborated with security teams to implement security best practices, vulnerability assessments, and threat detection strategies.
Ensured compliance with industry regulations (e.g., GDPR, HIPAA) and internal security policies.
Created and maintained documentation for configurations, procedures, and incident response playbooks.
AWS Data Pipeline: A web service for orchestrating and automating the movement and transformation of data between different AWS services and on-premises data sources.
AWS Glue Data Brew: A visual data preparation tool that makes it easy for users to clean and transform data for analytics and machine learning.
implemented advanced AEM workflows and automation using ACS AEM Commons, reducing manual tasks, and increasing content publishing efficiency.
Contributed to the ACS AEM community by sharing knowledge, code samples, and best practices through blog posts, forums, and open-source contributions.
Proficient in Linux/Unix admin for CentOS, and Ubuntu. Expertise in provisioning, config, and maintenance.
Skilled in Bash/Python scripting for automation, monitoring, and task streamlining.
Implement security practices, firewalls, SSL/TLS certificates, and intrusion detection.
Experience in developing and maintaining Python applications.
Strong understanding of core Python concepts, data structures, and algorithms.
Familiarity with Python libraries and frameworks for various purposes (e.g., data analysis, web development, automation).
Worked on various Cloud services, AWS being the cloud partner.
Implemented CI/CD pipelines using Jenkins, Maven, Nexus, GitHub, and AWS.
Installed and configured Jenkins for Automating Builds and Deployments through integration to automate the code check-out.
Developed build and deployment scripts using Ant and Maven as build tools and integrated with Jenkins to move from one environment to other environments.
Administered multiple Pre-Production environment configurations, controls, code deployments, and code integrity using tools such as GIT, and Jenkins.
Configured Build and Release pipeline for application servers such as Apache Tomcat, client Java-based applications, and Jenkins.
Involved in all the activities related to the build, packaging, deployment, and maintenance of the applications.
Single point of contact for any Build-Release and Environment-related requirements or issues.
Handled the build and release of software baselines, code merges, branch and label creation in Subversion/GIT and interfaced between development and infrastructure.
Environment: AWS, GCP, Ansible, GIT, Jenkins, CI/CD, Docker, Linux, Nexus, Maven
Contact this candidate