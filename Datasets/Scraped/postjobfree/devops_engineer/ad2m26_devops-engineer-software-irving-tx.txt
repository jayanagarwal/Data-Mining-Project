Name: Dhyana Sai Reddy Dalli
Number: 469-***-****
Email: ad2m26@r.postjobfree.com
AWS Cloud DevOps Engineer

PROFESSIONAL SUMMARY:
Overall 10+ years of professional experience in the areas of AWS DevOps, Build and Release Engineer in automating, building, deploying, and releasing code from one environment to another environment.
AWS Certified DevOps Engineer Professional, Expertise in AWS Services such as EC2, ELB, VPC, S3, CloudFront, IAM, RDS, Route 53, ECR, ECS, CloudWatch, SNS, LAMBDA, GLUE.
Experience on complete software development life cycle (SDLC) and software development models like Agile and Waterfall methodologies.
Experience working in a variety of professional system support and solution-based IT services for Linux Systems, AWS, and AZURE DevOps.
Responsible for building and maintaining automated CI/CD pipelines using hosted cloud-based services in AZURE and AWS.
Excellent background in multi-cloud technologies AWS and Microsoft AZURE Cloud Services, recent hands-on GCP (APIGEE Edge).
Proficiency in Airflow, DAG, Data flow, cloud pub/sub.
Implement and maintain container-based application services using AWS Kubernetes Service (EKS) or Azure Kubernetes Service (AKS).
Set up a GCP Firewall rules to allow or deny traffic to and from the VM's instances based on specified configuration and used GCP cloud CDN (content delivery network) to deliver content from GCP cache locations drastically improving user experience and latency.
Experience in providing highly available and fault tolerant applications utilizing orchestration technologies like Kubernetes and Apache Mesos on Google Cloud Platform.
Expertise in creating Kubernetes cluster with cloud formation templates and deploying them in AWS environment and monitoring the health of pods using Helm Charts.
Worked extensively on automation engine Ansible that automates cloud provisioning, configuration management, application deployment.
Extensively involved in infrastructure as code, execution plans, resource graph and change automation using Terraform. Managed AWS infrastructure as code using Terraform.
Experience using Jenkins with version control systems tools like GIT, SVN and build tools like ANT & MAVEN to automate the build steps for daily operations.
Extensively worked on Jenkins, Docker for continuous integration and for End-to-End automation for all build and deployments.
Experience in DevOps, Automation with Docker and Continuous Deployment procedures using tools such as Docker-machine, Docker-compose.
Installed, Configured, and automated the Jenkins Build jobs for Continuous Integration and AWS Deployment pipelines using various plugins like Jenkins EC2 plugin and Jenkins Cloud Formation plugin.
Experience in monitoring tools like AppDynamics, DataDog, Splunk, Dynatrace, Prometheus.
Experience in Configuring, Deploying application artifacts on application stack on middleware tools such as Jboss, Apache Tomcat, Web Server, WebSphere.
Installing, Configuring and Managing of RDBMS, NoSQL tools such as SQL Server, MySQL, PostgreSQL, and Mongo DB.
Proficient in Installation of VMware ESX server and creation of VMs and install different guest OS.
Expertise in scripting for automation, and monitoring using Shell, Python and Perl scripts. Used Golang in generating API’s that interact with front-end applications, also used for writing lightweight microservices.

TECHNICAL SKILLS:

Hadoop Technologies
Map Reduce, Spark, SparkSQL, Azure, Spark Streaming, Kafka, PySpark,,Pig, Hive, HBase, Flume, Yarn, Oozie, Zookeeper, Hue, Ambari Server
Languages
HTML5,DHTML, WSDL, CSS3,C, C++, XML,R/R Studio, SAS Enterprise Guide, SAS,R (Caret, Weka, ggplot), Perl, MATLAB, Mathematica, FORTRAN, DTD, Schemas, Json, Ajax, Java, Scala, Python (NumPy, SciPy, Pandas, Gensim, Keras), Java Script, Shell Scripting
NO SQL Databases
Cassandra, HBase, MongoDB, MariaDB
Web Design Tools
HTML, CSS, JavaScript, JSP, jQuery, XML
Development Tools
Microsoft SQL Studio, IntelliJ, Azure Databricks, Eclipse, NetBeans.
Public Cloud
EC2, IAM, S3, Autoscaling, CloudWatch, Route53, EMR, RedShift
Development Methodologies
Agile/Scrum, UML, Design Patterns, Waterfall
Build Tools
Jenkins, Toad, SQL Loader, PostgreSQL, Talend, Maven, ANT, RTC, RSA, Control-M, Oozie, Hue, SOAP UI
Reporting Tools
MS Office (Word/Excel/Power Point/ Visio/Outlook), Crystal reports XI, SSRS, cognos.
Databases
Microsoft SQL Server 2008,2010/2012, MySQL 4.x/5.x, Oracle 11g, 12c, DB2, Teradata, Netezza
Operating Systems
All versions of Windows, UNIX, LINUX, Macintosh HD, Sun Solaris

WORK EXPERIENCE:
Client: Shaw Systems, Houston, TX October 2022 – Present
Role: Sr. AWS / DevOps Engineer

Responsibilities:
Implemented and managed AWS Control Tower to automate account provisioning and management for multiple AWS accounts. Created and managed AWS Control Tower landing zone to provide a secure and compliant foundation for multiple AWS accounts.
Designed and implemented authentication and access control solutions using AWS Control Tower, AWS Organizations, AWS Single Sign-On, and Amazon Cognito. Configured and managed AWS Web Application Firewall (WAF) and AWS Shield to protect web applications and mitigate DDoS attacks.
Configuring new workloads within CSP (e.g., AWS Accounts, Azure Subscriptions/Resource Groups, CSP Policies and Security Controls) also Configuring and troubleshooting CSP networking services (e.g., VNETS, Private Links, Gateways, Load balancers)
Configuring and integrating Terraform with cloud provider APIs, such as AWS, Azure, and Google Cloud, to automate the provisioning of infrastructure resources.
Developing and maintaining Terraform modules to abstract and standardize the provisioning of infrastructure resources across multiple environments. Developing and implementing automated deployment scripts and configuration management tools, such as Ansible and Puppet, to automate the deployment process.
Designing and implementing CI/CD pipelines to automate the software development process and ensure fast, reliable, and secure software releases, also implementing best practices for code branching, version control, and code review to ensure high-quality software releases.
Configuring and managing deployment infrastructure, such as Kubernetes clusters, to enable fast and reliable software deployments.
Lead incident management, involving other support organizations and outside vendors, analyze workloads, identify optimization opportunities.
Ensuring all systems comply with security patching and vulnerability recommendations and that sufficient automation tools exist to ease administration overhead.
Research, audit, test, and set standards for AWS and Azure cloud deployment frameworks and best practices to ensure compatibility and functionality in the enterprise.
Independently develop reference materials (network diagrams, installation documentation, etc.) for supported cloud technologi es to be used for both online and in-person training of other technical staff.
Report on the health of cloud services to leadership, providing detailed information around both lifecycle and cost management.
Make recommendations for improvements to security, scalability, manageability, and performance across a wide variety of cloud network, storage, and computer technologies.
Formulate detailed network, storage, and compute design specifications for stable and secure computing operations in a dynamic cloud-based environment.
Liaise with customers, architecture leadership and technical teams, including systems and network administrators, security engineers, and IT Support teams.
Build and configure build plans, code pipelines, and create automated solutions that can be frame worked and re-used.
Evaluating, Designing, Developing and Building PoC and Architect Infrastructure solutions

Experience: AWS, AWS LAMBDA, AWS Shield, AWS Web Application Firewall, AWS Cognito, AWS Control Tower, Ansible, Puppet, Terraform, Azure, Google Cloud Platform, Kubernetes Clusters, ELB, Jenkins, IAM, VPC, RDS, Puppet, JIRA, Python, EC2, Agile DevOps

Client: Medline Industries, Chicago, IL April 2020 – September 2022
Role: Azure/GCP DevOps Engineer

Responsibilities:
Designing, planning and implementation for existing on-premises applications to AZURE Cloud (ARM), Configured and deployed Azure Automation Scripts utilizing Azure stack Services and Utilities focusing on Automation.
Migrating on-prem and Hybrid-cloud applications (IBM ACE, Google APIGEE Edge/X) to Azure/GCP, configured management plane on GCP and Runtime plane on Azure, setup Ingress and Egress using Istio Service mesh and performed PowerShell scripting to do Patching, Imaging, and Deployments in Azure.
Deployed and monitored scalable infrastructure on Amazon web services (AWS) and configuration management instances and Managed servers on the Amazon Web Services (AWS) platform using Chef configuration management tools and Created instances in AWS and migrated data to AWS from the Data Center.
Involved in design and deployment of a multitude of Cloud services on AWS stack such as EC2, Route53, S3, RDS, Dynamo DB, SNS, SQS,IAM, LAMADA, GLUE, while focusing on high-availability, fault tolerance, and auto-scaling in AWS CloudFormation.
Managing the Azure Kubernetes Services (AKS) policies, providing access to different Azure resources and developing and improving the workflows that govern access.
Deploying CI/CD system using Azure DevOps on Kubernetes container environment, and for the runtime environment of CI/CD system to build, test and Deployment using Kubernetes and Docker.
Provisioning servers/instances using infrastructure-as-code in Terraform. Code is stored in a private repository and constantly updated.
Structured cluster AutoScaler for Azure Kubernetes Service (AKS) using Terraform and worked with scheduling, deploying, and managing pods and replicas in AKS.
Terraform was used along with Packer to create custom machine images, Ansible to install the software dependencies once the infrastructure is provisioned.
Worked on Terraform templates for provisioning virtual networks, subnets, VM Scale sets, Load balancers, and NAT rules and used terraform graph to visualize execution plan using the graph command. Configured BGP routes to enable ExpressRoute connections between on-premises data centers and Azure cloud.
Kubernetes Cluster management of cloud/on-premises environments with master/minion architecture and wrote YAML files to create many services like pods, deployments, auto scaling, load balancers, labels, health checks etc.
Configured Jfrog Artifactory (local, virtual, remote) as a medium to import container images from External registry to K8’s services.
Used Splunk APM for log aggregation and analysis on different application servers and integrated Splunk with Single Sign-On authentication and Service now ticketing tool.
Integrated Docker with Jenkins to automatically build containers and then auto deployment of containers using Kubernetes. Developed build and deployment scripts using Maven and ANT as build tools in Jenkins to move from one environment to other environments,
Integrated GIT into Jenkins to automate the code check-out process. Developed GIT hooks for the local repository, code commit and remote repository, code push functionality and on GitHub

Environment: Azure Stack Services, Istio, Service Mesh, EC2, Route53, S3, RDS, Dynamo DB, SNS, SQS,IAM, LAMBDA, GLUE, AKS, CI/CD, Kubernetes, Docker, Ansible, Terraform, JFrog, Splunk, Jenkins, Maven, ANT, GIT, GitHub.

Client: Tailored Brands, Fermont, CA August 2018 - March 2020
Role: Azure Cloud/Site Reliability Engineer

Responsibilities:
Responsible for Setup and building AWS infrastructure using resources VPC, EC2, S3, RDS, Dynamo DB, IAM, EBS, Route53, SNS, SES, SQS, CloudWatch, CloudTrail, Security Group, Autoscaling, and RDS using CloudFormation templates.
Developed strategy for cloud migration and implementation of best practices using AWS services like database migration service, AWS server migration service from On-Premises to cloud.
Implemented and maintained the monitoring and alerting of production and corporate servers/storage using AWS CloudWatch and assigned AWS elastic IP addresses to work around host or availability zone failures by quickly remapping the address to another running instance.
Provisioned the highly available EC2 Instances using Terraform and cloud formation and wrote new python scripts to support new functionality in Terraform.
Deployed pods using Replication Controllers by interacting with Kubernetes API server defining through declarative YAML files.
Worked in cloud formation to automate AWS environment creation along with the ability to deploy AWS using bill scripts (Boto3 and AWS CLI) and automate solutions using python and shell scripting.
Designed AWS Cloud Formation templates to create custom sized VPC, to set up IAM policies for users, subnets, NAT to ensure successful deployment of Web applications, database templates and Security group.
Wrote Ansible playbooks from scratch in YAML. Installing, setting up & Troubleshooting Ansible, created and automated platform environment setup, Refined automation components with scripting and configuration management using Ansible.
Managed Docker orchestration and Docker containerization using Kubernetes. Used Kubernetes to orchestrate the deployment, scaling, and management of Docker Containers.
Developed build and deployment scripts using MAVEN as build tools in Jenkins to move from one environment to other environments and Supporting Maven multi-module builds and store artifacts in a remote repository in artifacts.
Worked on writing Jenkins build a pipeline with Gradle script and Groovy DSL (Domain Specific Language) and integrating ANT/MAVEN build scripts with Gradle for the sole purpose of continuous build.
Built and maintained ELK stack to centrally collect logs used to monitor applications also Installed, monitored, and configur ed Applications in Nginx and Apache Tomcat Server and established connectivity to databases and troubleshoot issues on the fly.
Worked on google cloud platform (GCP) services like compute engine, cloud load balancing, cloud storage, cloud SQL, stack driver monitoring, and cloud deployment manager.
Setup GCP Firewall rules to allow or deny traffic to and from the VM's instances based on specified configuration and used GCP cloud CDN (content delivery network) to deliver content from GCP cache locations, drastically improving user experience and latency.

Environment: AWS infrastructure, VPC, EC2, S3, RDS, Dynamo DB, IAM, EBS, Route53, SNS, SES, SQS, CloudWatch, CloudTrail, Security Group, Autoscaling, RDS, database migration service, AWS server migration service, Terraform, Python, Kubernetes, Boto3, Ansible, Docker, Maven, ANT, Nginx, Groovy, Apache Tomcat, ELK stack.

Client: Chewy, Dania Beach – FL January 2017 - July 2018
Role: AWS DevOps/Build-Release Engineer

Responsibilities:
Worked with AWS services using S3, RDS, EBS, Elastic Load Balancer, Auto-scaling groups, EC2 instances with optimized volumes and achieved cloud automation and deployments using Chef, Python, and AWS Cloud Formation Templates.
Worked with AWS CLI and AWS API to manage resources on AWS for many services such as EC2, S3, VPC, Cloud Watch, ELB, Auto- scaling, created python script using AWS API Calls to manage all resources deployed on AWS.
Configured AWS IAM and Security Groups in Public and Private Subnets in VPC Managed IAM accounts (with MFA) and IAM policies to meet security audit & compliance requirements.
Provided high durability of the available data using data stored in the AWS S3 bucket, versioning S3, lifecycle policies. Also, web hosting the data from the S3 bucket by creating URLs.
Utilized AWS CLI to automate backups of ephemeral data-stores to S3 buckets, EBS and create AMIs for mission-critical production servers as backups and used AWS Beanstalk for deploying and scaling web applications and services developed with Java, Node.js, Python and Ruby on familiar servers like Apache, Nginx, Tomcat.
Terraform as infrastructure as code, execution plans, resource graph, and change automation—Managed AWS infrastructure as code using Terraform.
Deployed and configured Elasticsearch, Logstash, and Kibana (ELK) for log analytics, full-text search, application monitoring in integration with AWS Lambda and CloudWatch.
Wrote Pyspark scripts to apply hard quality checks on data at record level to generate reports to end users and automate the same through AWS Apache Airflow
Configuring the Docker containers and creating Docker files for different environments.
Created private cloud using Kubernetes that supports DEV, TEST, and PROD environments.
Creating clusters using Kubernetes and making many pods, replication controllers, deployments, labels, health checks, and ingress by writing YAML files.
Used Jenkins and pipelines to drive all microservices builds out to the Docker-registry and then deployed to Kubernetes, Created Pods, and managed using Kubernetes.
Installed, Configured, Managed Monitoring Tools like AppDynamics, Data Dog.

Environment: : S3, RDS, EBS, Elastic Load Balancer, Auto-scaling groups, EC2 instances, Chef, Python, AWS Cloud Formation Templates, AWS CLI, AWS API, IAM, VPC, Apache, Nginx, Tomcat, Java, Node.js, Ruby, Kibana, Logstash, Elasticsearch, Terraform, AWS Lambda, Pyspark, Apache Airflow, Kubernetes, Jenkins, AppDynamics, Datadog.

Client: Konoha Solutions, Hyderabad June 2013 - October 2016
Role: Linux / DevOps Engineer

Responsibilities:
Involved in authoring pom.xml files, performing releases with Maven release plugins, and managing artifacts in Maven internal repository.
Designed and set up CI/CD pipeline to deploy containerized applications in the servers.
Used Jenkins on a Linux environment and implemented a Master and Slave configuration to run multiple build operations in parallel.
Used JIRA to track issues and Change Management.
Launched Amazon EC2 Cloud Instances using Amazon Web Services (Linux/Ubuntu) and configured launched instances with respect to specific applications.
Designed and implemented fully automated server build, management, monitoring, and deployment solutions spanning multiple platforms, tools, and technologies.
Performed all necessary day-to-day GIT support for different projects. Implemented and maintained the branching and build and release strategies utilizing GIT.
Used Python scripts to update content in the database and manipulate files.
Deployed code through SVN and GitHub.
Installation, Configuration, and Administration of Jenkins for continuous integration and Continuous Deployment.
Deployed new Linux servers, configured the servers, and Installed Apache Tomcat, and Apache Webserver.
Coordinated with different teams and customers to get approvals regarding planned maintenance.
Deployed the code in production, UAT, PT, development servers.
Worked with internal customers DBA and App teams to support their databases and applications.

Environment: Maven, CI/CD, Jenkins, Linux, JIRA, Amazon EC2, GIT, SVN, python, Apache Tomcat, GitHub, Apache Webserver, servers, database.
Contact this candidate