Rohan D
Sr DevOps Engineer
Email: ad3ar5@r.postjobfree.com
Phone: 512-***-****

Professional Summary
9+ years combined experience in IT, Systems Engineering, Cloud Engineering, Management, and DevOps Engineering.
Hands-on with AWS Services such as EC2, ELB, Auto Scaling, S3, VPC, Route 53, CloudWatch, and IAM Roles and Policies
Build and deploy applications by adopting DevOps practices such as Continuous Integration (CI) and Continuous Deployment/ Delivery (CD).
Use Application Load Balancer with Auto Scaling Group of EC2 Instances and RDS.
Proven skillful at troubleshooting issues that arise during building, deploying, and the production support and documenting phases of the build and release process.
Holding extensive experience as an SRE, DevOps, and Cloud Developer in Python, Java, JavaScript, and cloud services such as AWS, and Azure. Have solid experience in the Software Development Life Cycle (SDLC) process which incorporates Requirement gathering, Analysis, Developing, Large scale production implementations, maintenance, and Testing.
Hands-on with Terraform for infrastructure as code versioning and management.
Work with version control systems like GIT and Source code management client tools like GitHub, GitLab, and Bitbucket.
Experience with GitLab building automation runner in building Docker images.
Hands-on with Containerization tools such as Docker and Kubernetes.
Hands-on with security practices IAM, CloudWatch.
Adept with various distributions of Virtualization, Cloud, and Linux.
Manage IT annual budget and internal IT process
Manage IT Teams like Infrastructure, Developers, PMO, Support
Manage and Lead infrastructure migration to Azure Cloud
Proven expertise in scripting with Bash, and Python.
Knowledge of utilizing cloud technologies including Amazon Web Services (AWS) and Microsoft Azure.
Experience in Bug tracking and Project tools like JIRA.
Manage and support the development and production environment databases
Hands-on PowerBI and Data Modelling
Proven IT support tier 2 and tier 3 for manufacturing production environments

Technical Skills:
PROGRAMMING LANGUAGES
Python, JavaScript, C, C++
DEVOPS
Docker, Ansible, Kubernetes, ELK, Jenkins, Argo CD, Subversion, GIT, CI/CD, Terraform, Argo CD, Prometheus, Grafana.
CLOUD
AWS, Azure, GCP
SCRIPTING
Python, UNIX, Shell scripting, LINUX, SSH, YAML
NETWORK PROTOCOLS
HDFS, SMTP, SNMP, ICMP, TCP/IP, FTP, TELNET, UDP, and RIP, iSCSI, NIS, NFS, DNS, DHCP, Cisco Routers/Switches, WAN, LAN, NAS. SAN
DATABASES
Microsoft SQL Server Database, MySQL, PostgreSQL, Databricks, Amazon Redshift, Cassandra, NoSQL MongoDB, Cosmos DB, RDS Database normal forms and data warehouse models, Redshift.
Web Technologies
Azure Kusto Explorer, AWS, PyCharm, Jupyter Notebook, MySQL, Cloud Formation, PowerShell, GIT, Data Analytics, HTML, XML, Oracle, Object Oriented Programming, Object Oriented Design, Agile., Ngnix
Operating Systems
Unix/Linux, Ubuntu, Amazon Linux, Red Hat Linux, CentOS, Windows, MS Server, Windows Server

Professional Experience

Client: Fancy Robotics, Michigan April 2022 – Till Date
Role: Sr DevOps Engineer
Responsibilities:

Hands-on with AWS Services such as EC2, ELB, Auto Scaling, S3, VPC, Route 53, CloudWatch, and IAM Roles and Policies.
Designed, configured, and deployed Amazon Web Services (AWS) for multiple applications using the AWS stack (EC2, Route53, VPC, S3, RDS, Cloud Formation, Cloud Watch, SQS, IAM) with a focus on high availability, fault tolerance, and auto-scaling.
Designed, developed, and monitored robust data pipelines utilizing a range of cloud-based services and open-source technologies to enable effective and consistent data ingestion, processing, and storage.
Engaged with data engineering teams from various Lines of Business to gather requirements, find data sources, and develop data pipelines that enabled a range of analytical use cases, including real-time analytics and data warehousing, suitable to particular business requirements.
Utilized Boto3, Terraform, Ansible, and servers with Datadog and Splunk to deploy, monitor, and troubleshoot AWS resources.
Used Jenkins and other continuous integration platforms to schedule and automate build operations, and combined Jenkins with shell or Python scripting to automate repetitive tasks.
Developed, maintained, and improved Amazon Lambda functions and EMR clusters, making sure they aligned with best practices and met service-level goals.
Constantly tracked and analysed Lambda and EMR performance, finding areas for improvement and putting them into practice to ensure effective resource use and cost reductions.
Developed and deployed cloud architectures that are highly scalable, fault-tolerant, and economical using AWS services including EKS, ECS, EC2, S3, RDS, SQS, SNS, DynamoDB, Route53, EBS, and ELB/ALB.
Debugged and troubleshot Terraform deployment.
Defined AWS Security Groups that acted as virtual firewalls that controlled traffic allowed to reach one or more AWS EC2 instances.
Configured, deployed, and managed Docker containers using Kubernetes.
Successfully migrated containerized environment from ECS to Kubernetes Cluster.
Provided other storage solutions such as S3, EBS, EFS, etc.
Configure and manage the ELK Stack for centralized logging, log analysis, and monitoring.
Wrote Terraform Templates for AWS infrastructure-as-Code to build staging and production environments.
Created and maintained highly scalable and fault tolerant multi-tier AWS environments spanning across multiple availability zones using Terraform.
Conducted regular audits of IAM settings to identify and remediate security risks, ensuring compliance with security standards.
Build and deploy applications by adopting DevOps practices such as Continuous
Integration (CI) and Continuous Deployment/ Delivery (CD) in runtime with various CI tools such as Jenkins, and Ansible.
Design and architect scalable and resilient microservices-based systems to meet business requirements and ensure high performance.
Implemented real-time data processing pipelines to handle streaming data for AI-driven features.
Developed, implemented, and maintained RESTful APIs using best practices, ensuring efficient communication between microservices and external systems.
Implemented microservices using technologies such as Spring Boot, Node.js, or other frameworks, adhering to established design principles and coding standards.
Proven skill at troubleshooting issues that arise during building, deploying, and the production support and documenting the build and release phases
Used Application Load Balancer with Auto Scaling Group of EC2 Instances and RDS, and AWS CloudFormation Service
Hands-on with Terraform and CloudFormation for infrastructure as code versioning and management
Deployed web applications on AWS S3 served through CloudFront and Route 53 using AWS CloudFormation.
Continuously monitor the performance of the graph database solution and associated AWS services, identifying opportunities for optimization and efficiency gains.
Designed, deployed, and managed Azure Kubernetes Service clusters for containerized applications.
Optimize AKS configurations for scalability, performance, and efficient resource utilization.
Created, customized, and managed custom images for virtual machines in Azure.
Configured and managed Azure Network Load Balancer for distributing incoming network traffic across multiple backend resources.
Conducted a thorough assessment and discovered existing applications and workloads on Pivotal Cloud Foundry to understand dependencies, configurations, and resource requirements.
Developed a comprehensive migration strategy outlining the approach, timeline, and key milestones for migrating applications from PCF to Azure AKS.
Optimized NLB configurations for high availability and performance.
Administered and maintained Active Directory Federation Services for federated identity and single sign-on solutions.
Troubleshoot and resolve ADFS-related issues.
Design and implement Azure Key Vault solutions for centralized and secure key management.
Integrate Azure Key Vault with applications and services for secret and key retrieval.
Implement image versioning and maintain a library of standardized images.
Implement and manage service discovery using Clutch, ensuring that services can be easily discovered and accessed within the infrastructure.
Implement automation workflows using Clutch to streamline and automate routine infrastructure tasks and procedures.
Design and implement infrastructure solutions to support AI/ML workloads, ensuring scalability, performance, and optimal resource utilization.
Integrate AI/ML frameworks (e.g., TensorFlow, Pytorch) with the underlying infrastructure, optimizing the environment for training and inference.
Implement containerization solutions (e.g., Docker, Kubernetes) for AI/ML applications, enabling portability and scalability.
Designed, deployed, and managed Kafka clusters, ensuring high availability, scalability, and fault tolerance.
Configured and optimized Kafka producers and consumers, considering factors such as batch size, compression, and acknowledgment settings.
Designed, implemented, and maintained a comprehensive Service Catalog, including the organization's services, products, and resources.
Manage the service Catalog in Backstage, ensuring accurate representation of all services and components in the organization.
Developed end-to-end solutions using Django and Flask frameworks for the backend, and modern frontend technologies for a responsive user interface.
Designed and maintained the CMDB, ensuring accurate tracking of configuration items and their relationships within the enterprise.
Developed and optimized GrepQL queries for graph-based data querying and analysis.
Integrate Grafana with various data sources, including Prometheus, InfluxDB, and others, for real-time data visualization.
Monitored the performance of Nginx and load balancers, analyzing logs and metrics to identify bottlenecks and areas for improvement.
Troubleshoot issues related to Nginx and load balancing, collaborating with system administrators, developers, and network engineers to resolve problems promptly.
Monitored and optimized resource utilization on Nginx servers, ensuring efficient use of CPU, memory, and network bandwidth.
Developed and deployed automation scripts or integrated Nginx into deployment pipelines for seamless application updates and rollbacks.
Implemented metrics collection for Nginx, integrating with monitoring solutions like Prometheus or StatsD.
Implement anomaly detection mechanisms for Nginx logs and metrics to identify unusual patterns or potential security threats.
Conduct manual and automated web application security testing using Burp Suite, including vulnerability scanning, session analysis, and parameter manipulation.
Investigated and troubleshooted OS-related issues, working closely with support teams and vendors to resolve complex problems.
Collaborate with penetration testers and developers to address identified security issues.
Utilize OWASP ZAP Proxy for automated and manual security testing of web applications.
Integrate ZAP Proxy into the development lifecycle for continuous security testing.
Designed, developed, and implemented APIs using the Apigee platform, ensuring adherence to best practices and standards.
Established and enforced an API governance framework within Apigee, ensuring compliance with organizational policies and industry standards.
Proven expertise in scripting with Perl, Groovy, and Python programming languages
Hands-on with Containerization tools such as Docker and Kubernetes
Hands-on with security practices IAM, CloudWatch, and CloudTrail
Adept with various distributions of Virtualization, Cloud, and Linux
Environment: DevOps, SVN, CVS, AWS, Ansible, Terraform, SonarQube, Jenkins, Docker, Kubernetes, Tomcat, Shell, Perl, TFS, JFrog, JIRA, Windows and LINUX.

Client: Lexmark, Remote Jan 2020 – April 2022
Role: AWS DevOps Engineer
Responsibilities:

Designed and managed public and private cloud infrastructures using AWS, which includes VPC, EC2, S3, Cloud Front, Elastic File System, RDS, Direct Connect, Route53, Cloud Watch, Cloud Trail, and IAM. Operations were automated using Cloud Formation.
Set up CI/CD pipelines so that each commits a developer makes goes through the standard software development lifecycle and gets tested well enough before it can make it to production.
Implemented Cloud Infrastructure as a service environment using open-source technology OpenStack to enable portability of cloud services across hybrid cloud environments.
Deployed AWS Infrastructure with IaC using Terraform as well as Cloud Formation on some of the legacy applications.
Integrated API Gateway with other AWS services, such as AWS Lambda, AWS Cognito, and AWS IAM, to enhance functionality and security.
Optimized API Gateway configurations to manage costs effectively, considering factors such as data transfer and request rates.
Automated continuous Integration builds, deployments, and unit tests across multiple different environments (DEV, QA, Training, Production) each constituting different types of servers (DB, App, Web) With varying numbers of servers for each type (for load balancing and such) using VSTS Build, Power Shell, and MS Build, MS Deploy
Used 50 sources to pull data into Power BI such as SQL Server, SAP BW, Oracle, SQL Azure, etc.
Database creation (DDL, DML, DCL), database tuning, SQL tuning, and performance planning. Extensively used Joins and Sub-Queries to simplify complex queries involving multiple tables.
Monitored and tracked deployments. Wrote PowerShell scripting for task automation and to schedule tasks.
Led the migration of infrastructure provisioning from ARM templates and PowerShell scripts to Terraform.
Develop and maintain Terraform code for provisioning and managing infrastructure resources across multiple environments.
Developed and implemented comprehensive backup strategies for critical systems and data, ensuring regular backups and adherence to data retention policies.
Performed performance-tuning activities at the OS layer to optimize resource utilization and enhance overall system performance.
Maintained and enhanced existing COBOL applications in legacy systems, ensuring they meet current business requirements and standards.
Designed, developed, and implemented ETL processes using AWS Glue to move and transform data between different data sources and destinations.
Managed and maintained the AWS Glue Data Catalog, ensuring accurate metadata for datasets and supporting data discovery across the organization.
Evaluated and selected an appropriate graph database solution based on project requirements, considering factors such as performance, scalability, and compatibility with AWS services.
Designed and implemented effective graph data models, ensuring optimal representation of relationships and efficient query performance.
Used Git version control to keep track of issues.
Target deployments of AWS infrastructure to Dev, QA, and Prod environments using Terraform code.
Worked with the development team to migrate Ant scripts to Maven and work on authoring POM.XML files, performing releases with the Maven release plugin, and managing Maven repositories.
Developed automation scripting in Python to deploy and manage Java applications across Linux servers.
Worked on customization of existing Python scripts of some of the internal applications.
Utilized AWS step-function for orchestrating and automating the pipeline.
Developed scripts for AWS orchestration, maintenance, and expansion of AWS infrastructure.
Branch, tag, and maintain the version across the environments using SCM tools like GIT, Subversion (SVN), and TFS.
Implemented caching strategies on Nginx to improve performance and reduce the load on backend servers, considering factors like cache duration and cache purging.
Configured Nginx as a Web Application Firewall to protect against common web application vulnerabilities and attacks.
Implement content compression on Nginx to optimize bandwidth usage and improve the performance of content delivery.
Created Ansible playbooks to automatically install packages from a repository to change the configuration of remotely configured machines and to deploy new builds.
Collaborated with Azure and PCF platform teams, ensuring alignment and coordination throughout the migration process.
Environment: WebSphere Application Server 5.x/6.x/7.x/8.x, Dell Servers, Maven, AWS, Power Shell, Red Hat Linux 6, Oracle RAC, Ubuntu, Puppet, Tomcat Server, Nginx, API Platforms, Cloud Foundry, Apigee, SOAP UI, Cassandra, Kafka, Docker, Mesos, Marathon.
Company: Voya, New York, NY July 2017 – Jan 2020
Role: DevOps Engineer
Responsibilities:
Implementing AWS Lambda functions to run scripts in response to events in Amazon DynamoDB table, S3 buckets, and HTTP requests using Amazon API Gateway.
Written Python scripts to automate AWS services which include Web servers, ELB, Cloud Front distribution, Database, EC2, database security groups, and S3 bucket.
Using Amazon IAM to grant fine-grained access to AWS resources to users. Also, manage roles and permissions of users to AWS accounts through IAM.
Integrating Amazon Cloud trail with Amazon EC2 instances for monitoring the EC2 instance usage using AWS Instance Scheduler.
Using Ansible Tower which provides an easy-to-use visual dashboard, role-based access control, job scheduling, integrated notifications, and graphical inventory management that allows use of Ansible for their deployment.
Managed Microservices using Docker to quickly spin up into production environment and auto-scaling them and orchestration using Amazon EC2 container service (ECS) and deploy it to an Amazon EC2 instance using launch configuration templates
Effectively met the organization's demands for cloud infrastructure, provisioned and monitored a broad range of AWS services, including EC2, Lambda, S3, ECS, Glacier, ELB, DynamoDB, Route53, ALB, Auto scaling Group, RDS, SNS, SQS, and EBS.
Python operations, reporting, data analysis, and web apps have been expertly designed, implemented, and debugged for optimum efficiency and usefulness.
Utilized DevOps tools like JFrog and SonarQube to create an effective workflow, as well as Continuous Integration tools like Jenkins for automating and scheduling build operations.
Configured security groups, network ACLs, Internet Gateways, NAT instances, and Route tables for the organization in the AWS public cloud, employing automation via Terraform and Cloud Formation scripts.
Configured and managed Nginx as a reverse proxy to handle incoming client requests and distribute them to backend servers.
Implemented SSL/TLS termination on Nginx, managing certificates and ensuring secure communication between clients and backend servers.
Implemented and managed the NIST Risk Management Framework (RMF) to identify, assess, and mitigate security risks across the organization.
Implemented and maintained NIST SP 800-53 security controls to ensure compliance with security requirements.
Implement and manage the Center for Internet Security (CIS) Critical Security Controls to enhance cybersecurity posture and protect critical assets.
Conduct risk assessments based on ISO 27005, identifying and treating information security risks by the ISO framework.
Conduct static application security testing (SAST) using Checkmarx to identify and remediate security vulnerabilities in source code.
Perform dynamic application security testing (DAST) using IBM AppScan to identify and exploit vulnerabilities in web applications.
Developed RESTful web services, and developed a web-based dynamic J2EE application. Applied Spring MVC architecture to establish control flow between user interfaces, database, and the Java servlets.
Using Elasticsearch, Logstash, and Kibana (ELK stack) for centralized logging and analytics in the continuous delivery pipeline to store logs and metrics into an S3 bucket using the lambda function
Implementing a Completely Containerized automated process to set up Jenkins servers over various AWS accounts, using Docker, and CloudFormation scripts deployed in AWS EKS.

Environment: AWS Cloud, AZURE, EMR, Red Hat, Linux, Windows, Atlassian Jira, Ansible, Kubernetes, Docker, Jenkins, Open Shift, Splunk, EFK, GitHub, Slack, SharePoint

Client: Infosys, India Oct 2014 – June 2017
Role: DevOps Engineer
Responsibilities:
Worked on continuous integration technologies with Jenkins. Designed and created multiple deployment strategies using Continuous Integration (CI) and Continuous Delivery (CD).
Taking care of Azure infrastructure owned by Clients and organizations. Design, and develop cloud-based applications using the Microsoft Azure cloud platform
Hands-on experience in building, designing& maintaining cloud-based applications with Azure.
Creating Repositories using Azure DevOps.
Involved in Writing Docker files to build customized images for creating containers and also worked on Docker container snapshots, removing images, and managing Docker volumes.
Involved in Designing Azure virtual machines (VMs) and VM architecture for IaaS & PaaS and understanding availability sets, fault domains, and update domains in Azure
Creating Pipelines both YAML-based and Task-based using Azure DevOps.
Using Terraform, resources are provisioned in the Azure portal.
Creating Storage Pool and Attaching Disk for Azure Virtual Machines. Backup Configure and Restore Azure Virtual Machine using Azure Backup.
Responsible for the full development life cycle, including design, coding, testing, and deployment.
Managed the Azure Security groups and attached them to VMs and Subnets using Azure Portal as well as PowerShell Scripts.
Build a CI/CD pipeline using Azure DevOps and Git validated the Build and promoted and deployed the Azure resources into multiple Azure subscription environments.
Monitored the health of Azure resources using Azure Monitor and Azure Service Health.
Extensively involved in Version Control, Build &amp, Release Management and Deployments of the
Solutions to the DEV, QA &amp, PROD Environments leveraging Azure DevOps principles/process (CI/CD) and toolsets of Visual Studio, AKS (Azure Kubernetes Service), Application Insights, and Log Analytics.
Hands-on experience with Kubernetes to automate the deployment, scaling, and operations of application containers across clusters of hosts.
Administered and Engineered Jenkins Pipeline for managing weekly Build, Test, and Deploy chain, SVN/GIT with Dev/Test/Prod Branching Model for weekly releases.
Worked on Ansible core concepts like Inventory, Playbooks, Roles, Tasks, and Modules created inventory in Ansible for automating the continuous deployment, and wrote Playbooks using YAML scripting.
Installed Docker Registry for local upload and download of Docker images and even from Docker Hub and administered monitoring Nagios and maintained it by using Shell scripting.
Installed Docker Registry for local upload and download of Docker images and even from Docker Hub using Jenkins Pipeline, Bamboo deployed Windows application to PCF.

Environment: Red Hat Linux 5.x, 6.x DHCP, DNS, IIS, SMTP, IMAP, LVM, NAS KVM, VERITAS Clusters, AWS, Auto scaling, ELB, Cloud Watch, EBS, Directory Services, Route53, MS SQL 2012, SQL Server Mirroring, Active Directory, DFS
Contact this candidate