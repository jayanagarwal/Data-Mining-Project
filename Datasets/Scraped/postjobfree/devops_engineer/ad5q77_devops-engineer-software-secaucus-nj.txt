Mir Ali
DevOps/AWS Engineer
Visa: US Citizen
Email: ad5q77@r.postjobfree.com
Contact No: 224-***-****

PROFESSIONAL SUMMARY:

Overall, 9 years of Experience IT industry with major focus on Release management, Software Development, Configuration, Build and Release Engineering, DevOps Engineer, Automation Engineer and Cloud Engineer.
Good understanding of the principles and best practices of Software Configuration Management (SCM) in Agile, scrum, and Waterfall methodologies.

Expertise in configuration and automation using Chef, Chef with Jenkins, Puppet, Ansible and Docker.
Hands on experience on Backup and restore Azure services and in Designing and configuring Azure Virtual Networks (VNets), subnets, Azure network settings, DHCP address blocks, DNS settings, security policies and routing. Azure cloud services, Blob storage, Active directory, Azure Service Bus, Cosmos DB.
Experienced working with CI (Continuous Integration) and CD (Continuous Deployment) methodologies using GitLab, Azure DevOps, Git, Bitbucket, Jenkins, Jfrog, SonarQube, Nexus, Argo-CD, Flux, Ansible, puppet and Python in an Agile Environment.
Experienced and passionate in Automation, Continuous Integration, Continuous delivery, configuration management with multi-cloud services. Experienced in network operations, system administration, proficient to dynamic work environment.
Have great experience in Configuring and Deploying instances on Amazon web services (AWS) and experience with AWS components like EC2, ELB, Auto scaling, S3, VPC, Route53, Cloud Watch, Cloud Trial, Cloud Formation Templates.
Experience in installing and administrating CI tools like Jenkins, Bamboo and other tools like Nexus, GitHub like systems, JIRA, Atlassian stack of tools like, Fisheye, Confluence.
Experienced in Azure Kubernetes service to produce production-grade Kubernetes that allow enterprises to reliably deploy and run containerized workloads across private and public clouds.
Good working knowledge on AWS IAM services, IAM policies, Roles, Users, Groups, AWS access Keys and Multi Factor Authentication, and migrated applications to the AWS Cloud.
Hand-On experience in Implementing, Build and Deployment of CI/CD pipelines, managing projects often includes tracking multiple deployments across multiple pipeline stages (Dev, Test/QA staging and production). Implemented CI/CD tools Upgrade, Backup, Restore, API call, DNS, LDAP and SSL setup.
Worked in container-based technologies like Docker, Kubernetes and OpenShift.
Experience in Build/Release/Deployment/Operations (DevOps) engineer with a strong background in Linux/Unix Administration and best practices of SDLC methodologies like Agile, Scrum, waterfall and DevOps/Cloud processes.
Designed Puppet Modules to manage configurations and automate installation process and developed automation scripting in Python using Puppet to deploy and manage Java applications across Linux servers.
Implemented Spring boot micro services to process the messages into the Kafka cluster setup.
Experience in working with EFK, for storing the logs and created production level AWS infrastructure using Terraform.
Used Ansible to run ad-hoc commands and playbooks to automate tasks and written playbooks.
Managed Ansible Playbooks with Ansible roles. Used file module in Ansible playbook to copy and remove files on remote systems.
Wrote Ansible Playbooks with Python SSH as the Wrapper to Manage Configurations of Open stack Nodes and Test Playbooks on AWS instances using Python.
Experience in creating Docker containers leveraging existing Linux Containers and AMI's in addition to creating Docker containers.
Experience in creating the ECS Cluster (Elastic Container Service) to spin up the services in the AWS using Terraform.
Experience with container-based deployments using Docker, working with Docker images, Docker hub and Docker registries, installation and configuring Kubernetes and clustering them.
Good understanding of Design Patterns, Multithreading and GO containers. Well versed in using Channels and goroutines.
Implemented Kubernetes to deploy scale, load balance, scale and manage docker containers with multiple names spaced versions.
Extensively worked on Jenkins, Docker for continuous integration and for End-to-End automation for all build and deployment.
Experience on working with on-premises network, application, server monitoring tools like Nagios, Splunk, AppDynamics and on AWS with CloudWatch monitoring tool.
Experienced in troubleshooting and automated deployment to web end application servers like WebLogic, and Apache Tomcat.
Expertise in implementing DevOps methodologies and practices, streamlining workflows, and driving automation using tools like Git, Jenkins, Bitbucket, Robot Framework/SonarQube, Ansible, Tomcat, WebSphere and Linux, Terraform, and Kubernetes.
Proficiently establishing CI/CD pipelines and Infrastructure as Code (IaC) principles.
Experience in architecting, implementing, and managing cloud-based solutions on Amazon Web Services (AWS), encompassing a wide array of services such as EC2, S3, VPC, RDS, ECS/EKS, Lambda, and more.
Broad experience working in an agile development team to deliver an end-to-end continuous integration/continuous delivery product in an open-source environment.
Extensive work being done in areas of SAAS, PAAS, IAAS.

TECHNICAL SKILLS:

Operating systems
Windows, Linux, Ubuntu, AWS CLI
SDLC
Waterfall model, Agile, Scrum
Languages
Python, Shell scripting, Bash, Groovy, Java, C++, HTML, XML, NodeJS, JavaScript, YAML, JSON
Source code Management
SVN, GIT, Bitbucket, IBM Rational Clear Case, Perforce, GitHub.
Bug Tracking Tools
JIRA, Remedy, Service Now
CI/ CD Tools
Hudson, Jenkins, Bamboo, Team City, Circle CI, Travis CI, Nexus
Configuration Tools
Ansible, Chef, Puppet, Vagrant, Docker, Kubernetes, OPS Work, Terraform, Helm
Networking
VPC, Route 53, LDAP, DNS, FTP, DHCP, SSH, TCP/IP, FTP, SFTP
Databases
MySQL, Mongo DB, Cassandra, PostgreSQL, SQL Server
Monitoring Tools
Splunk, Data dog, Nagios, CloudWatch
Build Tools
Ant, Maven, Gradle
Cloud Services
Amazon Web services, Microsoft Azure.
Web/App Servers
Nginx, JBoss, Apache HTTP, Tomcat, WebLogic, Web Sphere.
Bug Tracker and Testing
JIRA, Junit, Test Flight, Confluence

PROFESSIONAL EXPERIENCE

Client: Verizon (Remote) Sep 2022- Present
Role: DevOps/AWS Engineer

Responsibilities:

Creating AWS environment using Computing Services (EC2, ELB), Storage Services (S3, Glacier, Block Storage, Lifecycle Management policies)
Extensively working on Cloud Formation and Deploying the Web application using Docker and hosting it to cloud.
Facilitate daily Scrum meetings, Lead sprint planning meetings, manage obstacles that arise for the team by communicating with stakeholders outside of the team.
Created customized AMIs based on already existing AWS EC2 instances by using create image functionality, hence using this snapshot for disaster recovery.
Executive Leadership in proactive escalations, self-identified risks, areas to watch, resource hot/cold spots, release conflicts that could impact Users, Systems, Business that need leadership attention. (aggregated view)
Designed, configured and deployed Microsoft Azure for a multitude of application s utilizing the AZURE stack (Including Compute, Web & Mobile, Blobs, ADF, Resource Groups, Azure SQL DW, Cloud Services, and ARM, focusing on high-availability, Disaster Recovery, fault tolerance, and auto-scaling)
Utilized Agile Methodologies - Scrum meetings to manage full life-cycle development of the project. Configured VMs in availability sets using Azure Portal to provide resiliency for IaaS based solution and scale sets using Azure Resource Manager to manage Network traffic.
Designed and developed standalone data migration applications to retrieve and populate data from Azure Table / BL storage to on premise SQL Server instances. Transferred the data from on premises to Azure cloud using Talented jobs with Hybrid systems.
Worked on Serverless services (Azure Functions) created and configured HTTP Triggers in the Azure Functions with Application insights for monitoring and performing load testing on the Applications using the VSTS.
Worked with Azure Service Fabric, exclusively to create micro service applications and Azure storage firewalls and virtual networks that uses virtual network service endpoints to allow Worked on Chef for IaaS configuration by writing cookbooks and recipes to automate the actions for virtual and remote resources and nodes.
IAC- infrastructure as code - Advanced knowledge of writing Hashicorp Terraform code to provision using the command line.
Developed a CI/CD pipeline using Jenkins and Hashicorp Terraform Enterprise.
Installed Chef Server Enterprise on the workstation and bootstrapped the nodes using Knife and involved in writing Chef Cook books and recipes to automate the deployment process. Worked in setting up the Chef repo, Chef Workstations, and Chef nodes.
Worked on several Docker components like Docker Swarm, Docker Engine, Docker-Hub, Docker-Compose, Docker Registry.
Implemented a Continuous Delivery pipeline with Docker, Jenkins, and GitHub. Setting up and implementing the build and deployment delivery process using Git, Jenkins.
Responsible for Administering and maintaining Jenkins and Jenkins slaves on windows and Linux (Debian/Ubuntu). Created many Jenkins slaves and setup jobs on master to run on slaves.
Worked on Continuous Integration (CI) and Continuous Delivery (CD) process implementation-using Jenkins along with Python and Shell scripts to automate routine jobs. Migrated Legacy applications to a repeatable Continuous Integration platform.
Designed the project workflows/pipelines using for Continuous Integration and deployment into different Web/Application Servers.
Modified C++ programs to support compliance rule automation for many compliance rules for client accounts for both pre-and post-trade compliance purposes and manage leverage using many metrics like industry exposure, security type, long/short positions, currency / securities / options / futures, credit ratings etc.
Written, Maven scripts to automate build process and managed Maven repository using Nexus tool and used the same to share snapshots and releases.
Worked on version control systems tool Git by using source code management client tools like GitHub and other command line applications.
Used Nagios as a monitoring tool to identify and resolve infrastructure problems before they affect critical processes and worked on Nagios event handlers in case of automatic restart of failed applications and services.
Installed, Configured, Managed Monitoring Tools for Resource Monitoring/Network Monitoring/Log Trace Monitoring. Developed Perl and shell scripts for automation of the build and release process, developed Custom Scripts to monitor repositories, Server storage.
Performed and deployed Builds for various Environments like QA, Integration, UAT and Productions Environments.
Organized and Coordinated Product Releases work closely with product development, QA, Support across global locations to ensure successful releases.
Deployed and configured JIRA, both hosted and local instances for issue tracking, workflow collaboration, and tool-chain automation.

Environment: Microsoft Azure, Azure stack, Azure Portal, Azure Resource Manager, Azure Function, Azure service fabric, Terraform, chef, Docker swarm, Docker compose, Docker registry, Docker hub, Maven, Nexus, Jira, GIT, GitHub.

Client: CVS Health May 2021- Aug 2022
Location: Woonsocket, Rhode lsland
Sr Cloud/DevOps Engineer

Responsibilities:

Created AWS Launch configurations based on customized AMI and use this launch configuration to configure auto scaling groups and Implemented AWS solutions using EC2, S3, Route53, EBS, Elastic Load Balancer, Auto scaling groups.
Configured AWS IAM and Security Group in Public and Private Subnets in VPC.
Migrating present Linux environment to AWS by creating and executing a migration plan, deployed EC2 instances in VPC, configured security groups & NACL’s, attached profiles and roles using AWS Cloud Formation templates and Ansible modules.
Used Docker and setting up ELK with Docker and Docker-Compose. Implemented ELK (Elastic Search, Log stash, and Kibana) Stack for Application Logging.
Experience in using of Docker for virtualization, containerization, and deploying the applications securely to fasten the Build and Release Engineering, performed automation tasks using Docker Hub, Docker Engine, Docker Machine, Docker Compose and Docker Registry
Docker-compose to create Zoo Navigator, Kafka Manager and Kafka Monitor.
Diligently worked with Kafka Admin team to set up Kafka and Zookeeper cluster setup.
Had knowledge on Kibana and Elastic search to identify the Kafka message failure scenarios.
Implemented Kafka producer and consumer applications on Kafka cluster setup with help of Zookeeper.
Used Spring Kafka API calls to process the messages smoothly on Kafka Cluster setup.
Administered Production, Development and Test environment's carrying Windows, Ubuntu, Red Hat Linux, SUSE Linux, Centos and Solaris servers via Virtual Box.
Have knowledge on partition of Kafka messages and setting up the replication factors in Kafka Cluster.
Handled importing of data from various data sources, performed transformations using Hive, MapReduce, loaded data into HDFS and Extracted the data from SQL into HDFS using Sqoop.
Built performance testing suite applications using open-source tool JMeter.
Setting up Some Monitoring Tools using Prometheus and Grafana.
Ensure timely identification and remediation of any risks related to a CI/CD pipeline release.
Setting up Kafka Dashboard on Grafana and Adding Graphs to Grafana and removing broker from Cluster.
Managing Interpolation and Conditionals in Built-in Functions while using Terraform Usage.
Working on Variables, Resources, Data sources in Interpolation terraform.
Making Sure Infrastructure auditable and keeping the machines in compliance, in a certain state.

Environment: AWS, Linux, Cloud Custodian, CPM, VMware, Jenkins, GITLAB, Docker, Kubernetes, Artifactory, Confluence, MS Teams, Maven, Gradle, Bash, Shell, Python Scripts.

Client: Paylocity Jan 2019 – Apr 2021
Location: Schamburg, Illinois
Senior Cloud DevOps Engineer

Responsibilities:

Worked in Agile methodology and biweekly sprint system tracked in Jira boards.
Designed and automated cloud-native CI/CD build and release pipelines, monitored pipelines with nightly run capabilities. Automation of Continuous Test Flows and Monitoring of Infrastructure.
Led end-to-end SDLC processes, from development to release, ensuring high-quality deliverables and efficient deployment strategies enhancing software delivery efficiency by 40%.
Utilized AWS extensively for building scalable and robust cloud-based solutions, streamlining deployment processes and optimizing infrastructure in private/hybrid cloud.
Have worked day to day on source code management platforms such as Git/GitHub and Bitbucket to oversee code commits and merges, facilitating collaborative development efforts for fresh code to manage repositories efficiently and Integration with Jenkins and Cloud Bees for pipelines flow to deploy in target Kubernetes cluster environment.
Developed Python scripts and groovy scripts for executing commands on automating repetitive tasks and enhancing workflow efficiency.
Utilized Terraform and Ansible for Infrastructure as Code practices, ensuring consistent and automated infrastructure provisioning.
Led containerization efforts by implementing Docker for application containerization, streamlining deployment and management processes.
Orchestrated and managed containerized applications using Kubernetes OpenShift, managing pod lifecycles, and optimizing resource utilization.
Used Grafana dashboards for performance monitoring, providing end-to-end visibility into applications and infrastructure.
Participated in discovery sessions with business liaisons, vendors, and analysts, leading to the design and development of scalable and secure IT solutions.
Actively involved in Agile SDLC, participating in sprint discovery, stand-ups, retrospectives, and other Agile processes.
Triaged high-priority production issues, conducting root cause analysis to ensure quick resolution.
Documented processes and procedures, ensuring comprehensive and accessible reference materials for team members.
Supporting and resolving application component and pipeline execution issues and application maintenance activities.
Organized backlog grooming sessions to analyse business requirements and discuss automation enhancements to reduce production downtime.
Automated manual operational and deployment activities identified using shell script, python and writing ansible playbooks.
Always made customers happy and provided service to resolving application component issues and deployment issues on time.

Environment: Apache Tomcat7, Unix, AWS, Terraform, Jenkins, Apache, WebSphere Application Server, Kubernetes microservices, Oracle, Java, Bash, Linux, Ansible, Jenkins, Git, GitHub Bit Bucket, Confluence, Jira, Cloud bees.

Client: Ceridian July 2016 – Nov 2018
Location: Minneapolis, MN
Role: Cloud DevOps Engineer

Responsibilities:
Implemented CI and CD for application using Jenkins as CI tool for integrating different tools like GitHub, used Ansible as configuration management tool for continuous deployment into testing, staging and Production Environment.
Assisted in the migration of on-premises infrastructure to AWS cloud services.
Working with groovy scripting to develop/manage CI/CD pipelines.
Working with Cloud environment administration (AWS & Azure DevOps) responsible for the customer facing production environment monitoring, performance, release/deployment, security, reliability, availability, capacity, latency, and other non-functional concerns.
Worked on Terraform project that provisions infrastructure on AWS cloud provider.
Used Jenkins for automating/Scheduling the build processes and used Jenkins along with Bash/Python scripts to automate routine jobs.
Deploying new features of Java/J2EE Application(s) in Application Server, Webserver & DB Server.
Automation of manual tasks identified in the deployment process using shell script, python.
Worked on achieving single click deployment approach by integrating developed scripts with Jenkins and creating jobs.
Worked on integrating the Jenkins with source code repository GIT and antifactory for fetching of source code and trigger the Jenkins job for fully automated deployment model.
Worked on maintenance activities in parallel for the Application, Web, DB Server Environment Up & Running by Troubleshooting the issues.
Performed Linux Administration Activities related to Application & Web Server Administration.
Involved in projects that move to production and work closely with the Development, Quality Assurance and Management teams to ensure cross communication and confirmed approval of all production changes to ensure successful releases.
Managed, monitor cloud infrastructure on AWS, EC2, S3, and RDS including backups, patches, and scaling.
Worked on JIRA for tracking and updating the JIRA tickets and per assigned and Maintained JIRA Administration/User documentation in Confluence.
Build end to end CI/CD Pipelines in Jenkins to retrieve code, compile applications, perform tests and push build artifacts to Nexus.
Worked on Grafana, Identifying the critical applications for system resource utilization (CPU, Memory, threads etc.)
Actively develop YAML files and built Ansible jobs for needs of server configuration automation. And work with bash and python scripting for manual operational tasks automation.
Working in AWS environment, instrumental in utilizing Compute Services (EC2, ELB), Storage Services (S3, Elastic Block Storage), Elastic Beanstalk, VPC, SNS, IAM and Cloud Watch.
Involved in POC integrating DevOps tools and Cloud resources utilizing docker and Kubernetes containerization concept for building end to end cloud pipeline.
Provided security and managed user access and quota using AWS Identity and Access Management (IAM), including creating new Policies for user management.
Designed terraform templates to create custom sized VPC, Subnets to ensure successful deployment of Web applications and database templates.
Created EBS volumes to store persistent data and mitigate failure by using snapshots. Performed Data Back-up of Amazon EBS volumes to S3 by taking point-in-time snapshots.

Environment: AWS, EC2, S3, WebSphere Application Server 7.x & 8.x, IHS 7.0, Apache Tomcat7, Apache2.4, WebSphere MQ, WebSphere MB, Unix, Service now, Jenkins, GIT, Bit Bucket, Artifactory, Share point, Confluence, Jira, Grafana.

Client: Caterpillar Oct 2014- Jun 2016
Location: Irvine, TX
Sr Cloud/ DevOps Engineer

Responsibilities:

Working with AWS CLI and API to manage resources on AWS for many services such as EC2, S3, VPC, Lambda, Cloud formation, Cloud Watch, RDS, Dynamo DB, ELB, Auto-scaling, Route53, IAM created python script using AWS API Calls to manage all resources deployed on AWS.
Configured AWS Virtual Private Cloud (VPC) and database subnet group for isolation of resources within the Amazon RDS and Aurora DB clusters.
Worked on creating Elasticsearch, Logstash and Kibana (ELK) stack for log analysis, centralized logging and then store logs and metrics into S3 bucket using Lambda function.
Configured AWS IAM and Security Groups in Public and Private Subnets in VPC Managed IAM accounts (with MFA) and IAM policies to meet security audit & compliance requirements and worked as Admin.
IAC- infrastructure as code - Advanced knowledge of writing Terraform code to provision using the command line. Developed a CI/CD pipeline using Jenkins and Terraform Enterprise.
Experienced in Ansible Tower, which provides an easy-to-use dashboard and role-based access control and in developing Ansible playbooks for managing the application/OS configuration files in GIT hub, integrating with Jenkins, and Verifying with Jenkins plugins, deploying the application in Linux environment.
Migrated Marathon to Kubernetes to create projects, services for load balancing and adding them to routes by accessing from outside, created pods through new application and controlling, scaling and troubleshooting pods through SSH. Created private cloud using Kubernetes that supports development, test and production environments.
Created clusters using Kubernetes and worked on creating many pods, replication controllers, deployments, labels, health checks and ingress by writing YAML files as well as managed Kubernetes charts using Helm.
Involved in development of Test environment on Docker containers and configuring the Docker containers using Kubernetes.
Used Urban Code for deploy of automating application deployments through your private cloud environments.
Designed and developed Continuous Integration & Continuous Delivery pipelines using Code Pipeline, Code Build and Code Deploy plugins in Jenkins.
Deployed application using Jenkins’s server and Troubleshoot build and release job failures, resolve, work with engineers on resolution
Developed build using MAVEN as build tools and used CI tools to kick off the builds move from one environment to other environments, Integrated maven with GIT to manage and deploy project related tags.
Installed and configured GIT and communicating with the repositories in GITHUB and Created and maintained Subversion/GIT repositories, branches and tags. Setting up and implementing the build and deployment delivery process using GITHUB.
Created required Python scripts as well as bash scripts to create/configure Linux VMs. Created and automated the Jenkins pipeline using pipeline Groovy script for the applications.
Build upstream and downstream jobs in Jenkins to build and deploy onto different environments.
Developed middleware components for software in C/C++ using STL, multi-threading, data structures, IPC (TCP/IP socket programming), SNMP and design patterns.
Developed software algorithms and Model-based C++ programs for embedded control systems using MATLAB/Simulink.
Developed the IoT applications by utilizing programming language C, Data structure, Algorithm, Object Oriented Programming, and Object-Oriented Analysis Language C++, STL, Exception Handling, information encryption and decoding.
Set up MongoDB Client and writing queries to validate data against Mongo Collections, MySQL. Installed, configured, and managed MongoDB servers and performance tuning of Mongo Databases.
Used SonarQube for continuous inspection of code quality and to perform automatic reviews of code to detect bugs.
Designed, support and maintain large Splunk environment in a highly available, redundant, geographically dispersed environment
Worked with Turbo Time-Sheet plug-in for Jira Agile.
Created workflows, fields and other project components in Jira.

Environment: AWS EC2, EBS, S3, VPC, RDS, ELB, Route53, Lambda, Auto Scaling, Terraform, CloudFormation, AWS Import/Export, CloudWatch, Pivotal cloud Foundry (PCF), Nagios, Kubernetes, Groovy, GIT, GITHUB, Jenkins, Maven, Docker, Kubernetes, Ansible, Splunk, Grafana, Mango DB, Python, YAML.

Education: Bachelors from Osmania University, 2008 (India)
Contact this candidate