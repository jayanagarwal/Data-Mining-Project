DNKumar Reddy
Email ID: ad7fnj@r.postjobfree.com
Contact Details: +1-314-***-****
DevOps Engineer

Professional Summary:
Experienced Devops with 7 years and 6 month of expertise in proven expertise in Automation, Build/Release Engineering and Software development involving cloud computing platforms like Amazon Web Services AWS.Extensive Experience in Software Configuration Management and DevOps Engineering using Amazon Web Services (VPC, EC2, ELB, EBS, Auto Scaling and S3).
Ability to manage SCM which includes compiling, packaging, deploying and application configurations.
Hands-on Expertise in configuring Jenkins and maintaining Continuous Integration & Continuous delivery
Experience in Architecting and securing the Infrastructure on AWS using EC2, S3, RDS, EBS, VPC, ELB, IAM, KMS, EMR, Cognito, API Gateway, Cloud Trail, Cloud Watch, Amazon SQS, SNS, SES, Config, AWS Kinesis, Lambda, Network ACLs, Security Groups, Route Tables, Route53, Elastic Beanstalk, Redshift and deploying applications utilizing all these services majorly focusing on high-availability, fault tolerance, and Autoscaling in AWS CloudFormation.
Implemented CICD pipeline for java applications which includes build, deployment and post-deploy configuration automation.
Configuring Jenkins job with related plugins for Testing, Artifactory and Continuous
Delivery to accomplish the complete CI / CD.
Hands on experience on Backup and restore Azure services and in Design and configure Azure Virtual Networks, subnets, Azure network settings, DHCP address blocks, DNS settings, security policies and routing, Azure cloud services, Blob storage, Active directory, Azure Service Bus, Cosmos DB.
●Experience working with Azure Kubernetes Service (AKS), Azure Container Service (ACS), Azure Container Registry (ACR), AWS Elastic Container Service (ECS), Elastic Container Registry (ECR) and Elastic Kubernetes Service (EKS).
Created and deployed VMs on the Microsoft cloud service Azure, managed the virtual networks, Azure AD and SQL.
Using Gradle plugin as build automation tool for compile, build & package code.
Using Nexus as Artifact Repository Management tool integrating it with Jenkins.
Extensively worked on Jenkins for continuous integration and for End-to-End automation for all Build and deployments on AWS servers for Production.
Experience in configuring VPC with public & private Subnets to make interaction between Subnets.
Created Docker images using a Docker file, worked on removing images.
Worked with Docker, Docker images, Docker files, Docker Hub, Docker Compose, and Docker registry in container-based deployments, used Docker-Swarm to maintain the cluster of containers.
Expertise Performing J2EE application deployments using Jenkins on Tomcat servers.
Using automation tools for building, storing & deploying of war file on to the application server (Tomcat) and also familiar with console mode of deployment on Tomcat Servers.
Jenkins an extensible server for continuous integration & continuous deployment for distributing work across multiple machines.Monitoring and troubleshooting Jenkins Automation jobs.
Gradle as the build automation tool for building the source code into required format package.
Implemented Docker automation solution for Continuous integration / Continuous Delivery model.
Using the Cloud Bees Docker Pipeline Plugin, Jenkins was integrated with the Docker container, and the Amazon EC2 plugin was used to provision the EC2 instance.
Responsible for supporting 24/7 in production and non-production environment.
Configured and deployed applications in development, test and production.
Checking emanate Monitoring tool(Prometheus) and getting involved with the problem management team to find the root cause of the incident for permanent solution.
Built and delivered Kubernetes cluster using Kops and EKS on AWS.
Worked on UNIX command line utilities and has hands on experience on UNIX commands to support the environment.
Using Grafana for visualization of custom metrics taken from Prometheus.
Expertise Performing J2EE application deployments using Chef on Tomcat servers.
Monitoring servers and alerting R&D to check root cause analysis.
Experience in JIRA for ticketing and as well as defect tracking system and configure various workflows, customizations and plug-ins for JIRA bug/issue tracker, integrated Jenkins with JIRA, GitHub, Maven.
●Good experience in monitoring and logging tools like AWS CloudWatch, Azure Application Insights, Azure Log Analytics, Splunk, Nagios, Prometheus, Grafana, Graylog, Datadog, AppDynamics for monitoring network services and host resources.
For resolving few issues related to instances, we login to production servers, perform necessary actions and get the issue resolved within the given tenure of SLA.

Key Skills:
1.Scripting - Bash/Shell, Python,Groovy
2.Version Control - Git, Bitbucket, GitHub
3.Automation/Build Tools - Jenkins, Gradle, Maveen
4.Platforms - Linux/Unix
5.Containerized tool - Docker, Kubernetes
6.Amazon Web Services - VPC, EC2, S3, CloudWatch, ELB, Route53,ROUTE53, SNS, Cloud front, EBS, ELB, Cloud watch, Elastic beanstalk, Lambda, Glue
7.Configuration Tools - Terraform, Ansible,Chef

Self-Directed Learning and Certificates
AWS Developer – Associate Level
Azure Developer Associate

Company: Merizon Technologies LLC
Client: Kaiser Permanente. Los Angeles, CA.
Duration: Jan 2024 to Present.
Role: Senior DevOps engineer

Roles & Responsibilities:
●Worked on cloud platform to modify, create, and destroy the AWS EC2 servers, S3, Autoscaling configurations, Elastic Load Balancing configurations based on Cloud architect inputs.
●Involved in DevOps migration/automation processes for build and deploy systems.
●Built CI/CD on AWS environment using Code Commit, Code Build, Code Deploy and Code Pipeline and using AWS CloudFormation, ECS, ECR, EKS, API Gateway and Lambda in automation and secured the infrastructure on AWS.
●Configured EMR clusters, set IAM Role to guarantee S3 access, built bundle jar based on Apache Maven for EMR.
●Managed AWS EC2 instances utilizing Autoscaling, Elastic Load Balancing and Glacier for our QA and UAT environments as well as infrastructure servers for GIT.
●Designed AWS CloudFormation templates to create custom sized VPC, Kubernetes, subnets, NAT to ensure successful deployment of Web applications and database templates.
●Enhanced deployment efficiency by automating CI/CD pipelines with AWS Code Pipeline, significantly reducing deployment times and improving release cycles.
●Triggered pipelines via GIT events, Jenkins, Travis CI, Docker, Cron and other Spinnaker pipelines.
●Configured VPC (Virtual Private Cloud) networking, subnets, route tables, and security groups to establish secure and isolated environments for EKS and ECS clusters.Designed and implemented Infrastructure as Code (IaC) solutions using Terraform, defining infrastructure configurations in version-controlled code for consistency and repeatability.
●Responsible for Administering and Monitoring Visual Studio Team System (VSTS), taking backups and consolidating collections at the time of migration from one version of VSTS to another.
●Automated various infrastructure activities like Continuous Deployment using Ansible playbooks and has Integrated Ansible with Jenkins on AZURE.
●Implemented a CI/CD pipeline using Azure DevOps (VSTS, TFS) in both cloud and on-premises with GIT, MS Build, Docker, Maven along with Jenkins’s plugins.
●Used Docker, Kubernetes and OpenShift to manage micro services for development of CI-CD.
●Used Docker Hub, Docker Engine, Docker Images, Docker Weave, Docker Compose, Docker Swarm and Docker Registry and used containerization to make applications platform when moved into different environments.
●Maintained microservices using Kubernetes as front-end orchestrator for Docker containers and worked on installation of Kubernetes Cluster on AWS (EKS) to test different features, handled proxy requests and created Kubernetes cluster.
●Combined Kubernetes with Spinnaker V2 for resource mapping and implementing canary deployments.
●Created K8s Clusters using Helm Charts, helming packages and working on creation of multiple pods, replicating controllers, replica sets, services, deployments, labels, health checks, and ingress/egress by writing YAML files.
●Wrote Python scripts for pushing data from DynamoDB to MySQL Database. Used MySQL, DynamoDB and Elastic Cache to perform basic database administration build and JIRA for the collaboration tool.
●Monitored AWS cloud resources and applications that deployed on AWS by creating new alarm, enable notification service using CloudWatch.
●On-Call Cloud infrastructure, operation support to onboard the applications into AWS Cloud from On-prem.
●Worked on ticketing tools like Remedy, ServiceNow and Jira to update the records and the server vulnerabilities.

Company: RA InfoTech (TCS)
Project: Vanguard
Duration: Nov 2021 to Aug 2022 date.
Role: Senior DevOps engineer
Roles & Responsibilities:
Implemented Build pipeline/Release pipeline and Delivery pipeline to perform all the CI/CD activities and promoting the code to DEV/ST/UAT/E2E environments based on the smoke suite result.
Implementing Jenkins continuous integration tool including installing setting the jobs/plans and setting up the tool for deployment.
Configuring, Troubleshooting and Monitoring build jobs in Jenkins.
Worked on UNIX command line utilities and has hands on experience on UNIX commands to support the environment.
Done proof of concepts for concepts for created RDS In private subnets and connected through cloud9.
Working on Automating / Changing Infrastructure Provisioning or software patching/installation using Terraform and Ansible
building Infra as per Project requirement using Terraform and Terraform Modules and Integrate with CI/CD and also Build and Release Management by tagging Stories and modifying existing pipelines or creating new CI/CD Pipelines from Stratch if required
●Used Docker Hub, Docker Engine, Docker Images, Docker Weave, Docker Compose, Docker Swarm and Docker Registry and used containerization to make applications platform when moved into different environments.
●Automated deployment workflows with Kubernetes Helm charts and CI/CD pipelines (e.g., GitLab CI/CD, Jenkins) to achieve continuous integration and delivery of applications.
created and maintained an Angular, HTML, and CSS responsive front-end interface for internal DevOps dashboards. This allowed for effective administration and monitoring of CI/CD pipelines, system health indicators, and deployment statuses, which enhanced visibility and teamwork.
Implemented Kubernetes best practices for resource management, service discovery, and monitoring using tools like Prometheus, Grafana, and Kubernetes Dashboard
Code quality standards, code reviews, and automated testing procedures were enforced through the use of GitFlow or GitOps workflows on GitHub. This improved code dependability, shortened feature development time, and improved teamwork were the outcomes.
Developed and maintained Ansible Playbooks for automated configuration management, ensuring consistency and reliability across environments. Utilized XebiaLabs XL Release (XLR) to orchestrate and automate complex release processes, improving deployment efficiency and reducing time-to-market.
●Managed Ansible Playbooks with Ansible Roles and developed Playbooks using Ansible.
Having admin rights for wiz portal for checking vulnerabilities and working with team based on priority issues.
Manage AWS EC2 instances utilizing Auto Scaling, Elastic Load Balancing and Glacier for our QA and UAT environments as well as infrastructure servers for GIT and Chef.
Using Linux updated RHEL6 server to RHEL8.
Proficient in managing and automating Linux-based systems, utilizing shell scripting and configuration management tools to ensure efficient and reliable server operations. Experienced in setting up, maintaining, and troubleshooting Linux environments to support application deployment and performance
Implemented and managed CI/CD pipelines using Bitbucket, enhancing version control and automating the build, test, and deployment processes to ensure seamless integration and delivery of code changes.
Utilized Bitbucket pipelines to automate server updates, ensuring seamless deployment of code changes and configurations, enhancing system reliability and reducing downtime through efficient continuous delivery practices
We successfully installed Apache Kafka to provide our applications with real-time data streaming and processing, guaranteeing low latency and great throughput.Utilized Kafka for centralized log aggregation and monitoring, allowing for efficient collection, processing, and analysis of log data from various microservices
Utilized Jira and Confluence integration to enhance project management and collaboration, enabling seamless communication, task tracking, and documentation within cross-functional teams, resulting in improved productivity, transparency, and knowledge sharing across the organization.
Developed automated scripts using Python to create and manage JIRA tickets, streamlining project tracking and issue management processes, and improving team productivity and workflow efficiency
Implemented and managed incident response workflows using PagerDuty, ensuring efficient on-call management, automated incident notifications, and streamlined communication during critical events.

Company: Wipro
Duration: May 2020 to Sep 2021
Role: Sr Associate- Projects
Roles & Responsibilities:

Created required AMI based windows through Cloud Formation for testing team.
Azure Active Directory (AAD) for identity and access management, Azure Data Lake for big data storage and analytics, and Azure Kubernetes Services (AKS) for container orchestration and management were used to provide a safe and scalable cloud architecture. integrated Okta to improve security and streamline user access across numerous apps and services for single sign-on (SSO) and multi-factor authentication (MFA).
Managed Azure infrastructure such as Azure Web Roles, Worker Roles, SQL Azure, Azure Storage, Azure AD Licenses for development teams.
Identity & Access Management: Azure Active Directory, Azure Identity, Multi-Factor Authentication (MFA).
Created CI/CD Pipelines in Azure DevOps environments by providing their dependencies and tasks.
Managed and optimized Azure Cosmos DB instances, ensuring high availability and performance, while implementing comprehensive security measures using Azure Security Center and Azure Sentinel to protect sensitive data and maintain regulatory compliance.
Implemented data integration and ETL workflows using Azure Data Factory, managed big data processing with Azure Databricks, and ensured secure storage and management of secrets and keys using Azure Key Vault.
Orchestrated the migration of on-premises infrastructure to AWS, leveraging services like AWS CloudFormation and AWS Database Migration Service (DMS) to seamlessly transition applications and databases to the cloud, reducing operational costs and increasing scalability
Implemented a highly available and fault-tolerant architecture on AWS, utilizing services such as Amazon EC2, Amazon RDS, Amazon S3, and Amazon Route 53, incorporating auto-scaling, load balancing, and data redundancy strategies to ensure optimal performance and reliability of applications in the cloud
Implemented Jenkins as a continuous integration and continuous deployment (CI/CD) tool in DevOps workflows, automating software builds, testing, and deployments to streamline development processes, improve code quality, and accelerate time-to-market for software releases.
EC2, VPC, S3, Glacier, EFS, AWS Kinesis, IAM, Lambda, Directory Services, Security-Groups, CloudFront, Ops Work and Cloud Formation, Elastic Beanstalk, RDS, SNS, SQS, SES, DynamoDB, Redshift, EMR, ELB, Route-53, etc. were some of the AWS services used in the implementation of cloud solutions.
Leveraged Docker containers to containerize applications, facilitating consistent development environments, simplified deployment processes, and improved scalability and resource utilization in production environments
Responsible for Continuous Integration (CI) and Continuous Delivery (CD) process implementation-using Jenkins along with Python and Shell scripts to automate routine jobs
Implemented Kubernetes for container orchestration, managing and scaling containerized workloads, automating deployments, and ensuring high availability, fault tolerance, and efficient resource management in cloud-native environments
Configured Bitbucket Pipelines for CI/CD workflows, integrating Docker containers to automate software builds, testing, and deployments, improving development speed, code quality, and release consistency.
Developed and maintained CI/CD pipelines for Java applications, utilizing tools such as Jenkins and GitLab CI to automate the build, test, and deployment processes. This ensured rapid and reliable delivery of application updates while maintaining high code quality.
Designed and deployed Java-based microservices using containerization technologies like Docker and Kubernetes. Leveraged orchestration tools to manage, scale, and ensure the high availability of Java microservices in production environments.
Developed and deployed Kubernetes applications using Helm charts, ensuring efficient management of complex deployments and facilitating easy version control and reproducibility of Kubernetes resources
Leveraged Groovy scripting to enhance Jenkins pipelines, automating complex build, test, and deployment processes. Developed custom Groovy scripts for integrating various tools and services, optimizing CI/CD workflows and ensuring seamless and efficient delivery of software across multiple environments
Leveraged OpenShift to streamline DevOps processes, optimizing deployment pipelines and enabling continuous integration and delivery (CI/CD), resulting in a significant reduction in deployment times and enhanced software reliability.
Implemented automated scaling and monitoring solutions on OpenShift, enhancing system resilience and ensuring high availability of applications, thereby contributing to improved operational efficiency and minimized downtime
Proficient in utilizing Grafana to monitor and visualize key metrics and performance indicators across infrastructure and applications in a DevOps environment. Designed and implemented custom dashboards and alerts to ensure proactive monitoring, troubleshooting, and optimization of system health and performance
Utilizing DevOps ideas, we created and executed Service Level Agreements (SLAs) and Service Level Objectives (SLOs) to guarantee our applications' consistent performance and dependability. This increased accountability and customer satisfaction by establishing clear performance indicators, keeping an eye on the health of the system, and automating alerting and reporting procedures.
Designed and integrated robust applications using RESTful and SOAP APIs for seamless data exchange and leveraged SDK APIs to enhance functionality and streamline development processes
Integrated Grafana with various data sources, such as Prometheus, InfluxDB, Elasticsearch, and cloud monitoring services, to create comprehensive monitoring solutions. Automated data collection, analysis, and reporting processes using Grafana, enabling efficient decision-making and continuous improvement in DevOps practices.
●Responsible for designing, implementing, maintaining, and troubleshooting of high available critical applications running on WebSphere, SQL Server and PostgreSQL database.

Company: Cognizant
Duration: Sep 2018 to April 2020.
Role: AWS DevOps Engineer
Roles & Responsibilities:
Built and implemented collaborative development environment using GIT, GitHub and integrated it with Jenkins.
Create Application deployment CI/CD pipelines using multibranch pipelines.
Built CI/CD on AWS environment using Code Commit, Code Build, Code Deploy and Code Pipeline and using AWS CloudFormation, ECS, ECR, EKS, API Gateway and Lambda in automation and secured the infrastructure on AWS
Responsible for the GitHub repos as manage access given to the team members to the private repos.
Implemented centralized governance and management of multi-account AWS environments using AWS Control Tower, enhanced security and user management with AWS Cognito, and facilitated seamless data integration between SaaS applications and AWS services using AWS AppFlow
Created tables and schemas and users in PostgreSQL using cloud formation templates.
Created RDS database and proxies and required resources created by using Cloud formation templates.
Responsible for ensuring Continuous Delivery/Continuous Integration across all environments from UAT/TEST to Pre-Production and Production using Jenkins and cloud formation templates.
Build servers using AWS, importing volumes, launching EC2, RDS, creating security groups, auto-scaling, load balancers (ELBs) in the defined virtual private connection.
Working closely with developers to take requirements and setup new build environments for upcoming micro services.
Have designed Lambda function to detect and trigger the application whenever there a document is uploaded to AWS s3 bucket.
Implemented DevOps methodologies to automate the deployment, configuration, and monitoring of IBM WebSphere environments. This streamlined application releases, improved system reliability, and reduced downtime through continuous integration and continuous delivery (CI/CD) pipelines.
Implemented seamless integration of Power BI dashboards with DevOps pipelines, enabling real-time data visualization and reporting for continuous monitoring and decision-making. Automated the deployment and updates of Power BI reports using CI/CD practices, ensuring up-to-date insights and improved data-driven strategies across the organization
Continuous Delivery is being enabled through deployment into several environments like Test, QA, Stage and Production using Jenkins.
Managed and optimized SQL databases, including MySQL and PostgreSQL, ensuring data integrity, performance, and security. Developed and executed SQL queries, stored procedures, and triggers for data manipulation, retrieval, and reporting, supporting efficient data-driven decision-making processes.
Led data migration projects, transferring data between SQL, MySQL, and PostgreSQL databases while ensuring data consistency, accuracy, and completeness. Implemented database replication and synchronization strategies to facilitate seamless data integration across heterogeneous environments, enhancing data accessibility and usability.
Developed and maintained Bash scripts to automate routine tasks and streamline DevOps workflows, enhancing efficiency and reducing manual intervention. Utilized Bash for configuration management, deployment automation, and system monitoring, ensuring consistent and reliable operations across various environments
Managing access control list of release management tools including Jenkins, Git, and Jira.
Well versed with Amazon Route 53 which effectively connects user requests to the infrastructure running on Amazon EC2 instances and Amazon S3 buckets.
Utilized PowerShell to automate infrastructure provisioning and configuration management tasks in a DevOps environment. Developed PowerShell scripts for seamless integration with CI/CD pipelines, enhancing deployment efficiency and consistency across various cloud and on-premises platforms

Company: 24[7]
Duration: March 2017 to Aug 2018
Role: Digital Interaction Executive
Roles and Responsibilities:
Setting up the new build environment for various applications in Windows/Linux environment.
Installed, managed and administrated of all UNIX servers, includes Linux operating systems by applying relative patches and packages at regular maintenance periods using RedHat Satellite server, YUM, RPM tools.
Implemented Build pipeline/Release pipeline and Delivery pipeline to perform all the CI/CD activities and promoting the code to DEV/ST/UAT/E2E environments based on the smoke suite result.
Implementing Jenkins continuous integration tool including installing setting the jobs/plans and setting up the tool for deployment.
Configuring, Troubleshooting and Monitoring build jobs in Jenkins.
Worked on UNIX command line utilities and has hands on experience on UNIX commands to support the environment.
Building various Jobs on servers in different environment like QA, UAT, Pre-Prod.
Shell scripts for automation of the build and release process.
●Developed automation scripts in Python using Chef to deploy and manage Java applications across Linux servers.
Deploying WAR and JAR Application on targeted managed Servers by using Jenkins.
Using Git as version Control System and Automating the Code from GitHub to Jenkins.
Using Nexus for Artifact Repository Management and pushing the code from Jenkins to Nexus.
●Setup full networking services and protocols on UNIX, including NIS/NFS, DNS, SSH, DHCP, NIDS, TCP/IP, ARP, applications and print servers to insure optimal networking, application, and printing functionality.
Managed all Application-Server related activities such as Continuous Integration, Continuous delivery, monitoring in the Non-Prod and Production Environments.
Manage AWS EC2 instances utilizing Auto Scaling, Elastic Load Balancing and Glacier for our QA and UAT environments as well as infrastructure servers for GIT and Chef.
Developed automated processes that run daily to check disk usage and perform cleanup of file systems on LINUX environments using shell scripting.
Installed, managed and administrated of all UNIX servers, includes Linux operating systems by applying relative patches and packages at regular maintenance periods using RedHat Satellite server, YUM, RPM tools.

Company: Migids
Company: Aug 2015 to Jan 2017
Linux Administrator

The goal of the project is to administer and configure servers, workstations, monitoring local area network, performing system maintenance, applications deployment and management and audio/video configurations. The project involved in performing daily system monitoring, verifying the integrity and availability of all hardware.
Responsibilities:
●Built and installed PXE boot server, DHCP server, Kickstart and XCAT server to automatically load OS on test machines in the LAB environment.
●Performed Linux administration such as user accounts, logon scripts, directory services, file system shares, permissions.
●Configured password less login between Linux servers, install, configure and upgrade Linux operating systems and kernels.
●Supported and administered Linux, VMware, post-hardware setup and configurations based on various development environments.
●Developed, maintained, updated various scripts for services (start, stop, restart, recycle, Cron jobs) UNIX based Shell.
●Setup full networking services and protocols on UNIX, including NIS/NFS, DNS, SSH, DHCP, NIDS, TCP/IP, ARP, applications and print servers to insure optimal networking, application, and printing functionality.
●Provided systems administration support to Linux systems including server and workstation upgrades, backup and disaster recovery, monitoring, user account setup.
●Responsible for designing, Shell Scripting, supporting Oracle databases, and troubleshooting RHEL Linux/Oracle Linux servers.
●Resolved TCP/IP network access problems for the clients.
●Managed systems routine backup, scheduling jobs like disabling and enabling Cron jobs, enabling system logging, network logging of servers for maintenance, performance tuning, testing.
●Developed utilities in Perl, including templates and configurations for Nagios, PRTG, and basic system configurations. Wrote custom plugins for Nagios.
●Created Datadog dashboards for various applications and monitored real-time and historical metrics.
●Scheduled the Linux Cron jobs and Jenkins jobs for build automation.
●Developed Perl and Shell Scripts for automation of the build and release process & to perform deployments to JBoss and Tomcat Web servers.
●Worked on configuration and administration of LDAP, NFS and NIS in Linux and implemented Samba for sharing of resources between Linux environments.
●Handled admin tasks in Linux OS such as server restart, application installation setting up monitoring dashboards for app server.

Education:
Masters in Computer and Information technology
Eastern Illinois university
December 2023
Jawaharlal Nehru Technological University Hyderabad, Telangana, India April 2014.
Contact this candidate