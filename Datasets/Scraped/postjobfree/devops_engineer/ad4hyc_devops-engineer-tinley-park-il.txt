Naga Pravalika. A
ad4hyc@r.postjobfree.com
1-224-***-****
Visa – Green Card

Professional Profile
•6+ years of experience comprising of AWS solution Architect Associate Engineer with DevOps and Cloud.
•Responsible in adding new volumes & creating file systems on EC2 Instances as per user requirement.
•Worked on Agile and waterfall methodologies.
•Responsible for day-to-day execution of all Development, helping in testing activities and Production issues.
•As a DevOps Engineer, I am responsible in creating branches and managed the source code for various applications in GIT.
•As a DevOps Engineer, I am responsible in release management activities includes CI/CD and Change request handling in Test and Production environments and responsible for monitoring the health of Applications as part of SRE.
•Worked on setting up the life cycle policies to back the data from AWS S3 to AWS Glacier on various projects.
•Worked with various AWS EC2 servers based on the client requirements.
•Created Virtual Private Cloud, Internet gateway, subnet and route tables using Amazon VPC.
•Created monitors, alarms and notifications for EC2 hosts using Cloud watch.
•Provide responsive off-hours support in a 24/7 environment and ensure maximum availability of all servers and applications.
•Experienced in creating RDS instances to serve data through servers for responding to requests.
•List of AWS environments which were having good knowledge (EC2, VPC, S3, EBS, RDS, Route53, Cloud Watch, Cloud Formation, AWS Auto Scaling, Lambda, Elastic Bean Stalk), GIT, Jira, AWS CLI, Unix/Linux.
Certification
•Amazon Solution Architect Associate.
Candidate ID: AWS0128579
•Amazon Certified DevOps Professional.
Candidate ID: 8NMXFYFB2JR111CY

Skill sets
Scripting Languages : Power Shell, YAML, Groovy, Bash, Python (Basics)
Operating System : Linux, Windows, Mac OS
Version Management Tools : GIT, GIT Lab, BITBUCKET and SVN
CI/CD Tool : Jenkins, Spin Cloud, CODE PIPELINES
Deployment : Dockers, Kubernetes, uDeploy
Build Tool : Maven, MS BUILD, Code Build
Monitoring Tool : AWS Cloud Watch, ELK, Splunk, Grafana and Prometheus
Ticket Management Tool : JIRA, Secure24, Radar (Apple Inc)
Cloud Services : AWS, GCP (Basics) .
Configuration Tool : Ansible, Terraform, Whisper
Binary Management tools : JFROG Artifactory
Web Servers & Application Servers : Apache Tomcat

Project- 1
Wipro LLC - Austin TX
Client: Apple Inc (USA) Sep 2022 – November 2023
Position: Senior Software Engineer
Job Responsibilities
Defining and setting Development, test, release, update, and support process on DevOps Operation
Ansible playbooks that act as the entry point for Ansible provisioning, with automation specified through tasks in YAML format to run Ansible scripts.
Using Elastic Kubernetes Service, I was able to deploy, load balance, scale, and manage Docker containers with various namespace.
Using Kubernetes and Docker as the runtime environment for the CI/CD system to develop, test, and deploy.
Create and maintain the CI/CD pipelines in Jenkins for deployments in test environment.
Involved with Dev/QA team to debug & fix issues present in the system.
Experience on migrating Bare Metal servers to AWS Cloud, Kubernetes, and GCP
Managing Amazon Web Services (AWS) infrastructure through automation as Terraform and developing cloud-hosted applications.
Set up and maintained logging and monitoring subsystems using tools like Prometheus, Grafana and Splunk, monitoring the performance and status of the Applications in Splunk.
Creating Kafka topics based producer and consumer bytes and give access to the topics for the large streaming databases and clusters.
Created and maintained data pipelines Stream process engines like Apache Spark and familiar with Kafka Architecture and troubleshooting.

Project- 2
Donyati LLC – Banglore India
Client : Argo Groups July 2020 - Dec 2021
Position : Software engineer
Job Responsibilities
•Work with Developers and Architects in developing middleware configurations based on requirements.
•Perform troubleshooting, incident response, and patching the Data patches in a timely manner using PL/SQL.
•Effectively worked on JBoss server migrations.
•Experience in Service now ITIL process – Incident Life Cycle & Change Requests E2E processes.
•Successfully handled Preprod and production deployments in Windows Server IIS.
•Infrastructure configuration management setup in windows by using Ansible.
•Designed Continuous Integration & Continuous Delivery pipelines using Jenkins and uDeploy.
•Fully managed the pipelines and automate the pipelines for fast and reliable applications using AWS, services like, EC2, Code deploy, Code pipelines and GIT.
•Jenkins continuous integration server installation and configuration, to automate application Deployments, setting up Continuous Integration environment using Jenkins and set the new Jenkins server and slave machines to support machines to support.

Project- 3
Merizon Technologies LLC – Plano TX
Client : Toyota Nov 2019– May 2020
Position : DevOps Engineer
Job Responsibilities
•Used Kubernetes to deploy and manage containers on AWS. Created a private cloud using Kubernetes that supports test, development and production environments.
•Designed and implemented scalable, secure cloud architecture based on Amazon Web Services. Leveraged AWS cloud services such as EC2, S3, Elastic Search, RDS, Lambda, Docker Container, Kafka, Cloud formation (Temples - JSON), AMI, Restful API, Java Script, Yaml.
•Actively worked in creating Streaming Applications that process and respond the data by using Apache Kafka, was able to handle the large volume of data and also monitoring the Applications in Apache Spark Streaming.
•Implementing a Continuous Delivery framework using Jenkins, and Maven in Linux environment.
•Designed the project workflows/pipelines using Team city as CI tool. Expert in User Management and Plugin Management for Jenkins.
•Involved in development of test environment on Docker containers and configuring the Docker containers using Kubernetes.
•Similarly, when the Master branch of GitHub is updated, it directly triggers staging, where you can verify all the developments before it moves to production
•Created and maintained infrastructure in Azure (manage VNets, Subnets and NSG’s.
•Experienced in build tools such as Apache Ant, Maven.
•Configured Elastic Load Balancers with AWS EC2 Auto scaling groups.
•Experienced with CI (Continuous Integration) tools Jenkins.
•Developed various automation scripts that enable management of Azure environment in an automated manner.
•Designed infrastructure for AWS application and workflow using Terraform.
•Implementation and continuous delivery of AWS infrastructure using Terraform.

Project- 4
Merizon Technologies LLC – San Antonio TX.
Client : Argo Groups Apr 2017 – Oct 2019
Position : DevOps Engineer
Roles & Responsibilities
•Guided developers by establishing and applying appropriate branching, labelling convention using GIT source control
•Good experience in coordinating and supporting merging process with source code control.
•Created and configured the Elastic container service to containers. By configuring the whole cluster in the Ec2 service deploy Dockers
•Created several task definitions for running multiple tasks in a container Automate Continuous Build and Deploy Scripts for Jenkins Continuous Integration tool
•Creating the Build jobs in Jenkins and monitor status of daily builds. Working with Docker containers to deploy containers in Jenkins, create Docker volumes, and Experience with Dockers compose mainly to deploy in Nginx server
•For build fixes Any Error Occurs in WAR, JAR files fix by using the Maven and Those artifacts Storing Remotely in Jfrog Artifactory.
•Design and develop continuous integration and continuous deployments with tools like GIT and Jenkins
•Working with Kubernetes Clusters and orchestration, create and delete pods, create clusters and working with Master and slave Nodes, and configure Nginx and WordPress Servers with Master Nodes. Configure and Deploying K8s with Ansible and Deploy with Jenkins.
•Participated in setting up and deploy the Prometheus Monitoring tool, monitors the Cluster CPU and Memory Usage and gets The Graphs by deploying Grafana.
•Deploy the Elastic Search, Kibana pods to view logs of running Application and Configure Ansible for Run entire Infrastructures by using Ansible Playbooks, Yaml scripts.
•Performed S3 buckets creation, policies and on the IAM role based polices. Installed application on AWS EC2 instances and configured the storage on S3 buckets.
Environment: Ubuntu 16.04, Git, AWS, Dockers, Jenkins, Ansible, Kubernetes.

Education Background
Bachelor of Technology Electronics and Communications Engineering JNTU Kakinada.
Contact this candidate