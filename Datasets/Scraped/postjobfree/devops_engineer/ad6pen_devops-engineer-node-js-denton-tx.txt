BURUJU SOWMYA
DevOps Engineer
Phone: 469-***-****
Email: ad6pen@r.postjobfree.com
● Over 10 years of Experienced IT industry including a multi-talented and detail-oriented DevOps Engineer with 6+ years of experience specializing in the design, implementation, and maintenance of continuous integration/delivery pipelines, and 4+ years of experience in Linux administration roles.
● Proven expertise in AWS serverless technologies, including AWS Lambda, API Gateway, DynamoDB, S3, CloudFormation, and Step Functions, with experience in building scalable and fault-tolerant serverless applications.
● Proficiency in Node.js and Python, coupled with extensive experience in working with AWS Kafka service and developing RESTful APIs.
● Strong debugging and troubleshooting skills, along with the ability to diagnose and resolve complex serverless application issues.
● Familiarity with AWS security best practices, including IAM, VPC, and KMS, ensuring compliance and data security.
● Solid background in Java development, complemented by experience with Apache Hadoop, Kafka, Spark, and Logstash.
● Expertise in infrastructure automation using tools like Ansible, Chef, and Docker, ensuring efficient deployment and management of resources.
● Hands-on experience in managing and optimizing Databricks clusters, including monitoring performance, implementing access controls, and ensuring data integrity and availability.
● Proficient in scripting for automation and monitoring using Shell, PowerShell, PHP, Java, Python, YAML, Ruby, and Perl scripts.
● Implemented HashiCorp Vault to manage and secure sensitive data and credentials, ensuring compliance with security standards and regulatory requirements.
● Configured and maintained shared infrastructure on S3/Cloudian, optimizing storage solutions for efficiency, accessibility, and cost-effectiveness.
● Proficient in Linux/Unix fundamentals and network concepts, with hands-on experience in system administration and troubleshooting.
● Skilled in Shell scripting with proficiency in interpreted or compiled languages such as bash, Perl, Python, C/C++, Go, and Java, enabling automation and efficient system management.
● Experienced in configuration management and Infrastructure as Code (IaC) using tools like Ansible, Puppet, Terraform, and CloudFormation to automate provisioning, configuration, and deployment processes.
● Knowledgeable in containerization technologies such as Docker and Podman, as well as container orchestration platforms like Kubernetes and Apache Mesos, facilitating efficient application deployment and scaling.
● Strong communication and collaboration skills, with a proven ability to work effectively across functional teams, fostering synergy and driving collective success.
● Familiarity with key security principles, including encryption and keys, enhancing system integrity and safeguarding sensitive data.
● Understanding of Site Reliability Engineering (SRE) principles, including monitoring, alerting, error budgets, fault analysis, and automation, to ensure reliable and scalable systems
● Experience in CI/CD pipelines, configuration management, and container management with Docker, ensuring consistency and repeatability through infrastructure as code.
● Ensure 100% uptime of the infrastructure (virtual/ cloud/ on-premises and data centers).
● Evangelizes DevOps best practices with the team and team members.
● Participating in complete system builds, upgrades, migrations, code deployments and patch managements.
● Worked on various Azure services like Compute (Web Roles, Worker Roles), Azure DB (SQL & Cosmos DB), Network services, Azure AD.
● Troubleshooting the network issues and application access issues.
● Experience working in a multi cloud environment on varied cloud PaaS and SaaS services, its provisioning and troubleshooting.
● Installation, configuration and maintenance of servers in Physical (HP, Dell and IBM) and Virtualization using
(VMWare vSphere 5.5, 6).
● Successfully setup RedHat Satellite 6.4 and RedHat Satellite Capsule 6.4 from scratch and setting up all the Life Cycle Environments, Content Views, activation keys, adding and synchronizing the repositories from RedHat Portal.
● Expertise in Core Java concepts such as Multi-Threading, Generics, Exception Handling, Collections Framework, etc.
● Successfully setup Oracle Spacewalk 2.6 and Spacewalk Proxy 2.6 environments and created the required channels.
● Completed the upgrade of Spacewalk from 2.6 to 2.7 successfully.
● Registered all the Linux servers to RedHat Satellite Capsule and Oracle servers to Oracle Spacewalk proxy.
● Maintaining servers by managing packages using Ansible playbook.
● Successfully completed the setup of Red Hat Satellite 6.5 a latest version.
● Installation and setup of Foreman 1.21 and Foreman Smart-proxy environments on Red Hat servers.
● Completed the sync of all the repos created as products with the download policy set to immediate.
● Successfully patched thousands of servers to avoid security vulnerabilities, upgrade server OS to latest versions.
● SRE for a team that involved different development teams and multiple simultaneous application/software releases.
● Experience working with Apache Hadoop, Kafka, Spark and Log stash.
● Experience in managing multiple file systems like ext4, VxFS, implemented LVM, software RAID solutions.
● Experience in configuring and maintaining Linux applications with network protocols such as SSH, DNS, DHCP, HTTP, HTTPS, NFS, BIND, FTP, LDAP, Samba, and NFS.
● Demonstrated expertise in container technology, including extensive experience with Kubernetes and container orchestration.
● Hands-on experience with Amazon EKS (Elastic Kubernetes Service), managing and deploying containerized applications in the AWS cloud environment.
● Proficient in Automation, Infrastructure as Code (IaC), and GitOps methodologies, utilizing tools such as Argo or Flux, Helm, and Kustomize to automate and streamline deployment processes.
● Developed and implemented automation strategies to provision, configure, and manage infrastructure resources using Infrastructure as Code (IaC) principles.
● Utilized GitOps practices to manage and synchronize infrastructure configurations, ensuring consistency and reliability across environments.
● Leveraged Helm charts to define, install, and manage Kubernetes applications, simplifying the deployment and management of complex application architectures.
● Implemented customizations and configurations using Kustomize to adapt Helm charts and Kubernetes manifests to specific project requirements.
● Collaborated with cross-functional teams to design and implement scalable, resilient, and secure containerized solutions in alignment with best practices and industry standards.
● Contributed to the design and architecture of containerized platforms, optimizing performance, scalability, and resource utilization.
● Actively participated in the Kubernetes community, staying abreast of the latest developments, best practices, and emerging technologies in container orchestration and management.
● Patch and maintain docker daemon on all OpenShift nodes as a service.
● Experience in Certificate Management for Servers, created and managed OpenSSL certificates for secured Server-Client communication, maintaining confidentiality, message and bilateral Authentication.
● Experience in writing scripts using Bash and playbooks using Ansible as per the project requirements.
● Applied security vulnerability fixes for OpenShift environment using agile methodology.
● Expertise in developing Python modules to automate processes in AWS and Automated the cloud deployment using AWS, AWS CLI, Python (Pip, Boto, Boto3) and AWS cloud formation templates also Proficient in scripting for automation & monitoring using Shell Bash, PowerShell, PHP, Java, Python, YAML, Ruby & Perl scripts.
● Managing users and groups using Active Directory, UNAB for controlling user access.
● Developed ansible playbooks to actively administer the OpenShift clusters.
● Upgrade OpenShift Environment in agile methodology for the advanced features in container technology.
● Automated application onboarding process to OpenShift.
● Created ansible playbook to run automatic email alerts to monitor OpenShift clusters.
● Using Issue tracking systems and ticketing tools like Jira, HP Quality Center, Service Now, Remedy, and Microsoft Teams.
● Troubleshoot the OpenShift Infrastructure - cluster level issues, determine the root cause and apply fix.
● Applying the Monthly OS Security patches, hotfixes and minor release upgrade for the OpenShift Infrastructure servers.
● Experience with configuration management using Ansible, Chef and container management with Docker.
● I used PowerShell commands to manage my domains.
● Configure, deploy, and maintain Databricks clusters and workspaces.
● Utilize Terraform to provision and deploy Databricks clusters, workspaces, and associated AWS resources, ensuring consistency and repeatability through infrastructure as code.
● Monitor cluster performance, resource utilization, and troubleshoot issues to ensure optimal performance.
● Implement and manage access controls and security policies to protect sensitive data.
● Manage platform features and software releases and updates.
● Provide technical support to Databricks users, including troubleshooting and issue resolution.
● Conduct training sessions to educate users on platform best practices and capabilities.
● Optimize cluster configurations for performance and cost-effectiveness.
● Monitor and manage auto-scaling to ensure efficient resource allocation.
● Implement and enforce security policies, access controls, and encryption mechanisms.
● Stay up-to-date with security best practices and compliance requirements.
● Develop and maintain backup and disaster recovery strategies to ensure data integrity and availability.
● Collaborate with data engineers to integrate Databricks with other data sources, data warehouses, and data lakes.
● Monitor and manage platform costs, optimizing resource utilization to control expenses.
● Maintain detailed documentation of configurations, procedures, and best practices.
● Collaborate with cross-functional teams, including data scientists, data engineers, and business analysts, to understand their requirements and provide technical solutions.
● Administer OpenShift Infrastructure and nodes across environments.
● Managing performance monitoring and tuning using CLI tools and using third-party tools like Nagios, Inmost, and Orion.
● Installed PortWorx Container storage solution on the OpenShift cluster.
● Used Apache spark for processing large sets of data volumes for rapid processing and enhancing the output.
● Experienced in Managing Jenkins and Cloud bees, ELK.
● Experience with Docker and Kubernetes, having used ECS or EKS.
● Proficiency in at least one language from our stack: C#TypeScript.
● Strong notions of security best practices (e.g. using IAM Roles, KMS, etc.).
● Experience with monitoring solutions such as CloudWatch, Prometheus, and the ELK stack.
● Experience with APACHE ANT and Maven as a build tool for Java Application.
● Strong Experience in implementing Data Warehouse solutions in AWS Redshift Worked on various projects to migrate data from on-premise databases to AWS Redshift, RDS and S3.
● Valuable knowledge on DevOps tools such as Checkmarx, Coverity, Sonarqube, Chef, Vagrant, Virtual Box, Puppet, Ansible, Jenkins, NEXUS, Maven, ANT, GIT, TFS, Kubernetes, and Docker.
● Experience with APACHE ANT and Maven as a build tool for Java Application.
● Implemented AWS Redshift to manage data warehouse and running SQL queries.
● Performance tuning the tables in Redshift, data Validation, Quality check in Redshift using Python.
● In-depth understanding of the principles and best practices of Software Configuration Management (SCM) processes, which include compiling, packaging, deploying and Application configurations.
● Experienced in designing and distribution of Data across all the nodes and Clusters on different availability zones in AWS Redshift.
● Skilled at AWS Cloud platform and its features which include EC2, VPC, EBS, AMI, SNS, RDS, Cloud Watch, Route53, Auto Scaling, Security Groups, Redshift, and Cloud Formation.
● Experience in using Nexus and Artifactory Repository Managers for Maven builds.
● Wrote tools in Perl & shell scripting to gather user data from global network and database systems via parallel SSH connections for user management & made data available across the network via RESTful interface.
● Build and configure a virtual data Center in the AWS cloud to support Enterprise Data Warehouse hosting including Virtual Private Cloud (VPC), Public and Private Subnets, Security Groups, Route Tables, Elastic Load Balancer (ELB).
● Experience in using Configuration management software's like Chef, Puppet, Ansible and Docker for AWS/Azure.
● Manage Amazon Redshift clusters such as launching the cluster and specifying the node type as well.
● Setup and build AWS infrastructure using various resources, VPC EC2, RDB, S3, IAM, EBS, Security Group, Auto Scaling, SES, SNS and RDS in Cloud Formation JSON templates, Route53, Lambda.
● Managing data backup using EMC Networker Management console, Legato Networker, Symantec Endpoint Protection Manager.
● Completed Bachelors from The ICFAI Foundation for Higher Education TECHNICAL SUMMARY
AWS Services RDS, EC2, VPC, IAM, Cloud Formation, EBS, S3, ELB, Auto Scaling, Cloud Trial, SQS, SNS, SWF, Cloud Watch.
CI/CD Jenkins, Azure Pipelines
Artifactory Jfrog and Nexus
Web Servers Nginx
Documentation Confluence
Operating Systems Microsoft Windows XP/ 2000, Linux, UNIX. Tracking Tools Jira
Code Scanning Sonar Qube, Jfrog X ray, ECR Inspector Databases RDS, Cosmos DB, My SQL DB.
Logging Cloud Watch, Cloud Trail, Azure App Insights, Azure Monitor,ELK, Configuration & Automation
Tools
Ansible
Container Platforms Docker, Kubernetes, Redshift, Open Shift. Monitoring Tools Nagios, Splunk
Languages Python, Shell scripting.
Cloud Platforms Microsoft Azure, Aws Cloud.
Azure Services App Services, Key vault, function app, Blob storage, Azure Active Directory (Azure AD), Service Bus, Azure Container Registry (ACR) and Azure Kubernetes service (AKS), Azure SQL, Azure Cosmos DB.
Cloud Security FedRAMP
Version Control Tools GIT, Bit Bucket.
● Microsoft Certified Azure Administrator Associate.
● AWS Certified Developer – Associate.
● Certified Kubernetes Administrator.
Client: Baker Hughes. March 2023 - Present.
Location : Houston, Texas, USA
Role: AWS DevOps Engineer
Responsibilities:
● Experience on DevOps Platform team and responsible for specialization areas related to Chef for Cloud Automation.
● Worked on IAM to create new accounts, roles and groups and using Jenkins AWS Code Deploy plugin to deploy to AWS.
● Worked extensively in creating and administering different environments for development, testing, production, and deployment.
● Implemented and maintained infrastructure within FedRAMP regulated environments, ensuring compliance with Federal Information Processing Standards (FIPS) Cryptographic modules.
● Developed and implemented automated compliance checks within CI/CD pipelines to validate adherence to FedRAMP security controls, enabling rapid identification and resolution of compliance issues during the software development lifecycle.
● Worked closely with FedRAMP stakeholders, including the Joint Authorization Board (JAB) and the Program Management Office (PMO), to address security concerns, provide evidence of compliance, and facilitate the authorization process for cloud services.
● Developed scripts and templates to automate the generation of FedRAMP-required security documentation, such as System Security Plans (SSPs) and Security Assessment Reports (SARs), streamlining the authorization process and reducing manual effort.
● Experience in Product Development process and working with interdisciplinary teams with excellent organizational and project management skills.
● Utilized Configuration Management Tool Chef & created Chef Cookbooks using recipes to automate system operations.
● Deployed Prometheus with Grafana to monitor the Kubernetes cluster and configured alerts firing when different conditions met
● Responsible for implementing monitoring solutions in Ansible, Terraform, Docker, and Jenkins.
● Leveraged AWS cloud services such as EC2, auto-scaling and VPC to build secure, highly scalable and flexible systems that handled expected and unexpected load bursts.
● Manage AWS EC2 instances utilizing Auto Scaling, Elastic Load Balancing and Glacier for our QA and UAT environments as well as infrastructure servers for GIT and Chef.
● Worked as an SRE, my role is to improve and maintain the web application life cycle from inception to design, deployment, operation and refinement.
● Worked Collaboratively with Client Personnel to design and document the appropriate Enterprise DevOps & SRE Solutions that will support business objectives and developer communities such as: Configuration Management, Continuous Integration/Deployment and Cloud platforms.
● Provided solutions on new technologies based on the proof of concepts to deploy on Kubernetes cluster for edge/IOT environment
● Developed custom automation scripts and workflows using Groovy scripts, Terraform, or other automation tools to orchestrate the provisioning and management of infrastructure resources, reducing manual intervention and enhancing efficiency.
● Played a key role in ensuring compliance with industry regulations and security standards by implementing robust governance policies and security controls within the Kubernetes platform.
● Acted as a subject matter expert in Kubernetes and container technology, providing guidance and mentorship to team members and stakeholders on best practices, architectural patterns, and emerging trends.
● Conducted regular performance monitoring and optimization activities, leveraging tools like Prometheus, Grafana, and AWS CloudWatch to ensure the platform's reliability, scalability, and cost-effectiveness.
● Collaborated with cross-functional teams, including developers, operations, and security personnel, to drive continuous improvement initiatives and optimize the end-to-end delivery pipeline.
● Actively participated in knowledge sharing sessions and training programs to enhance team capabilities and foster a culture of learning and innovation within the organization.
● Automated Windows server deployments leveraging Groovy scripts, Terraform, and Jenkins pipelines, streamlining the provisioning process and ensuring consistency across On-Prem and cloud environments.
● Integrated Gradle into the build process, optimizing build configurations and dependencies management for Java-based applications.
● Hands-on experience with Amazon EKS (Elastic Kubernetes Service), managing and deploying containerized applications in the AWS cloud environment.
● Proficient in Automation, Infrastructure as Code (IaC), and GitOps methodologies, utilizing tools such as Argo or Flux, Helm, and Kustomize to automate and streamline deployment processes.
● Wrote deployment recipes for infrastructure management using Terraform.
● Automate Continuous Build and Deploy Script for Jenkins Continuous Integration tool
● Automated the cloud deployments using chef, python (boto & fabric) and AWS Cloud Formation Templates
● Have implemented chef provisioning for creation of on demand instances and instance infrastructure using the chef-client and bootstrapping using plugins against AWS EC2.
● Experience in automating private and public cloud configuration using Terraform.
● Working with AWS services such as EC2, VPC, RDS, CloudWatch, CloudFront, Route53 etc
● Experience using DevOps tool Terraform in provisioning AWS machines. Implemented a continuous deployment
(CD) pipeline involving Jenkins, Ansible to complete the automation from commit to deployment.
● Lead the cloud infrastructure maintenance effort using a combination of Jenkins, Chef and Terraform for automating CICD pipeline in AWS.
● Experience in Setting up the build and deployment automation for Terraform scripts using Jenkins.
● Created and worked on building Azure pipelines in YAML for CI/CD process and schedule the pipelines to run.
● Created YAML Scripts from the scratch to build the Azure CI/CD pipelines with given requirement.
● Worked with AWS CloudFormation Templates, terraform along with Ansible to render templates and Murano with Orchestration templates in OpenStack Environment, also worked with Ansible YAML Automation scripts to create infrastructure and deploy application code changes autonomously.
● Writing the JSON and YAML scripts to improve alert manager to get the proper information about the alerts on a Grafana dash board.
● Collaboration using Orchestration with Keystone, Kubernetes and other functions within Open Stack.
● Provisioned the highly available EC2 Instances using Terraform and cloud formation and wrote new plugins to support new functionality in Terraform.
● Worked on the creating the YAML scripts for azure pipelines for creating the monitor metrics conditions to alert.
● Setup Nginx Ingress controller to manage the ingress/egress routing rules for Kubernetes
● Written some Groovy scripts for setting up LDAP configuration for Jenkins using security matrix.
● Administering Jenkins and secured Jenkins with role-based access controls and matrix-based project access.
● Managed Maven project dependencies by creating parent-child relationships between projects.
● Build script using MAVEN build tool in Jenkins to move from one environment to other environments
● Setup all different kinds of projects in Jenkins ranging from software to maven style projects and matrix-based projects
● Experience in Jenkins monitoring external jobs, distributed builds, and plugin management.
● Leveraged several Jenkins plugins to automate tasks like code coverage, metrics, aws-ec2 plugin, and job creation.
● Performed proof of concepts on various open-source CNCF graduated solutions to test and deploy with Kubernetes.
● Working with release and deployment in java/j2ee, C, C++, Helm charts and web application environment.
● Developed C, C++ scripts for developed in Unix admiration environments.
● Researched and implemented code coverage and unit test plug-ins with Maven/Jenkins.
● Written puppet modules for logstatsh, elasticsearch and kibana and Used puppet to measure the AWS metrics
● Used Maven dependency management system to deploy SNAPSHOT and RELEASE artifacts to JFrog to share artifacts across projects.
● Experience in setting up and managing Azure Databricks clusters and workspaces.
● Utilize Terraform to provision and deploy Databricks clusters, workspaces, and associated AWS resources, ensuring consistency and repeatability through infrastructure as code.
● Develop and maintain backup and disaster recovery strategies for Azure Databricks to ensure data integrity and availability.
● Collaborate with data engineers to integrate Databricks with other data sources, data warehouses, and data lakes.
● Automate application onboarding process to Azure Databricks.
● Manage platform features and software releases and updates for Azure Databricks.
● Provide technical support to Databricks users, including troubleshooting and issue resolution.
● Conduct training sessions to educate users on platform best practices and capabilities.
● Optimize cluster configurations for performance and cost-effectiveness.
● Implement and enforce security policies, access controls, and encryption mechanisms for Azure Databricks.
● Experience in AWS Ansible Python Script to generate inventory and push the deployment to.
● Managed the configurations of multiple servers using Ansible.
● Able to develop and build the platform for building data and ML operations.
● Maintain Azure infra (certified preferred) using Databricks (hands-on experience).
● Leveraging AKS (hands-on experience) and doing automation using Python scripting.
● Should be able to create parameterized workflows (Databricks Developer, ETL not mandatory).
● Should be able to expose workflows as APIs and deploy the solution (Python Backend Developer, and some DevOps).
● Designed Delivery pipeline in Jenkins based on different Environments like Dev, SIT, UAT and Production. Environments: Git, Chef, Kubernetes, Jenkins, AWS, Maven, Apache Tomcat, Openshift, Redshift, MySQL, Plutora, BlackDuck, CSS, JIRA, YAML, AWS Cloud, Shell Scripts, Cloud Watch. Client: Takeda. Mar 2021 - Feb 2023.
Location: Boston, Massachusetts, USA
Role: Azure DevOps Engineer
Responsibilities:
● Managed Azure Security groups using Azure Portal and PowerShell scripts and attached them to VM’s and Subnets
● Docker environments created and maintained for containerized micro services-oriented environments and for hosting images configured private container registry on Microsoft Azure by creating docker files.
● Created and managed pods. Migrated the Micro Service Based applications from Virtual Machines to Docker containers and docker registry
● Data from On-Premise SQL Database servers to Azure SQL Database servers was sent by designing the Azure Data Factory Pipelines using the Azure Data Factory Copy tool and Self-Hosted Runtimes.
● Configured Azure web apps, Azure App Services, Azure Application insights, Azure Application gateway, Azure DNS, Azure Databricks, Azure Traffic manager, App services, Analysing Azure Networks with Azure Network Watcher, Azure stack, Azure Backup and Azure Automation.
● Code repository management, code merge and quality checks with Bitbucket.
● Worked with various Azure services like Web Roles, Worker Roles, Azure Websites, Caching, SQL Azure, Net worker servicers, API Management, Active Directory (AD) services infrastructure in advocating, maintaining and monitoring and Azure Active Directory (AAD) infrastructure, incorporated with periodic auditing, troubleshooting and performance.
● Created and managed Kubernetes Pods, Services, ConfigMaps, Deployments.
● Worked with Terraform Templates to automate the Azure Iaas virtual machines using terraform modules and deployed virtual machine scale sets in production environment.
● Expertise in writing MAVEN/ANT scripts for automation of build and deployment. Maintain a Live Like environment to test any production issues on the setup and push it into production.
● Configured and maintained stress server in different geographical location and provide setup in every release to perform stress testing.
● Experience in Developing KORN, BASH, PERL, Python shell scripts to automate cron jobs and system maintenance. Scheduled cron jobs for job automation through Autosys.
● Created and maintained Jenkins jobs that execute shell script.
● Performed Shell Scripting (bash, python and ruby) to monitor logs, disk space, services and process.
● Written Templates for Azure Infrastructure as code using Terraform to build staging and production environments. Integrated Azure Log Analytics with Azure VMs for monitoring the log files, store them and track metrics and used Terraform as a tool, Managed different infrastructure resources Cloud, VMware, and Docker containers.
● Written Maven scripts, Installed Jenkins, written shell script for end to end build and deployment automation.
● Automation of ETL loads into Redshift Database using Windows Batch Scripts.
● Provisioned Redshift clusters for descriptive, predictive and prescriptive analytics of big data with traditional Business Intelligence tools
● Experience in Developing KORN, BASH, PERL, Python shell scripts to automate cron jobs and system maintenance. Scheduled cron jobs for job automation through Autosys.
● Performed Shell Scripting (bash, python and ruby) to monitor logs, disk space, services and process.
● Kernel tuning, Writing Shell scripts for system maintenance and file management.
● Worked with Azure Cloud Terraform API to create infrastructure on Azure as a code, write YAML script to build infrastructure.
● Create Jenkins job to build the artifacts using maven, deploy the Terraform templates to create the stack
● Working on build Systems such as Make, Maven.
● Using YAML and Python scripting templates developed automation and deployment utilities.
● Converting the ANT Build projects to Maven Build projects.
● Championed in cloud provisioning tools such as Terraform and CloudFormation.
● Developed automation of Kubernetes clusters with Ansible, writing playbooks with YAML Scripting. Used Ansible and Ansible Tower as configuration management tool to automate repetitive tasks, patching and software deployment
● Capable of doing Ansible setup, managing hosts file, Using Yaml linter, authoring various playbooks and custom modules with Ansible.
● Wrote Ansible playbooks from scratch in YAML. Installing, setting up & Troubleshooting Ansible, created and automated platform environment setup.
● Developed Terraform scripts to build, change and version infrastructure as code.
● Worked in Agile Environment
● Coordinated with the Project Management, Development and QA Team in resolving any configuration and deployment issues to provide smooth release process. Environments: Microsoft Azure (Including ASP, VNETs Web & Mobile, Blobs, Resource groups, Key Vault, Azure SQL, CouchDB, RabbitMQ), Bitbucket, Ansible, Docker, Kubernetes, Bamboo, Maven, Nexus, Shell Scripts, Terraform, Redshift, .Net, Rally, Nagios, PowerShell.
Client: CEI America. July 2018 - Feb 2021.
Location: Pittsburgh, Pennsylvania, USA
Role: DevOps Engineer
Responsibilities:
● Involved in DevOps migration/automation processes for build and deploy systems.
● Consulted and
Contact this candidate