Ram Middidoddi
Sr. Devops Engineer
Email: ad3nib@r.postjobfree.com
Ph No: +1-469-***-****

Professional Summary

Over 10+ Years of experience in IT industry as AWS DevOps Engineer, Build/Release Management, includes Site Reliability practices such as SLA/SLO Management Linux system Administrator, DataDog and Cloud Management in all phases of SDLC like Analysis, Design. Development, Deploying, Testing and Maintenance of various web-based applications.
In-depth knowledge on JMX and MBean APIs to build, deploy, and manage enterprise applications to J2EE servers.
Integrated JMX with existing monitoring and alerting systems, providing seamless integration and centralized monitoring of the application stack.
Specialized in trouble shooting memory issues on Application Server by taking Thread/Heap dumps, analyzing the same.
Using Heap Dump Analyzer, Thread Dump Analyzer, Command line recommending appropriate memory tuning parameters.
Strong troubleshooting in WebLogic by taking thread dumps and heap dumps.
Experienced in AWS Cloud platform with features ЕС2, VPC, ELB, Auto-Scaling, Security Groups, IAM, EBS, AMI, RDS, S3, SNS, SQS, CloudWatch, CloudFormation.
Created a high availability and scalable AWS stacks using EC2 auto scaling functionality. Used AWS CloudWatch extensively to monitor and debug the cloud-based AWS EC2 services.
Worked on using Chef Attributes, Chef Templates, Chef Recipes, and Chef Files for managing the configurations across various nodes using Ruby scripting.
Analyze time series metric logs for upstream and downstream traffic in Prometheus/Kafka and Grafana Dashboards. Responsible for automation and orchestration of cloud services offerings on AWS.
Deployed cloud stack using AWS OpsWorks, Optimized volumes and EC2 instances & Created multi AZ VPC instances.
Experienced Developer with extensive experience in Datadog, AWS, and Kubernetes EKS, with a focus on creating and implementing reliable monitoring and observability solutions.
extensive knowledge of using Datadog to track and analyze infrastructure data, application health, and system performance across AWS environments.
proficient in using Datadog to build custom metrics, monitors, and dashboards that provide information on resource use, application performance, and operational effectiveness.
Used CloudWatch and Datadog to monitor AWS resources such as EC2 instances, RDS databases, and Lambda functions for performance and availability, and to set up alarms to notify the team of any issues.
Expertise in integrating Grafana with various monitoring tools like Instana, DataDog, and AppDynamics to create comprehensive and unified monitoring dashboards.
Experience in using Nexus and Artifactory Repository Managers for Maven builds and also Experienced in scripting languages like Python, PowerShell, Ruby, Perl, Bash.
Hands on experience with Chef, Ansible, Run Deck, AWS, Ruby, Vagrant, Pivotal Tracker, Bash and middleware tools.
Experience in changing over existing AWS infrastructure to Serverless architecture (AWS Lambda, AWS Kinesis) through the creation of a Serverless Architecture using AWS Lambda, API gateway, Route 53, S3 buckets.
Used configuration management tools Chef, Puppet, Atlassian and CF Engine and Web Service like AWS.
Hands-On experience in Implement, Build and Deployment of CI/CD pipelines, managing projects often includes tracking multiple deployments across multiple pipeline stages (Dev, Test/QA staging and production with Strong hands on experience on Palo Alto Firewalls, PIX Firewalls, ASA Firewalls.
Extensively worked on Hudson, Jenkins, Cruise Control Hudson, Bamboo and UDeploy for continuous integration and continuous delivery to achieve End - to-End automation for all build and deployments.
Experienced with Puppet, Ansible, Chef and saltstack as System Configuration Tool.
Deployed and configured Chef Server including bootstrapping of chef-client nodes for provisioning.
Created roles, recipes, cookbooks and data bags for server configuration.
Exposure to administration of servers such as Apache, Tomcat, WebLogic, JBoss & WebSphere.
Experience in setting up Baselines, Branching, Merging and Automation Processes using Shell/bash and Batch Scripts.
Extensive Experience of Operating Systems including UNIX, Linux, Solaris, Windows NT2000/7/XP/Vista, Windows Server 2008 and Expertise in TCP/IP, AD, DNS, DHCP, WAN, LAN, SMTP.
Implemented a CI/CD pipeline using Azure DevOps (VSTS, TFS) in both cloud and on-premises with GIT, MS Build, Docker, Maven along with Jenkins's plugins.
Extensively worked with version control systems like GIT, CVS, Perforce version.
Experience in writing Docker files to build the micro-service applications.
Experience in implementing, administering and monitoring tools Splunk, Nagios, Consule, Netcool, Graphite and building, deploying Java and SOA applications and troubleshooting the build and deploy.
Experience in all stages of software development cycle thorough with software methodologies like Waterfall, RUP, Scrum and Agile.
Expertise in Querying RDBMS such as Oracle, PL/SQL and MY SQL by using SQL for Data integrity.
Experience in Installing, upgrading and configuring Red Hat Linux 4.х, 5.х, and 6.х using Kickstart Servers with Administration experience in GitHub and SVN configuration tools.
Experienced writing python, yaml, ruby and shell scripts to automate the deployment and scheduling.
Experienced with Nagios, CloudWatch as IT Infrastructure Monitoring tool.
Experienced with Web/Enterprise Application Deployment Technology specifically including Apache Tomcat, WebLogic, Web Sphere 5.1/6.0, Java and MySQL.
Experience working Data Center's managing Servers, SAN and NAS devices like HP, Cisco, Brocade, EMC and HDS devices.
Education

Bachelors in Electronic and Communication from Jawaharlal Nehru Technological University, India.

Technical Skills

Cloud Environment

Amazon Web Services (AWS), Azure, OpenStack, Google Cloud (GCP).
Languages
C#, C++, Java/J2EE, ASP.NET and python
Scripting
Shell, Python, Ruby, Power Shell, YAML, Groovy, Bash
Version Control Tools
SVN (Subversion), GIT, CVS, GitLab, GitHub, Bitbucket
Build Tools
Ant, Maven, Gradle, IBM UDeploy, Release.
Configuration Management
Chef, Puppet, Ansible, Terraform, Grafana.
Continuous Integration Tools
Jenkins, UDeploy, New Relic, Datadog.
Ticketing Tools
JIRA, Bugzilla and Confluence.
Monitoring Tools
Nagios, Splunk, Cloud Watch, ELK Stack
Artifactory Repositories
Nexus, JFrog.
Methodologies
Agile, Scrum, Waterfall.
Operating Systems

Unix/Linux (Red Hat, CentOS, SUSE), Solaris, Ubuntu, Windows 2008, 2012 Server, XP, Vista
Databases
Oracle, MS SQL Server, MySQL, Dynamo DB, Mongo DB, NoSQL, PostgreSQL
Virtualization
Virtual Box, VMWare, Windows Hyper-V

Role: Sr. DevOps Engineer MAY-2022 - Present
Client: PNC Financial Services Group INC, PA.

Environment: AWS, IBM UDeploy, Release, Ansible, Kubernetes, Data dog, GCP, Jenkins, Git, Splunk, EC2, ELB, RDS, Docker, Google Container Registry, Azure Monitor, Google cloud storage, Elk, Kubernetes, GitHub, Ansible, Terraform, Maven, Nexus, Jira, TFS, CI/CD Pipelines.

Managed a team of site reliability engineers responsible for ensuring the availability, scalability, and performance of critical production systems.
Focused on application availability, application performance and minimized downtime/failure.
Led multiple cross-functional project implementations and solutions deployments for mission-critical systems & Tuned TCP/IP, JVM's, Garbage Collections, Java Stack and Native Thread.
Experience in troubleshooting Garbage Collection Issues and Memory Leaks Issues and adjusting the JVM Heap Sizes and GC Parameters.
Server Hang, Deadlock, application level lock, database level lock by taking thread dump and analyze to get the root cause for the hang.
Experienced with JVM performance tuning by optimizing Heap size and Garbage Collection.
Configured and fine-tuned JMX settings for optimal performance and security, ensuring efficient and secure remote management of the application.
Implemented JMX-based notifications and event handling to detect and react to critical system events, enabling proactive alerting and automated recovery actions.
Utilized TDMA (Thread Dump Analysis) to diagnose and troubleshoot performance issues in Java applications, identifying bottlenecks and areas of improvement.
Good Experience in set up and build AWS infrastructure various resources (VPC, EC2, S3, IAM, EBS, Security Groups, Auto scaling, RDS).
Expertise in developing web - based application based on java technologies using J2EE, J2SE, Hibernate, Python, JSP, Struts, Multithreading, Data Structures, Java Servlets, JDBC, JNDI, Spring, JSF, EJB, XML, WSDL, Spring Boot, SAX/DOM.
Responsible for ensuring the reliability, availability, and performance of systems and applications, and implementing automation to improve efficiency and reduce downtime.
Build/Configure and maintain source/byte code management system such as GIT and Nexus.
Responsible for overseeing and managing the incident/crisis management process, ensuring that issues are quickly identified, triaged, and resolved.
Involved in designing and deploying multiple applications utilizing almost all the AWS stack (Including EC2, Route53, S3, RDS, Dynamo DB, SNS, SQS, IAM) focusing on high-availability, fault tolerance, and auto- scaling in AWS Cloud Formation.
Experience in Amazon Cloud Services (AWS) and its features (AWS teraEC2, VPC, EBS, AMI, APIs, Route 53, snapshots, Autoscaling, Cloud Formation, Lambda, SES, SNS, ELB, EBS, CloudWatch, S3 etc.)
Configured Splunk to ingest logs from Servers and Applications, S3 (CloudTrail), CloudWatch logs with Experience on various monitoring tools like Datadog, Splunk and new relic to ensure our IT infrastructure.
Setup datadog monitoring across different servers and aws services & Integrated cloud check, Datadog. Splunk Dashboard with aws accounts.
Monitored CloudFront to deliver content from AWS edge locations to users, allowing for further reduction of load on front-end servers and utilized AWS CLI to automate backups of ephemeral data-stores to S3 buckets and create nightly AMIs for mission critical production servers as backups.
Expert in using AWS lambda to run servers without managing them and to trigger to run code by S3 and SNS & Proficient in building RESTful APIs using NodeJS, Java, Express, and MongoDB to support the backend of web applications.
Expertise in building CI/CD on AWS environment using AWS Code Commit, Code Build, Code Deploy and Code Pipeline and in using AWS CloudFormation, and AWS Lambda in automation and securing the infrastructure on AWS.
Managed other AWS Services like S3, CloudFront, Cloud Watch, RDS, Kinesis, Redshift Cluster, Route53, SNS, SQS, and Cloud Trail.
Automated infrastructure provisioning on AWS using Terraform and Ansible.
Ansible playbooks from scratch in YAML. Installing, setting up & Troubleshooting Ansible, created and automated platform environment setup on AWS cloud.
Developed and implemented automated deployment pipelines using IBM Urban Code Deploy for a large-scale enterprise application, reducing the deployment time from days to hours.
Automating the Build Infrastructure for deploying services in dockized environment using Jenkins, SonarQube, Gradle, Groovy, Job DSL, Docker and Splunk.
Splunk implementation, planning, customization, integration with Application servers, big data and statistical and analytical modeling.

Role: Sr. DevOps Engineer MAR2021 - APR2022
Client: Cigna Health care, Nashville, TN.

Environment: AWS (IAM, EC2, S3, EBS, ELB, New Relic, Cloud Formation, Cassandra, Grafana, Cloud Watch, Cloud Trail, SNS, Route53,), Ansible, Splunk, Docker, Kubernetes, Jenkins, Python, Git, Terraform, Chef, GCR.

Developed and executed strategies to fine-tune GC parameters and optimize heap settings based on application requirements and workload characteristics.
Utilized GC profilers like Your Kit, VisualVM, or Java Mission Control to perform in-depth analysis of GC behavior, identifying inefficiencies and recommending optimizations.
Conducted performance testing and benchmarking of Java applications under different GC configurations, evaluating the impact on response times, throughput, and memory utilization.
server Performance Tuning -Thread Dump Analysis, Core Dump Analysis when Server crashed unevenly.
Involved actively in troubleshooting application issues by analyzing the performance metrics from WebLogic console, thread dumps and polling certain key mbean attributes using WebLogic.
Managed a vendor software upgrade project, leading and driving the overall progress with regular status reporting to VUMC leadership, ensuring that the project was completed on time and within budget.
Strong analytical and problem-solving skills, with an ability to identify issues, propose solutions, and implement changes that improve system performance and reliability.
Responsible for Day-to-day Build and deployments in Dev, Test, pre-production and production environments. Implemented AWS high availability using AWS Elastic Load Balancing, which performed balance across instances in multiple availability zones.
Vast experience on server monitoring tools like New Relic, AWS CloudWatch, Visual, 13 Monitoring, Perfmon, Datadog. Web Page Diagnostics, etc.
Created management consoles and dashboards using JMX to visualize and analyze system metrics, facilitating proactive performance tuning and issue identification.
Currently working on Dashboard Designing for Cloud migration project using the following tools, like Splunk, DataDog, CloudWatch & d Kubernetes and Experience in creating Splunk and DataDog dashboard and Alerts creation.
Used AWS Route53, to route the traffic between different availability zones. Deployed and supported AWS Elastic Cache & then configured Elastic Load Balancer (ELB) for routing traffic between zones. Used Elastic Block Store (EBS) for persistent block level storage and performed access management using Identity Access Management (IAM) service.
Created custom metrics from AWS logs to create alarms and used CloudWatch and CloudTrail.
Designed and implemented scalable, secure cloud architecture based on Amazon Web Services.
Written Terraform templates, Chef Recipes and pushed them into Chef Server for configuring EC2 Instances, and deployed code in to the required environments using AWS Code Deploy.
Launched Amazon EC2 Cloud Instances using Amazon Images (Linux/ Ubuntu) and configured launched instances with respect to specific applications.
Install Splunk forwarder on various platforms like windows, Linux, Unix.

Role: Sr. DevOps Engineer NOV2019 - FEB2021
Client: CBRE, Dallas/TX.

Environment, EC2, S3, VPC, AWS, GCP, Jenkins, GIT, GITHUB, Ansible, Datadog, Docker, Splunk, Maven, Ant, SonarQube, Python, Terraform, IAM Roles, Nginx, Nagios, CloudWatch, Cloud trail, Route53, SNS, Kubernetes, Apache, Tomcat, Groovy, Ruby, Shell, Bash, Bitbucket.

Experienced Developer with extensive experience in Datadog, AWS, and Kubernetes EKS, with a focus on creating and implementing reliable monitoring and observability solutions.
extensive knowledge of using Datadog to track and analyze infrastructure data, application health, and system performance across AWS environments.
proficient in using Datadog to build custom metrics, monitors, and dashboards that provide information on resource use, application performance, and operational effectiveness.
Used CloudWatch and Datadog to monitor AWS resources such as EC2 instances, RDS databases, and Lambda functions for performance and availability, and to set up alarms to notify the team of any issues.
Automated the AWS Cloud platform Infrastructure using AWS Cloud Deployment Manager. Used AWS App Engine for deploying and scaling web applications and services developed with Java.
Using Cloud Trail, Cloud Passage, Check Marx, Qualys Scan tools for AWS security and scanning.
Created AWS Cloud Formation templates to create custom sized VPC, subnets, EC2 instances, ELB, security groups.
Analyzed the java garbage collection behavior, heap dumps and thread dumps, identification of connection leak and memory leak of the application under test.
Developed data garbage collection regression and analysis tool to evaluate improvements in GC mechanism, uncovering production bugs by analyzing certain data trends after GC.
Created AWS cloud formation templates for the migration of applications from on-premises to AWS and to create custom-sized VPC, subnets, EC2 instances, ELB, security groups.
Maintained DNS records using Route53 to Improve Fault Tolerant Connections and using Load Balancer, Security groups and NACLS.
Hands-on experience in Terraform for building, changing, and versioning of Infrastructure and wrote Templates for AWS infrastructure as a code using Terraform to build staging and production environments.
Monitored CloudFront to deliver content from AWS edge locations to users, allowing for further reduction of load on front-end servers and utilized AWS CLI to automate backups of ephemeral data-stores to S3 buckets and create nightly AMIs for mission critical production servers as backups.
Expert in using AWS lambda to run servers without managing them and to trigger to run code by S3 and SNS.
Implemented Cloud Infrastructure as a Service (IaaS) Automation across AWS Public Cloud using Packer & Terraform and implemented Terraform Enterprise to Provision Infrastructure across AWS Workloads.
Managed other AWS Services like S3, CloudFront, Cloud Watch, RDS, Kinesis, Redshift Cluster, Route53, SNS, SQS, and Cloud Trail.
the GCP infrastructure using Private subnets, Security groups, NACL(VPC), WAF etc.
Developed and Automated the Tests to validate the correctness of the Servers Configuration. Expressed in YAML Code and Used GIT to update the playbooks to the GIT repository.
Used MAVEN as build tools on Java projects for the development of build artifacts on the source code.
Good experience in Splunk, WLST, Shell scripting to automate and monitor the environment routine tasks. Configured network and server monitoring using ELK Stack with Log spout and Nagios for notifications.
Experience in writing Bash, Shell Scripts to automate the administrative tasks and management.

Role: DevOps Engineer SEP2018-OCT2019
Client: SAFEWAY, TEXAS.

Interacted with client teams to understand client deployment requests.
Handling AWS Cloud Operations starts from Architecture Design till Application delivery.
Handling almost entire cloud operations like EC2, EBS, RDS, VPC, ELB, Autoscaling etc. and leading the team of Cloud Engineers.
Architecting High Available, Auto scalable platforms in AWS cloud on Windows & Linux.
Implemented Aws solutions using EC2, lambda, S3, RDS, EBS, Elastic Load Balancer, and Auto scaling groups, Optimized volumes and EC2 instances.
Set up CI/CD pipelines for Microservices and integrated tools such as Maven, Bitbucket, SonarQube, Nexus, Docker, Slack for providing immediate feedback to DEV teams after code check-in.
Set up Git repositories and SSH Keys in Bitbucket for Agile teams.
Octa integration with AWS solutions for identity kept at cloud, Create and attach volumes on to EC2 instances.
Deployed Puppet, Puppet Dashboard and Puppet DB for configuration management to existing infrastructure. Wrote Puppet models for installing and managing java versions.
Implemented Puppet Master, Puppet Console and Puppet Agents, Create Puppet modules and Classes.
Rehydration of AWS servers are performed periodically to upgrade the application's infrastructure to have latest OS and configuration.
Installed and maintained core network equipment such as Routers, Switches, Firewalls, and Load Balancers. Configured routing protocols like RIP, EIGRP & BGP in Cisco.
Configured and supported Cisco Load Balancer (CSS) for server load balancing and Cisco PIX/ASA Security Appliances, L2L VPN tunnels.
Configured STP, VTP, VLANs, Trunking, Port Channels, InterVLAN routing, HSRP, ACLs, NAT, etc. Provided support for communication facilities such as SONET, DWDM, FR, ATM, 11, T3, OC3, EVPL, etc.
configured servers to host Team Foundation Server (TFS) instance to setup and manage Continuous Integration (CI) using Team Foundation (TF)Build Service.
Used Docker for setting in Azure Container Registry with Docker and Docker -compose and actively involved in deployments on Docker using Kubernetes.
Facilitated the flow of information, by organizing and presiding over regularly scheduled meetings with all Aurora Lounge Team Members. Design, deploy, maintain Ubuntu server environments primarily hosted in AWS.

Role: DevOps Engineer NOV2017-AUG2018
Client: FANNIE MAE, Herndon, VA

Migrated existing databases from on premise to AWS using various tools using AWS Data Migration Services and AWS Schema Conversion Tool.
Created highly available and scalable infrastructure in AWS cloud by using various AWS services like EC2, VPC, Auto scaling, ELB, RDS, Route53.
Migrated corporate Linux servers from physical servers to Amazon AWS virtual instances.
Worked on AWS Elastic load balancing for deploying applications in high availability and AWS Auto Scaling for providing high availability of applications and EC2 instances based on the load of applications.
Installed Workstation, Bootstrapped Nodes, Wrote Recipes, and Cookbooks and uploaded them to Chef-server, Managed On-site OS/Applications/Services/Packages using Chef.
Implemented and maintained the monitoring and alerting of corporate servers/storage using AWS CloudWatch to ensure reliability of applications, developed and deployed stacks using AWS Cloud Formation templates
Environment provisioning solutions using Docker, Vagrant and Red Hat Satellite.
Used Ansible Playbooks to Manage Configurations of AWS Nodes and test Playbooks on AWS instances using Python. Run Ansible Scripts to provision Dev servers.
Worked on Ansible for configuration management and infrastructure automation.
Worked as a part of OCSC team which administers and provides support for Oracle SaaS, PaaS and IaaS (OCI) Oracle Cloud.
Deployed and configured Elasticsearch, Logstash and Kibana (ELK) for log analytics, full text search, application monitoring in integration with AWS Lambda and CloudWatch. Then store that logs and metrics into S3 bucket using Lambda function.
Implemented a Kubernetes Container Orchestration solution within OpenStack allowing for easy management, creation & recovery of OpenStack assets.
Configured and deployed GIT repositories with branching, tagging, merge requests, and notifications and installed and configured Jenkins for Automating Builds and Deployments through integration of Git into Jenkins to automate the code check-out thus providing an automation solution.
Administered Jenkins continuous integration server installation and configuration to automate application packaging and deployments.
Used various plug-ins to extend the base functionality of Jenkins to deploy, integrate tests and display reports.
Worked with various scripting languages like Bash, Shell, Ruby and Python.
Environments: Maven, Nexus, Ansible, Jenkins, Docker, Azure, Kubernetes, Puppet, Chef, Terraform, Nagios, Apache, GIT, AWS EC-2, Route 53, S3, VPC, SQS, Auto scaling, ELB, Shell Scripts, Unix/ Linux environment.

Role: DevOps Engineer JUN2015-OCT2017
Client: Activision, TX.

Sending the Uptime and Downtime notifications to teams regarding Servers Status as a part of the Build Engineer role at the time of deploying the EAR and WAR package in Tomcat Admin Console.
Participated in the release cycle of the product which involves environments like Development QA UAT and Production.
Responsible for Regular Build jobs are initiated using the Continuous Integration tool like Jenkins.
Used Jenkins/Cruise Control in conjunction with ANT, Maven and MS Build to automate the builds.
Publishing the Release notes for all the releases.
Configured Jenkins for doing the build in all the non production and production environments.
Used Remedy change management and bug tracking to track the issues in all pre production and production environments.
Coordinated with all the teams before and after the production deployments for the smooth production releases.
Used Artifactory repository tool for maintaining the java based release code packages.
Provided the assistance for the smooth phase of Release for the Emergency and Expedite Releases by getting the Director Level Approval and coordinating with different teams.
Written Shell scripts to apply the Integration label to all the files which needs manual labelling of files.
Gathered all the stakeholder approvals, necessary signoffs while acting as a release manager for two development teams.
Installation, Configuration and Management of RDBMS and No SQL tools such as Dynamo DB.
Creating S3 buckets and maintained and utilized the policy management of S3 buckets and Glacier for storage and backup on AWS.
Configured an AWS Virtual Private Cloud (VPC) and Database Subnet Group for isolation of resources within the Amazon RDS Aurora DB cluster.
Experience in creating notifications and alarms for EC2 instances using Cloud Watch.
Good knowledge of AWS services like Glacier, ELB (Load Balancers), RDS, SNS, SWF, and IAM and hands on experience on Amazon Web Services (AWS) provision.
Deployed and monitored scalable infrastructure on Amazon Web Services (AWS)using Terraform.
Automated deployment modules of IIS web applications, bindings and configuration settings using a combination of PowerShell scripts.
Configured GIT with Jenkins and schedule jobs using POLL SCM option.
Responsible for installing Jenkins master and slave nodes and configure Jenkins builds for continuous integration and delivery.
Build scripts using ANT and MAVEN build tools in Jenkins to move from one environment to other environments.
Create and setup automated nightly build environment for java projects using MAVEN.
Using Jenkins AWS Code Deploy plugin to deploy and Chef for unattended bootstrapping in AWS.
Involved in setting up builds using Chef as a configuration management tool and managed the configurations of more than 270 servers.
Successfully developed and implemented backup and disaster recovery automation processes for APM solutions via NSH shell scripting to build in redundancy and maximize infrastructure uptime.
Implemented a Continuous Delivery pipeline with GitHub, Jenkins, Docker and AWS AMI's, whenever a new GitHub branch gets started, automatically, Jenkins, our Continuous Integration(CI) server attempts to build a new Docker container from it, the Docker container has the AMI baked in and leverages Linux containers.
Environment: AWS, Linux, Shell, Docker, Jenkins, GIT, ANT, Maven, Chef, Tomcat, WebSphere.

Role: Build & Release Engineer OCT2012-MAY2015
Client: FRESHQO, TX.

Worked in team environment to automate the deployments using scripts which execute the automated CI and release management process.
Version control system Team Foundation server is used for Source code management and integrated to AnthillPro to build the artifacts.
Automate Deployment on Open stack as well as artifact repository manager Artifactory, using configuration Management tool like Chef.
Employed Puppet to configure production and test infrastructure provisioned with Apache, Nginx and MySQL.
Exposed to all aspects of software development life cycle (SDLC) such as Analysis, Planning, Developing, Testing and Implementing and Post-production analysis of the projects.
Worked on Installation, configuration and upgrading of RedHat server software and related products.
Installation of patches and packages using RPM and YUM in Red hat Linux using patch add and pkg add in Linux Operating System.
Scheduled backup and recovery jobs using Crontab.
Installed, configured and maintained Apache Tomcat Web Server/JBOSS.
Configuring and administering LDAP, DNS and Sendmail on RedHat Linux.
Use of Disk Management Utility for file system management and file system creation.
Bash Shell Scripting for job automation.
Worked as part of a team and provide 7x24 support when required.
Bugzilla is used for tracking bugs and raised tickets to get resolved.

Role: Linux System Administrator JAN2012 – SEP2012
Client: Standov Corp, Hyderabad, India.

Experience with upgrading ESX 3.0 to ESX 3.5 also using VMware update manager to install patches and updates on ESX host and virtual machines.
Worked in team of five System Administrators and five System Analysts to perform daily tasks required for supporting an enterprise Hospital Network with over 1500 users, 150 servers, and 10 remote Clinics.
Maintained 10 Linux Servers which provided security and services for other Windows machines on the network such as: DNS, NAT, Anti-Virus/Spam, and Firewall via iptables.
Managed backups for Windows, Linux, PACS, and File Servers to EMC Clarion SAN device.
Provisioned, audited, and administered server logs, backups, and Active Directory objects including remote forests.
Responsible for Installing, configuring Virtual Infrastructure environment using ESX 3.Х, VCS, НА, DRS and VMotion.
Familiarity with log analysis and troubleshooting tools such as Log watch, Syslog, and Journalctl to diagnose and resolve system issues.
Features such as SE Linux, firewalls, and encryption, and experience implementing security best practices.
Experience with package management tools such as Yum and RPM to install, update, and manage software packages on CentOS 7 systems. with kernel tuning and system performance optimization to ensure maximum system performance.
Provisioned, audited, and administered server logs, backups, and Active Directory objects including remote forests.
Researched
Contact this candidate