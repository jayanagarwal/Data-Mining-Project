Vivek
acvq5p@r.postjobfree.com
469-***-****

Over 8+ years of diversified experience as Senior Quality Assurance Analyst/ Performance Engineer, Experience includes Requirement Analysis, Manual Testing, Automation and quality assurance of Client/Server, Web based and SOA. Extensive experience using automated tools like HP Load Runner and JMeter. Proven self-starter, motivated team player with Leadership abilities, excellent communication and interpersonal skills.

Technical Experience:

Experience working in Different domains like Insurance, Pharmaceutical, Financial and Retail sectors with a unique combination of skill set in solving complex quality assurance challenges, and implementing solutions that work.
Expertise in testing Web/J2EE technologies, .Net, middleware, Web services, API’s, Customer facing applications.
Excellent understanding of the functionalities of QA in Development, Enhancement and Maintenance of software applications and Software Development Life Cycle (SDLC).
Expertise in different testing methodologies like Agile, Scrum and Waterfall etc.
Experience in understanding application performance requirements, developing performance engineering strategies, wide-ranging exposure to complete performance testing using protocols and usage of performance monitoring tools.
Expertise in Unit Testing, Smoke, Sanity, Functional, Regression, Integration, System Testing, Network Testing Load, Performance, Stress, endurance, Volume, spike, failover, configuration and UAT testing .
Used Automation tools like HP Load Runner, Performance Center, ALM, and JMeter for performance testing and also QTP for Functional Automation Testing.
Experience with Load Runner components: VuGen, Controller, Analysis, Load Generator and with the components of JMeter.
Experience in testing the web services applications and API’s using SOAP UI and other similar testing tools like JMeter.
Used Bug Tracking Tools like Quality Center (QC) and Jira.
Excellent Knowledge of programming languages like C, C++, Java, .Net, SQL, Java to debug and execute Load runner scripts.
Expert in protocols like Web HTTP/HTML, Web Services, Citrix, Siebel-Web, Mainframe(RTE), FLEX, Click & Script, RDP, Mobile Web, Database, SAP and Multi Protocols for performance testing.
Experience in enhancing the VuGen, JMeter scripts by Manual Correlations technique, Parameterizations.
Good with debugging scripts by running it within VuGen with Runtime Settings and performing IP Spoofing using Load Runner to replicate a real world/Production like Scenarios.
Good skills in SQL statements, database connectivity, Oracle10g, configuring TNS file and connecting through TOAD.
Hands on experiences in analyzing performance bottlenecks, root cause analysis, monitoring end-to-end performance and fixing performance issues.
Used Monitoring tools like Wily Introscope, HP SiteScope, Fog light, App Dynamics, Windows Performance monitor, Nmon, VM Stat, I/O Stat, HP Diagnostics and Dynatrace etc.,

Excellent knowledge and skills in performance monitoring CPU, Memory, Network, Web connections, throughput, transaction response times, web/app server metrics ( Windows / Linux / AIX), Database metric and J2EE Performance while running Baseline, Performance, Load, Stress and Soak testing.
Did JVM Tuning on the Garbage collection, which is a key aspect of Java server performance and also Revised JVM Heap Sizes analyzing the Performance of the Application.
Took Thread Dumps and Heap Dumps for finding and analyzing the Bottleneck areas.
Expert in deliverables like Test Report and Test Analysis (Weekly Status Report, Work Break down structure, Defect Trend etc.
Good experience in engaging with business contacts and stakeholders for requirements gathering, architecture review and results analysis.
Good analytical, interpersonal and communication skills. Driven, committed and hard working with a quest to learn new technologies and undertake challenging assignments.

Technical Skills:

Testing Tools
Load Runner 8.1, 9.5, 11.0, 11.50, 12.02, HP Performance Center 9.5 11.0,11.5, 12, ALM, HP Quality Center, JMeter 2.5, 2.7, 2.8, 2.9, 2.10, SOAP UI and QTP
Languages
Microsoft C#, C, C++, .Net, Java
Markup/Scripting Languages
DHTML, CSS, JQuery, JavaScript, XML, HTML
RDBMS
MS SQL, Microsoft Access, SQL Server, Oracle Database
Operating Systems
AIX, HP-UX, Solaris, UNIX, Windows XP,2003,2000,Vista, Windows NT and Linux
Monitoring Tools
Performance Center, Wily Introscope, SiteScope, Dynatrace, App Dynamics, HP Diagnostics, Transaction Viewer, Splunk, Windows Performance monitor, Nmon

Professional Experience:

Client: T-Mobile, Frisco, TX Duration: Oct 2015– Till Date
Role: Lead Performance Engineer

Responsibilities:
Gathered business requirements, collecting the information about Service Level Agreement from Business Analyst and developers.
Responsible for performance testing using Performance Center, JMeter and HP Load Runner.
Developed V Users Scripts in Web, Java, and .Net, Web Services, FLEX protocol and Database Protocols.
Performance testing of client-server, web services, web-based applications, and Mobile applications.
Designed varieties of Scenarios for Baseline, Benchmark, Load, Regression, Stress, Steady state and Endurance Testing.
Parameterized large and complex data to achieve complex test to achieve accurate performance and execute test in a Performance Test environment.
Validated the scripts to make sure they have been executed correctly and meets the scenario description.
Used HPALM-Performance Center 12.01, standalone Controllers to create scenarios and run load tests.
Analyzed results using load Runner Analysis tool based on Transaction per Second, Average Response times and resource usage to meet the SLA (Service Level Agreements)
Analyze, interpret, and summarize meaningful and relevant results in a complete Performance Test report.
Develop and implement Load and Stress tests with Load Runner, JMeter and present performance statistics to application teams, and provide recommendations on the issues that impact performance.
Monitor and administrate hardware capability to ensure the necessary resources are available for all the tests.
Performed online monitoring of Disk, CPU, Memory and Network usage while running the load test.
Perform in depth analysis to isolate points of failure in the application.
Monitor and administer hardware capability to ensure the necessary resources are available for all tests.
Involved in creating Dynatrace& App Dynamics dashboard and reports using built-in and/or custom measures to present testing and analysis results effectively
Analyzing performance critical transactions using tagged web requests, Pure paths and Stack Trace of the Transactions to trace bottlenecks
Analyze Heap behavior, throughputs and pauses in Garbage collections as well as tracking down memory leaks.
Responsible for Setting up user profiles, configuring and adding application servers on Dynatrace tool
Assist in production of testing and capacity certification reports.
Investigate and troubleshoot performance problems in a Performance Test and production Environment.
Responsible for analyzing application and components behavior and optimizing server configurations.
Maintained defect status and reported testing status weekly and monthly using defect tracking tools.
Interacted with developers during testing for identifying and fixing bugs for optimizing server settings at web, app and database levels.
Environment: Performance Center, HP Load Runner, JMeter Java, .Net, MS SQL Server, MS SQL, IIS, Quality Center, Wily Inters cope, Site Scope, DynaTrace6.1, Web Services, Flex protocol, Web applications.

Client: Progressive Insurance, Cleveland, OH Duration: Feb 2014 - Sep 2015
Role: Performance Engineer

Responsibilities:

Involved in Requirements Gathering, Test Plan creation, Analysis and Reporting.
Partially Responsible to Monitor the Production, find the Performance Issues and replicate in Performance Testing environment for Fix.
Performance Testing Web Applications, Siebel Web Applications, AJAX,Oracle EBS, Mobile Native Mobile Web Applications using HP LoadRunner 11.52/12.02 and JMeter.
Web services testing using Meter and LoadRunner
Used Dynatrace, App Dynamics to monitor Production and Performance testing Environments.
Responsible for Monitoring the Performance of the Applications, findings the Bottleneck, doing Tuning.
Monitoring Mobile Native App’s in Production and Performance testing Environment using Criticism.
Creating AWR reports for every test Run and had a review meeting with the DBA’s.
Responsible for determining the room for Performance improvement for any Application or a Service while testing, Implementation and retesting.
Used JIRA for reporting the Performance Bottleneck Found.
Responsible for Setting up the environments for Performance Testing and Co-coordinating with HP Customer Service.
Used Rabbit and Jenkins for deploying the code in to Performance Testing Environments.
Involved in creating Dynatrace dashboard and reports using built-in and/or custom measures to present testing and analysis results effectively
Analyzing performance critical transactions using tagged web requests and Pure paths to trace bottlenecks
Analyze Heap behavior, throughputs and pauses in Garbage collections as well as tracking down memory leaks.
Tuned number of full GC and its CPU spikes at high memory conditions by increasing heap size and thereby eliminating JVM abnormalities
Capacity planning / sizing recommendations i.e. increase jvm heap memory, jvm database connections, additional number of jvm, additional hosts etc. based on current production metrics/ capacity baselines
Suggesting the Project teams on Configuration and Tuning Parameters on JVM, Server.XML, Timeouts, Logs and other areas of improvements.
Reviewing the deployments folders and tuning to improve the Performance.
Created a Strategy to Figure a Performance Bottleneck. Find the Time--Finding the End to End time with Breakdowns (Client, App server, Gateway, F5, and Network Time) for every project to determine the area where Performance improvement can be implemented.
Responsible for doing Load, Stress, Volume, Spike, Scalability, Failover and other testing’ s to determine the performance of the application.
Architecture review with the Project Teams along with the PE manager.
Updating the Stake holders about the performance results by generating reports using Load Runner analysis, JMETER Reports, Manual Reports about Tests, Findings and Tuning Implementations.

Environment: LoadRunner 11.52/12.0, JMeter 2.10, Java-J2EE, SOA, Web Services, Rest, SOAP, Web Services, API, XML, HTML, Oracle, Apache, JBOSS, F5, VMWARE, Unix, Linux.

Client: Kenry Home Improvement, Austin, TX Duration: Jun 2013 - Feb 2014 Role: Performance Engineer

Responsibilities:

Responsible for Test Design (Test case/ Test Data generation), Defect tracking, Reporting and Reviews of Test Execution.
Managed multiple stakeholders in Onsite-Offshore setup, Involved in all Performance engineering activities
Actively participated in the creation of Performance Test artifacts including test strategy and test plans, entry and exit criteria, test execution reports, defect/issues reports, action/item reports, and project plans.
Analyzed requirements and product specifications to determine the test objectives and the appropriate level and type of testing needed, Executed automatic test scripts for Performance and Load Testing using HP LoadRunner 11.00/11.52, HP ALM-Performance Center 11.00, and Meter
Participated in requirements and design reviews to identify test scenarios/cases to be executed for Performance and Load Testing.
Designed the Performance test Environment for accurate projection by capturing the details of Production Environment.
Used Load Runner Protocol Java VUsers, web Services and Web HTTP/HTML Protocols for Service oriented Architecture, Web Services, API’s, and TIBCO Environments.
Depending on the production volumes captured from the Business, Designed the Load tests, Performance, Stress tests, Volume and Long-Duration/Soak Test Scenarios
Extensively used JMeter for Performance testing SOA, Web services and API’s.
Analyzed applications test Results and Environment behavior under high Loads and optimized server configurations.
Tested performance of J2EE, J2SE, SOA, and Apache Tomcat, Web sphere App Server, F5 and IBM Data Power Appliances.
Analyzed CPU Utilization, Memory usage, thread usage, Garbage collection, and DB connection to verify the performance of the Application.
Analyzed the network connections and logs to troubleshoot any network issues.
Used monitoring tool such as Wily, Dynatrace, HP Performance Center 12, HP diagnostics,
Generated performance graphs using tools like Splunk and Fog light etc.
Used LoadRunner Analysis to Analyze the LoadRunner Performance results.
Ensure sufficient level of stakeholders’ participation in all phases of the Performance Testing life cycle.
Ensured appropriate stakeholders’ signoff is obtained where required on test artifacts and exceptions.

Environment: LoadRunner 11.0/11.5, JMeter 2.8/2.9 HP ALM-PC 11.0/11.52, JIRA, Splunk, Fog light, J2EE, Siebel,.Net, Web Services, TIBCO, Web Services, XML, HTML, ORACLE, WAS, MS IIS Server, Web Sphere, Data Power, F5.

Client: Agro Marketing Group, Lewiston, ME Duration: May 2011 - Jun 2013
Role: Performance Engineer

Responsibilities:

Lead multiple projects/efforts on Multiple Platforms working with On-Shore and Off-Shore leading a Team of 8 Engineers and produce efficient results.
Assisted in exploring of new software as escalated, Produce the hand-off / exit report for application support teams.
Mentor Systems, Architects and other team members.
Provided Subject Matter Expertise in core Performance and Analysis tools like LoadRunner, HP Performance Center, Dynatrace, HP diagnostics and Wily
Maintained cross-business responsibilities by providing end-user support within the company when issues arise.
Frequent interaction with the business to integrate knowledge of the business and Application Performance priorities.
Designed the Performance test environment coordinating with the infrastructure teams and Installed Open source (JMeter), Commercial Tools (LoadRunner) for Performance testing.
Used HP Performance Center 9.52/11.00 to create scenarios and run load tests, HP Load Runner 9.52/11.04 and JMeter for writing Vuser Scripts.
Assisted the team on Scripting using Web HTTP/HTML, .NET Applications, Siebel Web, RTE, SAP GUI, AJAX True Client, AMF, Flex and Citrix ICA protocols for testing different applications.
Assisted the team to use Firebug, HTTP watch and other Developer Tools for efficient scripting.
Developed, maintained, recommended, documented and suggested supports tools and backend utilities to perform performance and capacity planning management
Designed scenarios for Performance Testing, Generating scripts and handling Correlation as well as parameterization using LoadRunner VUGen.
Developed scripts and scenarios for automated testing new and enhanced web based products using Load Runner
Created and coded a very flexible LoadRunner script that allowed for fast configuration changes during testing
Enhanced script by inserting Checkpoints to check if Virtual users are accessing the correct page which they are supposed to be accessing.
Utilized performance/monitoring tools, analyzing results, resolving performance related issues to include optimization and tuning recommendations.
Extensively Monitored Hardware(CPU, Memory, DISK IO, Network IO), Memory (Heap Utilization, Garbage Collection Time Spent, Garbage Collection Minor Collections, Garbage Collection Major Collections)
Extensively Monitored Memory Pools--CMS Old Gen, CMS Perm Gen, Code Cache, PS Eden Space, PS Old Gen, PS Perm Gen, PS Survivor Space, Par Eden Space, Par Survivor Space
Extensively monitored JVM Properties, JVM Startup Options, JVM System Options, Environmental Properties, JMX Metrics, Application EARS, JDBC Connection Pools, Queues, Web Container Runtime- HTTPS or AJP, JVM-Classes, JVM-GC, JVM-Memory, JVM- Threads
Supported performance design patterns, architecture reviews, capacity planning, code profiling, and root cause analysis.
Worked closely with development on the design and implementation of enhancements based on the tuning recommendations.
Validate the code provided by development is efficient and accurately addresses performance issues reported.
Wrote clear and concise performance reports for review with the stakeholders.
Environment: LoadRunner 9.52/11.0/11.04, JMeter, Performance Center 11.00/9.52, QC .Net, Java, Siebel, Web Services, API, XML, HTML, DB2, Oracle, MS SQL Server, DB2, MS IIS Server, WAS 6.0, WAS 7.0.

Client: SunTrust Bank, Dallas, TX Duration: Nov 2009 - May 2011
Role: Performance Engineer

Responsibilities:

Served as a technical expert to IT groups in planning the resource requirements for systems under development.
Presented statistical availability and trend analysis and recommendations to IT management, IT leadership, and the business, as needed.
Served as a technical expert resolving critical and complex application performance issues. Identifying and driving optimization changes in the application design to improve customer experience for mission/business critical IT applications
Identified the testing objectives, planned Load Runner implementation and performed the simulation.
Created LoadRunner scripts to load test high traffic end user processes for performance and reliability.
Developed test scripts in VuGen. Enhanced the scripts by adding checkpoints, functions in C Language, transactions, rendezvous points, created parameters, and performed manual correlation to enhance recorded scripts.
Analyzed Throughput Graph, Hits/Second graph, Transactions per second graph and Rendezvous graphs using LR Analysis tool.
Designed performance test scenarios using HP Performance Center, ran stress tests and analyzed the results.
Conducted load and reliability testing on website’s workflows to identify and report performance bottlenecks.
Extensively developed various scenarios and performed performance and volume tests using Performance Center
Utilized HP Performance Center to synchronize LoadRunner Controller usage among the teammates in order to meet the software testing goals under tight deadlines
Infrastructure Monitoring using SiteScope &Application Monitoring using End User Management & Business Availability Center BAC.
Monitored DB Server Mainly CPU Usage, Memory Usage, Usage, Read/sec, Write/sec, any locking, queries, Average response times, concurrent invocations, Connection Counts, errors per interval, Responses per interval, JDBC-Concurrent Invocations, Oracle Active Connection Count, oracle Waiting for Connection count
Developed various reports and metrics to measure and track testing effort.
Attending weekly defect report meetings and presented progress updates.
Attending conference calls with offshore team to discuss the Testing status and to assign the defects to the concerned developers.

Environment : LoadRunner8.1/9.5, Rational Clear Quest, HP Quality Center, IBM OS version 4690, POS version 6, Java, J2EE, VBScript, Oracle, SQL, Unix, Shell scripting, HTML, WebSphere.

Client: Suven Life Sciences Limited, Hyderabad, India Duration: Nov 2007 - Oct 2009 Role: Performance Tester

Responsibilities:

Involved in the creation of detailed Test plan, Test Scenarios and Test cases according to the business requirements, and updated Requirement Traceability Matrix document to ensure complete coverage.
Created performance testing environment and installed all the necessary components of LoadRunner on all the remote machines.
Performed Non-Functional, Functionality, Security, Cross Browser, Backend, Integration and End to End testing by executing the test cases
Executed Smoke and Sanity testing on the initial received build to check the stability of the application build in Performance testing Environment.
Performed Performance Regression testing on the received build after defect fixes.
Performed load testing against internal applications and services using Load Runner scripts to emulate users and monitor systems performance.
Designed the VU-Gen scripts using Load Runner VU-generator and executed the VU-Scripts in Load Runner Controller in distributed load Generators.
Designed scenarios for Performance Testing, Generating scripts and handling Correlation as well as parameterization using LoadRunner VUGen, executed scenarios using Controller and analyzed the results using LoadRunner Analyzer.
Used Rendezvous point, Start and End Transaction, Parameterization, Correlation features in Virtual User Generator of Load Runner.
Enhanced script by inserting Check points to check if Virtual users are accessing the correct page which they are supposed to be accessing.
Created a scenario with certain amount of VUsers giving Ramp up, Ramp Down and Run time in the Controller of LoadRunner.
Mapped the received test data to the specific test cases for test execution purpose
Performed backend testing using SQL to check if the data mapping and data integrity of the application.
Read and understand the Log files to verify the processes for debugging and/or test data verification purposes.
Identified performance issues, including: deadlock conditions, database connectivity problems and system crashes under load.
Generated the Application Performance reports and reported to the analysis group of Performance testing for fine tuning the application Performance.
Shared design with Stake Holders and worked with Design Architects to ensure changes in design with respect to Performance Impacts.
Identified and reported Performance test defects to the development team by applying Priority and Severity concepts using Quality Center.
Attended the weekly Project Meetings and discussed the issues (Performance test defects) raised according to their priority level in Quality Center.
Documented and communicated test results. Coordinate development, testing and documentation activities with the offshore team.

Environment: HP Business Availability Center(BAC), QC, Win Runner, LoadRunner, IBM Rational, SiteScope, Performance Center, HP J2EE Diagnostic, Windows, IIS 5, JMeter, IBM AIX, SQL, DB2, SQL Server, Oracle, UNIX, Siebel, SOA, API, WebSphere, J2EE.
Contact this candidate