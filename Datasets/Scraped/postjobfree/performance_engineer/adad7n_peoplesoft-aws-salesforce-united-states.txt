Hanumanth Rao
770-***-****
adad7n@r.postjobfree.com

Summary
Manager / Lead / Architect Performance Engineer with experience in Application Performance Engineering and Application Performance Monitoring
Complete knowledge of Performance Engineering and Performance Monitoring like gathering requirements, automating the Business Scenarios, Identifying the Performance Scenarios, Analysis of Results and Presentation of Results.
Experience in integrating DevOps tools with Performance Testing in shift left approach thus by doing early performance testing.
Experienced on different platforms like SAP, PeopleSoft, Vantive, Oracle Applications and Technologies like Microsoft’s .Net, J2EE technologies, service oriented architecture (SOA) on variety of Application Servers like but not limited to WebSphere, Weblogic, NetDynamics, and Databases like Oracle, SQL Server and Sybase and messaging services like MQ Series.
Experience in LoadRunner’s Virtual User Generator Protocols like HTML/ HTTP, Mobile Application, WinSock, Dual Web/Winsock, Web Services, SAPGUI, SAP WEB, RMI, Java, Citrix, Siebel and Multi-protocol scripts.
Experience in using Apache JMeter (HTTP, Beanshell, JDBC, FTP and Java Request Samplers)
Used LoadRunner’s Test Results Analysis for Summary Performance Report, Windows Resources, Network Delay Monitor, Throughput and bits/second.
Designed, Developed and Implemented Test Strategies, Test Plans, Test Designs, Resource Matrix, Job Allocation Matrix, Re-Tracebility Matrix.
Handled off shore and remote teams in India, Brazil, Vietnam and different places with in United States in application development functional and Performance Testing.
Worked using Capability Maturity Model (CMM), Rational Unified Process and IEEE Methodologies. Experience in all Stages of SDLC and QALC.
Proficiency in Automated Test Tools like Rational’s Suit Test Studio, Rational Suite Performance Studio, RequisitePro, Rational ClearQuest, Mercury’s LoadRunner, WinRunner Test Suite, Active Test, Astra Load Test, Quick Test Professional, Test Director, Silk Suite, Visual Test, Visual Performance Test, QA Center from Compuware and RadView’s WebLoad.
Implemented LoadRunner, Quick Test Professional, WinRunner, Test Director, Astra Quick Test, Topaz and Rational SQA Team Test Edition.
Excellent Scripting Knowledge of Rational’s “SQA Basic Language” and Mercury’s “Test script Language”.
Worked in different methodologies like Waterfall, Agile, test driven development and Scrum methodology.
Skills
APE / APM LoadRunner, Quick Test Professional, WinRunner, Test Director, Astra Quick Test, VU Generator, SiteScope, Topaz, CA Wily Interscope, Dynatrace APM/Gomez, NeoLoad, IBM Rational Team Test Edition, IBM Rational Test Manger, IBM Rational RequisitePro, IBM Rational Clear Quest, Clear Case, QA Run 4.6, QA Director, QA Load and Web Performer.
Operating Systems Windows XP, Windows 2000, Windows 2003, Windows NT 4, Windows 3.1, Windows 3.11, Windows 95, Windows 98, DOS, Linux (SUSE and Redhat) & UNIX.
Languages SQL, PL/SQL, Java, XML, HTML, DHTML, C, Visual Basic, Pascal.
Scripting Languages TSL, SQA Basic Language, Java Script, VB Script, Script it and Perl.
DBMS and RDBMS Oracle, DB2, MS SQL Server, Sybase, Access, dBase & FoxPro
ERP SAP (SolMan, WM,FICO, APO,P2S,P2P,OTC,Portal, HCM, SRM, SCM, BW), Oracle E-Business Suite (Order Management, Service Management, AP, AR, GL, FA, T&E) PeopleSoft and Vantive
Tools and Lotus Notes, Sablime, MS Project, VSS, Rational ClearCase, MS Office,
Other Technologies Adobe Photoshop, HomeSite, Vmware

Professional Experience
December 2018
Performance Consultant
T Mobile / TCS.
As a Performance Consultant responsible for T-Mobile Integration, BAU Projects, CI / CD Integration and PTaaS projects using tools like Performance Center, LoadRunner and JMeter
Deployment and maintain performance standards, Design and Development of PE CoE includes but not limited to Development of Questionnaire, Performance Strategy template, Summary Reports and others
Manage performance testing engagement for a size of 15 offshore team of leaders, developers and testers, working on key products for T-Mobile
Maintain vendor relationships resourcing vendors for resume review, resource identification, interviewing and on boarding and further coordination.
Coordinated meetings with various domains team implementing on onboarding the applications for automated and on demand performance testing.
Conduct, Report and Execute project initiation meetings and subsequent status meetings to the Leadership team across domain and technology teams
Plan, design, execute and maintain different types of performance tests like load, stress, endurance, spike, capacity, etc. in coordination with the different divisions
Develop a comprehensive performance testing monitoring strategy to enhance and maximize performance testing value to organization in conjunction with DevOps
Maintain a detailed understanding of system component interaction and data relationships to effectively build and execute tests and analyze results
Effectively Build and Design Performance Testing work load metrics to reflect the real time business scenarios, capturing key performance metrics such as CPU, Memory, Disk IO and others
Effectively used continuous integration and continuous deployment (ci/cd) for faster deployment of code for testing and for production, by using tools like Jenkins, gitlab and bitbucket
Implementation of ELK for early automated performance testing and creation of dashboards for performance metrics reporting

July 2017
Lead SDET (Performance) Consultant
Exactuals Inc.
As a lead performance SDET Consultant responsible for Performance for Residual Payment project includes AWS, Web Technologies, Salesforce and other Applications
Written Performance Test plans based on the interviews conducted with the Product, Project and implementation teams.
Propose automation strategy, ROI and implement automation tools for web application, Web service/API
Evaluate test automation tools, establish selection criteria and drive POC implementation
Work with engineering teams on deployment of automation into CI/CD pipeline for shift-left testing vision
Written Java utilities for S3 up-loader tool to simulate payroll files sent by various clients into AWS S3 bucket on eclipse platform.
Coordinated with Product team to Identify and prioritize the Business Process to be Performance Tested
Implemented and Developed JMeter performance testing scenarios for file upload and Web User Interface transactions using Java Request, Beanshell and HTTP samplers
Defined JMeter Test Plans, Thread Group, Samplers, Listener (Results and Graphs) to simulate the real-time business scenario and gather results.
Created Jenkins jobs to perform the automated performance testing (uploading the files – java, UI – validation using JMeter HTTP samplers)
Design and run extensive volume, scalability, stability, load, peak and stress tests using JMeter

February 2015 to December2017
Sr. Performance Engineering Consultant
Cox Automotive Inc.
Design detailed performance test plans, scenarios, scripts, or test harness for Cox Automotive, Inc for Gavel to Gate project includes Oracle Applications, Salesforce, Mobile and other Native Applications.
Implemented, developed and executed automated performance test harness using tools like HP LoadRunner (HTTP & Web Services) and JMeter (Beanshell, JDBC Request and Java Request Samplers).
Collaborate with Developers / Architects on system impacts of the downstream and upstream Application while doing performance testing.
Design and run extensive volume, scalability, stability, load, peak and stress tests using HP LoadRunner.
Develop robust benchmark workloads based on production traffic patterns and anticipated feature usage with varying load levels.
Created scenarios to simulate the real time business scenarios for performance testing of the applications.
Gathered slow performing methods, SQL’s during performance testing using Dynatrace Application Monitoring in all layers of the Application Under Test.
Evaluation of Performance results by gathering core operating system metrics and comparing them with previous releases for trend analysis.
Preparation of Performance Summary report (Suggestions, Comments, Conclusions and Recommendations).
Developed monitoring scripts using Dynatrace (Compuware) Gomez for multi browser, multi locations and multi devices for synthetic monitoring.
Extensively used vSphere to gather and evaluate VMware performance metrics of inventory of VM hosts covering all layers of the applications.
Evaluated mobile performance testing tools (HP LoadRunner, JMeter and Neoload), presented the PoC to the senior management.

July 2012 to January 2015
Sr Performance Engineering Manager / Tata Consultancy Services
PSCU Financial Services, St. Pete, FL / State Farm / Cummins
Serve functionally as, Sr Performance Engineering Consultant developing Performance test strategy, Performance test planning, Performance test framework, and performance Engineering.
Responsible for Statement of work creation, renewal, identification of deliverables, timelines, project planning, budgeting, control, documenting and deliver entire testing process.
Worked with different performance testing tool vendors like IBM (Rational), HP (Performance Center / LoadRunner, CA (Interscope), Dynatrace APM / Gomez and Neotys (Neoload) for purchase and support agreements of the tools.
Conduct both internal and stakeholders Weekly, Monthly and quarterly status reports including Key accomplishments, coming activities, project milestones and Issues / Concerns and Support requirements.
Partner with senior technology leadership, including C-Level Executives and Directors to define long-term testing objectives, negotiate and plan project financials and resource planning mitigating risks.
Instrumental member of PMO enabling strategic planning and execution of critical initiatives focused on technology enhancements, project implementation, adoption, budgeting and scheduling.
Managed customer escalations effectively by providing sufficient and necessary strategies towards successful project implementation.
Comfortably planned budgeted, recruited resource, training and allocation of resources and executed several upgrade projects.
Successfully conducted Performance Testing / Engineering at multiple locations with direct reporters across on site / off shore and near shore.
Responsible for performance certification using which includes performing Load tests, Stress tests, Capacity Planning, Stability tests and Scalability testing. Application Performance Monitoring and diagnose of both test and production environment.
Train and Mentor the junior performance test engineers on VUGen scripting and creating scenarios.
Coordinated with Technical Teams to Setup Heart (Database Query, CPU Utilization, Memory and URL)
Coordinated with Functional Teams to Identify and prioritize the Business Process to be Performance Tested
Recorded and customized Virtual User Generator scripts. Performed manual correlation, parameterization, runtime settings adjustments, recording settings adjustments.
Creation of data using VUGen, data creation includes application data set up, flat files and csv files.
Created scenarios to simulate the real time business scenarios for performance testing of the applications. Added load generators
Evaluation of Performance results by gathering core operating system and comparing them with tests results.
Preparation of Performance Summary report (Suggestions, Comments, Conclusions and Recommendations)

January 2011 to Jul 2012
SAP Performance Engineer
Newell Rubbermaid, Atlanta, GA.
As SAP Test Engineer consultant to Newell Rubbermaid, I am responsible for:
Interviewed the Business Group and Gathered performance requirements and documented the requirements in the HP Quality Center.
Based on the Business Requirements developed Performance Test plan, Performance testing scenarios developed parameters like think time Ramp up scenarios and Scenarios Run Times, number of dialog steps in SAP.
Extensively developed Automated Performance Testing Scripts in SAP ECC and Portal Environment using VUGen SAP GUI and SAP Web protocols.
Developed end-to-end Performance Test Scenarios (using VUgen) for OTC, WM, FICO, APO, P2P, P2S SCM, SRM and HCM Modules
Developed Performance Scenarios for various SAP Interfaces like OTM (Oracle Transport Management) Application and PKMS.
Extensively worked on creating data creation for end-to-end Business Scenarios for Performance Testing.
Gathered the Performance Results and analyzed the results and presented the results to the management.
Developed customized test harness for error handling, logical data input and Output messages.
Worked with Process Teams to create Solution Manager TPR creation documentation.

August 2010 to September 2011
SAP Performance Test Engineer
IBM, Evansville, IN.
As SAP Performance Test Engineer consultant to IBM, I am responsible for:
Collecting performance requirements, documenting Performance Test plan, design performance testing scenarios on the SAP and IWP.
Install HP LoadRunner and Virtual User Generator on the desktops, Install sitescope, configure sitescope.
Develop Test harness in VUGen, customize the test scripts for correlation, paramatization and setting up run time settings.
Coordinated efforts with Application Owner and Basis Team to communicate the bottlenecks and fine tune the application.
Executed Performance Testing across the different continents to get the Response times for different MJN Locations.
Worked with Vendor teams to identify the bottlenecks and performed regression testing to achieve the pre spin off results.
Quality Center is used for Test Management activities like Test Requirements, Test Design Steps and Defect Management.

January 2010 to July
Performance Test Lead
Bank of America, Charlotte, NC.
As Test Lead at Bank of America, I am responsible for:
Managed resources and process of performance testing (like Load, Stress, Volume, Endurance and Failover) using LoadRunner (Controller, Virtual User Generator, Analysis) and Protocols used Web, Web Services
Have lead whole TST applications in the retail banking space which includes IPD, RCK, ULZ, ACH DE and RDSO applications. The applications are developed in Java, WebSpehere on DB2 Database with SOA.
Managed near-shore and off-shore team to develop test harness, execute performance scenarios during nights and weekends and report generation.
Presented results of the performance testing along with Project Management team to the clients mainly senior management.
Also involved with project management team to schedule the testing activities for the TST space and resource allocation.
Designed Test Case documents for Performance testing in Quality Center and report defects.
August 2009 to December 2009
Lead SAP Performance Test Engineer
Pepsi, Plano Tx.
As SAP Performance Test Engineer at PBSG, I am responsible for:
Responsible for performance testing (Load, Stress and Volume) using LoadRunner (Controller, Virtual User Generator, Analysis) on SAP Applications (Server Testing).
Coordinated with Process owners to Identify the Business Process to be Performance Tested and perform functional UAT
Developed Test Requirements documents for Performance testing in Quality Center. Defects logged and tracked in Quality Center.
Developed VUGen scripts in SAP GUI for ECC and SAP Web, paramatization, correlation, error handling, and output messages.

May 2008 to August 2009
PeopleSoft Performance Test Engineer
State Accounting Office, State of Georgia Atlanta GA
As PeopleSoft Performance Test Engineer at SAO of State of Georgia, I am responsible for:
Responsible for performance testing (Load, Stress and Volume) using LoadRunner (Controller, Virtual User Generator, Analysis)
Installation and Setup of Performance Center and Multi LoadRunner Agents
SiteScope Installation and Set up (classic) includes creating Groups and Monitors for UNIX, Tuxedo, Weblogic and Oracle Database
Coordinated with Technical Teams to Setup Heart (Database Query, CPU Utilization, Memory and URL)
Coordinated with Functional Teams to Identify the Business Process to be Performance Tested
Performed Performance Testing PeopleSoft Human Capitol Management and Financials Modules from migrating from 8.8 to 9.0
Train and Mentor the Full time Loadrunner Staff on Scripting and creating scenarios.
Designed Test Case documents for Performance testing in Quality Center.

January 2007 to April 2008 QA Performance Lead
Witness Systems Roswell GA
As QA Performance Lead at Witness Systems, I am responsible for:
Load, Stress, sizing, scalability and capacity planning of different Witness Systems products which are client server products involved lot of Server testing.
Evaluated Performance Testing Tools from IBM Rational and HP Mercury Suite
Implemented LoadRunner 8.1 and got the licenses from Mercury Interactive
Designed and Implemented Performance Testing Plan for QM, eReporting, OEM's (BT, Avaya), Balance, and WFO.
Developed test harness using Virtual User Generator in Single and Multi protocols (HTTP/HTML, RMI, Web Services, Citrix, Dual Web/Winsock and Windows Sockets).
Monitor performance using windows performance monitors and LoadRunner monitors.
Setting up testing environment of various Applications from various builds to do performance testing (includes installation of operating systems, raid architecture using hp tools, installing applications from the suite and installing multi databases like MS SQL and Oracle).
Analyzed Test using Summary Analysis, Average Transaction Response Time, Throughput, Windows Resource, Network delay and HTTP Codes
Extensively used J2EE Diagnostics/Deep Diagnostics to diagnose and troubleshoot Web/App server performance issues
Used VMware to create virtual machines to run different consoles for screen capture

September 2006 to January 2007 Performance Test Engineer
ADP Roswell GA
As Performance Test Engineer at ADP, I am responsible for:
Written Performance Test Plan and Test Case design document with the inputs from developers and functional testers.
Extensively used LoadRunner using Virtual User Generator to script and customize performance test harness using Web Protocol. Extensively used Controller to generate load and define load generators. Test Results are used to report summary reports, response times and monitors averages.
Dealt with business team to get the performance requirements for the Load Testing, Stress Testing and Capacity Planning.
Extensively used SUSE Linux to change the database connections, monitor resources of the machines.
Written Summary Performance Report (includes details about load, stress and capacity planning).
Extensively used features like paramatazation, correlation and configured monitors for WebSphere, MQ Series and Database.

February 2005 to August 2006
Prolific Technologies, Inc. Alpharetta GA
As QA Performance Lead at Prolific Technologies, Inc., I am responsible for:
Design and Implementation of Performance Testing.
Evaluated Performance Testing Tools based on implementing the product and/or its suite, accuracy of the product, inputs required for performance testing, data captured from the server, the presentation of the data and its usefulness to fine tune the application or applications.
Writing Test Strategies, Performance Test Plans, Test Harness, Test Implementation Plan, Test case Design Documents and Test Summary Reports.
Implemented LoadRunner and Performance Testing SAP SD, MM and CRM Modules.
Created Test Harness using SAPGUI / Web protocols in Virtual User Generator
Changed LoadRunner Agent from service mode to process mode.
Updated SAP Patches to capture the Virtual User Generator test harness.
Coordinated with Technical Teams to Setup Monitors for Database, Application server and captured CPU Utilization and Memory
Coordinated with Functional Teams to Identify the Business Transactions to be Performance Tested in terms of frequency of usage and the number of concurrent users.
Configured Scenarios for ramp-up configured SAPGUI Run-Time Settings Configured Parameters List.
Generated Results Using Loadrunner Analysis.
Developed Performance scripts for Siebel CRM, Sales and HelpDesk.

October 2003 to January 2005 QA Lead
Ernst & Young LLC, Atlanta GA
As QA Lead at Ernst & Young, I am responsible for:
Writing Test Strategies, Functionality Test Plan, Performance Test Plans, Test case Design Documents and Test Summary Reports with RUP methodology.
Designed strategies to let the Users know about the project status and project completion online and 3 tier status calls.
Developed Test Case Design Document Template and Test Case Execution Status Documents.
Developed sample Automated Test scripts for Functionality Testing and Performance Test Testing to present the customer.
Developed Release Plans, Code Review Documents and Resource Usability Matrix.
Reviewed the Resumes, Interviewed and got resources on board. Resource Allocation amongst different Projects.
Coordinated with the development team for build releases and testing the AUT.
Responsible for the complete testing of the application (functional and performance) and User Acceptance Testing (UAT).
Implemented IBM’s Rational’s RequisitePro, ClearQuest, Team Test Edition (Performance Studio, Test Manager and Robot), LoadRunner, WinRunner, Quick Test Professional, TestDirector Professional and the database on Oracle 8.16 on Unix Operating System.

July 2003 to September 2003
Performance Test Engineer
UPS, Alpharetta GA
As Performance Test Engineer at UPS I am responsible for:
Writing Test Strategies, Performance Test Plans, Test Harness, Test Implementation Plan, Test case Design Documents and Test Summary Reports.
Implemented LoadRunner and Performance Tested PeopleSoft CRM Application Vantive sitting on DB2 Database.
Excellent knowledge and experience in logistics, operating networks and warehouse management such as slotting, allocation, picking, packing, shipping, returns, and receipts.
Developed Performance Scenarios for PeopleSoft CRM Application (Migrating from Vantive to PeopleSoft
Mentoring and providing direction to co-workers
Responsible for Performance Testing at HP Cupertino (Test Center).
June 2001 to July 2003 QA Lead
Hewlett Packard, Atlanta GA
As QA Lead at Hewlett Packard (Media and Communications) Consulting I am responsible for:
Writing Test Strategies, Functionality Test Plan, Performance Test Plans, Test case Design Documents and Test Summary Reports with RUP methodology.
Writing Project Plan, developed project schedule using MS project
Designed the Customization of Rational DDTS, ClearQuest to track the effort of on individual tasks of the consultants.
Developed sample Automated Test scripts for Functionality Testing and Performance Test Testing to present the customer.
Developed Release Plans, Code Review Documents and Resource Usability Matrix.
Regression Testing is performed using Rational Robot and Performance Testing is done using LoadRunner 7.02 and ClearQuest is used to document the Defects.
Used Rational RequisitePro for documenting and updating the Requirements.
Installing Applications, Databases (Oracle 8.16 and 8.17), creating instances, administering Web Servers and Databases for testing purpose.
Implemented Rational’s RequisitePro, ClearQuest, Team Test Edition (Performance Studio, Test Manager and Robot), LoadRunner, WinRunner, Quick Test Professional, TestDirector Professional, Empirix' eManager Enterprise, eLoad, eTester, and the database on Oracle 8.16 on Unix Operating System.
Evaluated Performance Testing Tools based on implementing the product and/or its suite, accuracy of the product, inputs required for performance testing, data captured from the server, the presentation of the data and its usefulness to fine tune the application or applications.

Nov 2000 to May 2001 Automated Test Lead
Schlumberger Austin, TX
As an Automated Tester at Schlumberger I am responsible for:
Developed and Designed Project Planning, Test Plans. Test Design Documents and Test Summary Reports for knowledge based system being developed using JAVA, XML, DHTML, Cold fusion, Spectra, Actuate and Oracle 8I technologies.
Developed Project Plans, Status Reports, Test Execution Presentations and monitored the Test Scripts Development.
Implemented LoadRunner (Virtual User Generator and Test Result Analysis).
Involved in the generation of functional, Volume, Stress and Load Test scripts using Automated Test Tools.
Involved with Tech leads in-migrating the Applications database migration, Dropping the Code and upgrading the versions of the Applications.
Used Astra Quick Test 6.02 to identify the missing links for the web-based Applications and develop Test Scripts for Testing Web-based Applications.
Developed Scenarios to do Performance Testing of Databases on Solaris based Servers from hosts like Windows NT 4, Application Servers on Windows NT and the Web Server on Windows NT.
Developed Automated Test Scripts for Web Monitoring Using Topaz and Virtual User Generator.
Developed Manual and Automated Test Scripts for White Box Testing in JAVA, XML, JDBC and JavaScript.

May 1999 to Oct 2000 Test Lead
AT&T, Greensboro, NC
As a Performance Tester at AT&T HRISO (IWS) I am responsible for:
In AT&T all the HRISO (IWS) applications are developed using Java, Net Dynamics, PeopleSoft HRMS running on Windows Environment and Oracle Database and running on Unix environment.
Involved in the Design of Test Plans, Test Design, Test Case Matrix and Test Summary Reports.
Involved with Tech leads in-migrating the Applications, database migration, Domain Name change and Redirection of Domain Name.
Involved in Project Planning, Test Scheduling, Test Execution Monitoring, Performance Test Summary meetings and Walk-Through meetings.
Monitored Co-Workers on Testing Approaches, Technical Aspects of the Test Tools like Paramatizing the variables, writing loops and Data validation while Test execution.
Involved in the generation of functional Test scripts using Automated Test Tools like Astra Quick Test, WinRunner and VU Generator and Manual Test Cases.
Developed Test Scripts for Performance Testing of Various Releases using VUGenerator and LoadRunner 5 and 6.
Involved in the Test Scripts generation to test the Migration of PeopleSoft Applications from 2 – Tier to 3 – Tier.
Involved in Database Performance testing of 30 GB Hard Disk (roughly 100, 000 records) sitting on NCR4100 UNIX Server for every release
Involved Performance Testing and Regression Testing PeopleSoft Upgrades 7.11 to 7.5 and 7.53 to 8
Performed Data Validation, Data Redundancy tests for the Data generated from SQR Reports and dynamically comparing the values generated from the Database using SQL.
Developed Scenarios to do Performance Testing of UNIX based Servers like NCR4100 UNIX Server from hosts like Windows NT 4.
Bug-tracking and Generating of MR (Modification Requests). Extensively Used Rational ClearQuest for Documenting the Projects.

Feb 1999 to May 1999 QA Lead
CITIBANK, Wall Street, NY
CTC (Corporate and Workgroup Solutions)
As a QA lead in NY office I am responsible for the migration of entire QA department from Dallas to New York.
Setting up of QA department in New York office. Implemented Rational Robot and Clear Quest.
Estimating the necessary Resource required for CTC New York using CRS (Client Requisition Service) from COSL Bombay for the next two years.
Conducting Interviews and Recruiting manpower. Delegation of Tasks to the available Resources.
Developing sub-divisions like system testing, performance testing and Unit testing.
Developed new Testing Strategies to accomplish Y2K compliance, Performance Testing and System Testing.
Implemented Mercury’s LoadRunner and developed and executed LoadRunner Test Harness and Scenarios.
Involved with Development leads in migrating the Applications, database migration, Domain Name change and Redirection of Domain Name
Involved in testing the migration of the majority of Applications from NCR4100 UNIX Server to Windows NT 4.
Also migrated the Applications developed by Lotus Notes using Domino server, N pump, DB2 to Oracle 7.322 and Net dynamics.
Used Astra Site Test to identify the missing links for the web-based Applications. Used WebPerformance Trainer for testing the Performance of the Web Server.
Used Clear Quest for tracking the Bugs. Used PVCS to track the Test Scripts Versions. Used Clear Case to maintain the versions of the Test scripts, Software versions.
Used Test Manger to write Test Plans, Test Tree and Created and implemented various responsibilities.
Used MS Project 98 to manage the Schedule deliverables.

Nov 1998 to Feb 1999 Test Analyst
Citibank Wall Street, NY
Working as Test Analyst at Citibank, NA New York for an in-house Project called GECD (Global Electronic Customer Delivery). GECD facilitates its Commercial Customers to perform bank operations from their desk at various locations across the globe. GECD consists of 23 Applications like Cash Management, Trade, Securities. am involved with platform group of Applications like Report Viewer, Report Designer, Communications Manager.

My Responsibilities include:
Responsible for Developing Test Plans, Developed Manual Test Scripts and Test Cases
Responsible for Migration Test Script development and deployment
Responsible for Install Shield Test script development
Test Y2K compliance for various applications
Testing the Communications Manager Using Modem by requesting the Messages on GID Global Interface Device which is located at Delaware
Developed Strategies (
Contact this candidate