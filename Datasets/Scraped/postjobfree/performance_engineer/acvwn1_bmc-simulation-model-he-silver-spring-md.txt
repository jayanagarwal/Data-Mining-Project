My experience has included both the private sector and federal government environments for 25 years. Simulation, benchmarks, mathematical modeling, capacity planning, performance analysis, and technical evaluations have spanned multiple hardware and software configurations. Recent projects have included project management, software and hardware systems modeling (including queuing analysis, simulation, and statistical techniques), and configuration management. Technical writing and verbal communications skills have been developed and refined over a challenging academic and professional career to guarantee clarity. Diverse technologies and approaches have been implemented to insure flexible, coherent, and disciplined outcomes. Mathematical and statistical approaches have played a pivotal role in a results oriented method of operation. My e-mail contact is acvwn1@r.postjobfree.com .

EDUCATION:
Enrolled in MIS and Project Management, George Washington University, Washington, DC, Sept-May 1997
MS, Mathematical Sciences/Operations Research, Rice University, Houston, Texas,
MS, Pure Mathematics, Texas Southern University, Houston, Texas,
BA, Economics/Mathematics, Texas Southern University, Houston, Texas.

ARTICLES WRITTEN:
"Capacity Planning, Performance Analysis, and Sample Size Determination" during 1990. Published Tandem International Users Group Journal
“Performance and Capacity Management for Client/Server Systems”, 1999, Published AMS Best Practices
“Performance Modeling and Simulation” 1999, Delivered at The European Technical Architects Conference, Malta, Published AMS Working Paper.
“Performance Monitors” 1999, Published AMSCAT Working Papers
“Comparing Mathematical Modeling and Event-Driven Simulation Strategies NetRule and SES/Strategizer”, 1999, Published AMSCAT Working Paper“
“Determining the Appropriate Clock and Simulation Times for Simulations”, 2000, Published AMS Technical Paper”
“Capacity Planning and Performance Assessment for Siebel Systems”, 2000, Technical Paper, AMS Technical Paper
“WAP Performance Assessment Using Segue’s SilkPerformer Software”, 2000, Technical Paper, Published AMS Technical Paper.

EXPERIENCE:a
1/2009 - Present Montgomery Community College, Takoma Park, MD. Mathematics Teacher.

11/2015 – 1/2016 Tek- Systems Capacity Planning Consultant As a Consultant in Alexandria Va. Studies were conducted and approaches analyzed that were developed by contractors and the Veterans Administration on possible increased demand because of changes in FileMan, a staple in VA’s processing.

10/2010 – 1/2012 Booz Allen & Hamilton, Hanover, MD Associate, Operations Research, Modeling and Simulation and Statistics. Conducted studies in all of the above areas for government agencies such as Homeland Security, Defense Department and other agencies. Mr. Keith worked on the development of a Modeling methodology for performance assessments using simulation modeling, analytical modeling, and statistical approaches for telecommunications, systems, and services. He also worked on the development of an expanded toolset for these types of studies. He assisted in developing a modeling and simulation laboratory. He developed, designed, and lead the technical tasks to process application activity and data modeling, transaction flow analysis, traffic models, and workload statistical analysis. He developed queuing models as threshold indicators for simulation models using OPNET products. He developed clustering models, verification and validation processes for the purpose of identifying and quantifying risk and using confidence analysis. He developed internal controls and risk analysis by implementing crucial aspects of ITILv3 and performance measurement techniques. He developed a series of transaction, traffic, and simulation models to examine various queuing algorithms on cross domain solutions. These solutions would provide better than expected performance for cross domain servers. Cross domain servers were considered to be of utmost importance.

4/2010 – 9/2010 NCS/Evolver, Greenbelt Maryland, Data Analyst. I was conducting statistical studies regarding The Bureau of Census information. The approaches use statistical analysis regarding accuracy and processing speed of forms, human beings, fields, processing centers, and other areas on an ad-hoc and regular basis. Savings exceeded one billion dollars, accuracy increased higher than at any other time, and the project finished before the due date.

12/2009 – 4/2010 General Dynamics Information Systems, Fairfax VA., Principal Statistician. I worked on the Army Online Project
Reviewed contract requirements for Availability and Performance Service level Agreements with recommendations for measurable metrics that characterizing and supporting the validation, verification of the contract AESD requirements for both AQL and target AQL. There were 21 requirements, critical success factors, and their associated performance levels
Developed a list of metrics needed to support the fulfillment of the availability and performance requirements in the contract. Cisco recommendations were used as a baseline. Produced the statistics needed to satisfy all requirements. There were well over 250 requirements, sources were also produced for validation.
Produced a summary and evaluation of all of the CA, BMC, and MITRE metrics received from theses sources for evaluation.
Researched the Corpus Christie data for statistical soundness and substance regarding service desk statistics for the transition of site operations and workloads
Developed a description of what dashboards should be able to do, how they can be used and why they are important and how they can be mapped to statistical modeling
Developed a study on the tools needed to support dashboards from a statistical, modeling and data visualization context. I included tools that can provide the ability to encompass forecasting and trending. -
Developed a method and example of implementing Six Sigma into the statistical evaluation of performance, availability and statistical soundness so that the results are used to present the information in a manageable context.
Developed a method of summarizing the availability and performance of the service desk enterprise information into various data categories, performance indicators that provided value to management and presented their charts and information into Quads
Developed a statistical presentation on trending including linear and non-linear regression, multiple regression, confidence intervals, visual tests, LR boxes, Estimation Theory, Categorical Predictors, Standard Deviation of Errors, Curvilear Models, Transformation Models, Mistakes to Avoid, tests for linear correlation, means, median, control limits, range limits, averages, standard deviations, variances, statistical inference, hypothesis testing, reliability, non-linear to linear transformations by using logarithms, dashboard metrics, algorithms for each entity and Deming Tests. All of these capabilities could be tied into the tools that are needed and requested. It was entitled Conduct Incident Trending Analysis
Produced a methodology for model design, development and evaluation for statistical and mathematical models.
Studied ITIL concepts and documentation provided and became ITIL Certified
Developed a presentation for the statistical, mathematical, and graphics tools needed, comparing those to other vendors, with price information while presenting the capabilities associated with the functionality of these tools. There were two versions.

3/2009 – 9/2009 OPNET Technologies, Bethesda MD. Senior Applications and Network Engineer. I worked in the area of Professional Services. I have been working with VNEServer, Network Transport, ACE, SP Guru Network Planner, SP Sentinel, and IP Guru.

9/2007-2/2009 Noblis, Falls Church, Virginia, Principal I worked with The Defense Information Systems Agency (DISA) and TSA contracts. The projects that I have worked one are as follows:
Assisted DHS regarding acquisitions, and procurements as staff support
Assisted the Navy and Marine Corps in developing suggested designs for networks for surface ships and various land based facilities.
Developed a study analyzing random number generators for developing seeds for simulation modeling in OPNET.
Developed a study on the advantages and disadvantages regarding truncation versus replication deletion methods for analyzing simulation results in OPNET.
Conducted meetings, interviews and distributed questionnaires to users and management to clearly determine and assist in forming performance requirements and targeted capabilities for the profiling the intended application end-user experiences. This included audio, video, and text messaging workloads.
Developed an analytical queuing model regarding estimating response times, queue lengths, queuing delays, and other useful performance indicators for modeling the NCES's Sametime application.
Developed a series of models to investigate the best method to generate background traffic for simulation runs for the Sametime Application. Four strategies were investigated: (1) Discrete event. (2) Application flows. (3) IP flows and (4) manually generated background utilizations.
Developed an OPNET model to determine the best method for generating background traffic for simulation runs. The four workloads included Web Traffic, e-mail, audio, video, and FTP traffic for: JTF, Conus, and Oconus models for various latencies, and packet loss.
All differences to the “ideal” throughput and utilization targets were under 1.88%. Spreadsheets were provided on model details and outputs
Researched scalar output information in OPNET for Validation
Background traffic models were developed for DISN Conus and Oconus models
oTarget utilization and throughput conformance for e-mail traffic, web-traffic, UDP, and FTP to the “ideal” throughput and utilization targets were better than 98.13%. The “ideal” targets were 95%.
oSpreadsheets were provided on model details and outputs
oResearched scalar output information in OPNET for validation purposes

11/2005 – 9/2007 Scientific Applications International Corporation, Dumfries Virginia Applied Mathematician/Sr. Operations Research Analyst: I have also worked with The Marine Corp regarding improving their Close Air Support and Ground Fires for war-fighters. Some of the areas worked on a day to day basis are:

DoDAF Architectural development of the Close Air Support Joint Operations and Fires Architecture,
Modeling and simulation studies,
Planning extensive WBS Planning and Development for a large modeling and simulation project for MAGTF C2,
Configuration Management Plan Development Strategic Planning for MAGTF C2 Spiral 0, as well as managing projects involving the development of DoDAF Enterprise Products.
Developed a model and paper providing MAGTF Fires with improved accuracy within 10 meters for a Target Location Error.
Developed profiles of future MAGTF Spirals 0 through 3 regarding the Technology Investment Strategies which can improve various categories of Marine Programs
Developed a strategy to use DoDAF Architectures in modeling and simulation efforts for analyzing and providing and quantitative and qualitative studies on integrating, assessing the impact of SOA networks, improved fires processing and delivery of munitions for MAGTF C2.
Determined by extensive research and interviews with The Marine Corp’s warfighters at Quantico Virginia what requirements and capabilities were necessary and sufficient to convert into viable Enterprise Architecture and Target Location Models to describe the Call for Fire Process.

4/2005 –11/2005 Scientific Applications International Corporation, Arlington Virginia, Lead Systems Engineer
My duties to date have included conducting performance and capacity planning studies on the DOD’s Clinical Health System which spans all of the DOD’s personnel. This includes the Army, Air Force, and Navy. The primary central processing machine is a HP Superdome with 128 processors and a performance database that is in excess of a terabyte of data. This included performance and capacity planning requirements determination relevant to all veterans both active and inactive as well as their families.

6/2004 –4/2005 MITRE Corporation, McLean, VA, Lead Information Systems Engineer
My duties have included supporting efforts by W906 regarding performance studies for applications, networks, and processes. I have worked primarily on Army Architecture Integration Cell, Army Knowledge Online Forward, and Joint Tactical Radio System projects.

Assisted in developing load testing use-cases for the AKO Forward project for the purpose of evaluating response time samples. These samples were used to provide inferences regarding the differences in response times for designated use cases regarding transactions being issued from the North American continent as opposed to locations in Europe.
Assisted AAIC in the development of a model to help estimate response times and throughput capacity regarding specific links and circuits for the Army. Further studies involved learning about how to build architectures using architecture COTS products.
Introduced vendors in the area of queuing theory modeling that are being currently considered for tools for future endeavors.
Simulated and model a number of Army Systems that I can not provide details
Member of Psig, an organization that explores and studies various performance factors, concepts and alternatives in the area of performance engineering, capacity, planning and simulation.
Attended classes for NetRule, a queuing modeling tool for networks, systems, and applications. Attended classes in queuing analysis provided for by professor Menasce.
Determined through interviews with current and prospective users of AKO Forward Project what were their performance and capacity planning requirements relative to response times and throughput rates for OCONUS and CONUS Access.

1/2001-6/2004 BearingPoint Federal Group, Landover, MD, Senior Consultant, Network Applications and Systems Performance Specialist
My duties have included supporting the Federal Services Sector of KPMG Consulting. This support includes the performance and capacity planning for the IRS’s ATM WAN and various applications and systems. I used strategies such as simulation and modeling as well as determining the bandwidth allocation and estimated utilization of the IRS’s service and computing centers.

Developed a study that help characterize the IRS’s bandwidth allocation and estimated utilization for their ATM network for nine service centers and three computing centers. This was used to reallocate bandwidth requirements and increase reserve bandwidth resources.
Developed a model for the Defense Logistics Supply Agency’s planned data warehouse based upon sampled morning batch performance information. The model was within 1.5% of the measured sample data. The process included providing estimated performance requirements based upon a similar enterprise used as a basis for this study. Recommendations were presented for sizing the HP Superdome (32 and 64 processors) and 200 disks. The software used to build the model was SPE-ED. The data was collected with BMC software.
Developed a network model for the IRS’s VLAN for the purpose of determining the impact on a reduction in PVC’s bandwidth allocation and various performance indicators for the distributive layer of the network. The model enabled the reduction by 50% resulting in substantial cost savings, but not a reduction in QOS.
Provided a study on network modeling performance software that included all distributive tiers for the Detroit Computing Center, Tennessee Computing Center, and The Martinsburg Computing Center. The study was used to purchase network monitoring and capacity planning software NetVantage form Compuware. Probes, servers, and taps were purchased and scheduled for deployment. This was based upon a solid base of distilled requirements extracted for system, network, and applications needs.
o Developed a methodology and strategy for application performance assessments and the application’s impact on network and system resources. This methodology included requirements determination and provisions for determining the most significant in a checklist for any system or network.
o Developed an approach for determining the performance bottleneck for a large asset center system using Peregrine, Oracle, web-servers, BMC software, NT and UNIX systems. Load and stress testing were the strategies that best fit the problem and the goals and objectives.
Provided new technology introductions the form of demonstrations by at least four vendors that are specialists in application response time monitoring, application centric simulation, and monitoring.
Developed network models for Enterprise System Management application and its impact on local area network as well as the ATM backbone network. Performance factors such as response times and expected utilizations were extracted from OPNET, while queuing modeling techniques were developed for the assessment of various switches, links, and routers. This included working with project’s chief engineer and chosen users to determine throughput and network bandwidth requirements.
Assisted in the development of an e-services BMC Patrol model that estimated the performance indicators such as system residence time, utilization and other factors by the means of monitoring and analytical modeling.
Developed models for e-services and various primary threads and scenarios for release 1.2 and 1.1. These models were developed in SPE-ED, an analytic and simulation modeling package.
Assisted in developing models for the Modernized e-File application. These models were to be used to help determine if there were any outstanding performance problems. The team was responsible for determining all performance requirements and concentrating them in a mathematically rigorous and statistically sound model.
Attended OPNET University course on simulation and the modeling of networks.
Developed a model for the purpose of determining four large application’s impact on the IRS’s Detroit Computing Center’s LANs and data communications infrastructure.
Served as the IPT for the e-services project providing estimates for expected e-services traffic for 2002 and 2004. Two approaches were used analytical and simulation modeling.
Developed an application workload profile of the e-services system used to process electronic information for the IRS. BMC software was used to model the background traffic as well as analytical modeling predictions.
Assisted in the performance assessment of the IFS application and the development of a model. Monitoring, collection and prediction for an analytical based model was based on BMC software.
Assisting in the development of a model and the NRP “Roadshow” for enhancing Business Development

1/99 – 1/2001 American Management Systems, Fairfax, VA, Principal Technologist, Simulation and Modeling Specialist/Applied Mathematics
My duties and responsibilities included providing consulting, advice, and expertise in the areas of, performance load-testing, simulation, analytical modeling, benchmarking, and measurement for computer and communications systems performance assessment. Strategies and techniques include statistical analysis, queuing theory, numerical methods, and probability areas in Applied and Computational Mathematics.

o Developed a large and complex simulation model to simulate the Hughes Spaceway System with Hyperformix modeling software in Perl. This model was a parallel host system that shared one database that incorporated a fault-tolerant method of operation. The model enabled Hughes Communications Systems to build the system (software and hardware) with confidence once the model was developed with findings recommendations, and two versions of host configurations. As an outcome Hughes not only found the model extremely useful, they bought the package used to develop the model. Performance requirements were developed by interviewing extensively Hughes users and engineers as well as database support personnel.

o Provided leadership, advice, and development in building a large simulation model to simulate the North Carolina Blue Cross and Blue Shield communications, computer and insurance application system for providing insurance information for physicians and other hospital personnel. The Hyperformix simulation helped to point out severe bottlenecks that resulted in a national vendor completely rewriting their COTS product.

Built three load and stress testing models with Segue’s SilkPerformer product. The first was for the ACAPS organization that involved Smalltalk and RMI protocols. The next involved The CACS organization’s release software that required not only performance assessment tools such as SilkPerformer, NTs Performance Monitor, and other Microsoft Products, but a queuing analysis and statistical models to calculated forecasts for projected demand and its impact on the selected host. The third project was a project for the Los Angeles Unified School District the largest in the country. It needs to build a software system and hardware configuration that will be used to host a large Web-based application that is being developed by AMS. I have been tasked to help them generate a task approach plan, task test plan, deliver a class about Segue’s SilkPerformer, and help them build a loadtesting model to evaluate the performance of their system. Findings, recommendations, and results will also be provided.

o Delivered a presentation and paper in Malta for the European Technical Architects Conference on simulation and modeling. The software used was Hyperformix for the simulation demonstration.

o Delivered a paper on simulation and modeling at the AMSCAT Associates Day Conference.

o Conducted research and developed a paper on comparing analytical modeling and simulation strategies for computer and communications assessment using SES/Strategizer-Hyperformix and NetRule.

o Conducted research and developed a paper on Capacity Planning for Client Server, Web-servers, and Distributed architectures and how to effectively measure them.

o Conducted research on Performance Monitors including hardware and software monitors. Sampling, event-driven, and hybrid monitors were investigated.

8/97 – 1/99- Candle Corporation, Falls Church, VA, Senior Systems Engineer Pre-sales and Consulting
My duties and responsibilities included providing consulting and pre-sales technical support for Candle performance management products. These include performance management systems for UNIX and NT platforms. I was also taught classes and developed courses for Candle products to be given after pre-sales customers signed contracts. Completed numerous classes and workshops on Candle products.

2/97 - 7/97 - United States Federal & Guarantee Insurance Company, Baltimore MD, Senior Technology Consultant Capacity Planning and Performance

o Worked as a specialist in communications and computer systems sizing, queuing modeling specialist, planning, and acquisitions.

o USF&G had a significant client-server configuration comprised of NT and Unix systems, and a mainframe Amdahl 5990 Model 12. Client-server transaction based workload forecasting, statistical analysis, system performance assessment, and capacity planning were the principal areas of my responsibilities.

o BGS’s Best/1 (BMC) for Unix and NT, in addition to the NT Performance Monitor with a variety of statistical tools was my primary resources for assessing the impact of transaction-based workloads.

o Developed planned and implemented a capacity planning strategy and system for insuring adequate client-server system resources, including a system for assessing performance of both development and production systems. This included performance parameter determination, thresholds established, and requirements being formulated. BGS/BMC software was used for predictions, collections and analytical modeling. This data could be shared with all departments.

5/93-2/97 - Illinois Institute of Technology Research Institute, Lanham MD, Science Advisor for Mathematics, Computer Modeling and Simulation, Communications Modeling, and Statistical Analysis.

o I worked on The Internal Revenue Tax Modernization Contract as a specialist in communications and computer systems sizing, simulation and queuing modeling specialist, capacity planning, and acquisitions. This included determining requirements, quantifying parameters, conducting surveys, generating data and process models, generating state-transition models, writing full system descriptions, developing workload and traffic models, performing analysis, weighing findings and making recommendations. These duties were performed on event-driven and continuous models.

o Developed a capacity planning and modeling strategy and simulation model for the evaluation of a hardware and software system implemented by the IRS's Electronic Management Project Office (EMS) and SEACOS Project Office. This included EDI software, X.400, X.435, X.12, and FDDI protocols and communications architectures. These systems were simulated with Network II.5, Microsoft Excel, and a series of benchmarks. Requirements were extracted by interviews conducted by expected system users and IRS personnel. The IRS used BMC/BMC software for collection and prediction of background workloads.

o Developed documents including a System Description and Requirements Documents, Workload Assessment and Traffic Modeling Document, and Experimental Design Assessment, that fully described the systems targeted for modeling for the SEACOS and EMS Project Office.

o Designed, developed, and acquired a $600,000 test bed system for performing computer evaluation studies designed to assess the performance of the pilot architecture used to automate the processing of Electronic Data Interchange (EDI) data into proprietary IRS formats.

o Developed a modeling and simulation tutorial used in most modeling and simulation tasks (i.e., client-server and non-client server) for all of TSMI in the ITRL.

o Designed, developed, and acquired a $700,000 modeling and simulation client-server system for the Information Technology and Research Laboratory (ITRL). A requirements document was constructed based upon user input as well as senior management and my experiences. This computer and mathematical modeling and simulation client-server system was designed to model computer, telecommunications (e.g., ATM, FDDI, BISDN, etc.), mathematical and statistical analysis, and econometric systems. Also included were data and process modeling capabilities provided through CASE tools, graphics tools provided analysis using statistically generated data. The hardware architecture included Sun, Intel based processors (486 and Pentiums), and Macintoshes. Interfaces for ATM, FDDI, and Ethernet have been included in every processor.

o Developed a capacity planning and performance plan for use in the laboratory and matched client-server requirements with the use of specialized capacity planning and performance tools. This was based on BGS/BMC Best1, the NT performance monitor, SAS’s products, Tivoli, and SunNet Manager.

o Assisted in developing an end-to-end telecommunications model Traffic Model for assessing the IRS’s anticipated integration case workloads comparing ATM versus other protocols and networks by using BONeS. Requirements and standards were distilled and generated with scenarios provided for each workload modeled. This simulation model was used for the assessment of traffic flows involving IRS's Computing and Service Centers. This included determining requirements, quantifying parameters, generating data and process models, generating state-transition models, writing full system descriptions, developing workload and traffic models, performing analysis, collecting data through interviews and automated efforts, weighing findings and making recommendations.

o Provided technical assessments and selection criteria for queuing modeling, statistical analysis, simulation, capacity planning, and performance analysis tools for the Information Technology Research Laboratory.

o Provided a Users’ Guide for the purpose of instructing laboratory users on how to: (1) use various software modeling and simulation resources, (2) use SunSparc and NT based platforms, and (3) conduct experiments and analysis with BONeS, Comnet III, Network II.5, Meshnet, Performance-3, and other communications simulation and modeling packages for the Information Technology Research Laboratory.

o Developed and presented introductory classes for the simulation software BONeS. The presentation covered the simulation methodology of BONeS, the Post Processor, and Block Diagram Editor to engineers, scientists, and researchers. It was used to present an introduction for simulating communications and computer systems.

o Provided consultation to the IITRI technical staff regarding Operations Research, simulation, statistical analysis, and mathematical modeling problems.

o Constructed a performance model for the purposes of comparing two database processors, three LANs, and two major computer architectures. The emphasis was on comparing throughput rates for four major workloads and response times for each combination and configuration of the systems listed in the sentence preceding. This was used for the acquisition of the optimal alternative based on price and performance.

o Developed risk assessment requirements for a decision support system and data warehouse. The assessment included Teradata, Hitachi Data Systems, Amdahl, Cray and Unisys processors (2200 series
Contact this candidate